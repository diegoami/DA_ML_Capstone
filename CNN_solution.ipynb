{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in required libraries, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SageMaker Resources\n",
    "\n",
    "The below cell stores the SageMaker session and role (for creating estimators and models), and creates a default S3 bucket. After creating this bucket, locally stored data can be uploaded to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# default S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix='cnn-wendy-data'\n",
    "prefix_output='cnn-wendy-model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we retrieve the dataset of images and we upload it to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://da-youtube-ml.s3.eu-central-1.amazonaws.com/wendy-cnn/frames/wendy_cnn_frames_data.zip\n",
    "!unzip -qq -n wendy_cnn_frames_data.zip -d wendy_cnn_frames_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uploaded to s3://sagemaker-eu-central-1-283211002347/cnn-wendy-data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# upload to S3. Skip if already uploaded. This can take a while.\n",
    "print('Uploading data to {}'.format(input_data))\n",
    "input_data = sagemaker_session.upload_data(path='wendy_cnn_frames_data', bucket=bucket, key_prefix=prefix)\n",
    "print('Data uploaded to {}'.format(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location to input data can be written down here, if known\n",
    "input_data='s3://sagemaker-eu-central-1-283211002347/cnn-wendy-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After uploading images to S3, we can define and train the estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path for models is s3://sagemaker-eu-central-1-283211002347/cnn-wendy-model\n"
     ]
    }
   ],
   "source": [
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix_output)\n",
    "print('Output path for models is {}'.format(output_path))\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='letsplay_classifier',\n",
    "                    role=role,\n",
    "                    framework_version='1.6',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    train_volume_size = 10,\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'img-width': 128,\n",
    "                        'img-height': 72,\n",
    "                        'batch-size': 32,\n",
    "                        'layer-cfg': 'D',\n",
    "                        'epochs': 8\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Estimator\n",
    "\n",
    "After instantiating the estimator, we train it with a call to `.fit()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 01:16:53 Starting - Starting the training job...\n",
      "2020-10-21 01:16:55 Starting - Launching requested ML instances......\n",
      "2020-10-21 01:18:01 Starting - Preparing the instances for training.........\n",
      "2020-10-21 01:19:27 Downloading - Downloading input data....................................\n",
      "2020-10-21 01:25:53 Training - Downloading the training image...\n",
      "2020-10-21 01:26:14 Training - Training image download completed. Training in progress.\u001B[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001B[0m\n",
      "\u001B[34mbash: no job control in this shell\u001B[0m\n",
      "\u001B[34m2020-10-21 01:26:15,089 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001B[0m\n",
      "\u001B[34m2020-10-21 01:26:15,116 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001B[0m\n",
      "\u001B[34m2020-10-21 01:26:15,741 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001B[0m\n",
      "\u001B[34m2020-10-21 01:26:16,162 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001B[0m\n",
      "\u001B[34m/opt/conda/bin/python -m pip install -r requirements.txt\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.23.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torch==1.6.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.6.0)\u001B[0m\n",
      "\u001B[34mCollecting torchdata==0.2.0\n",
      "  Downloading torchdata-0.2.0-py3-none-any.whl (27 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torchvision==0.7.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.7.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.19.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 1)) (2.1.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.5.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 1)) (0.17.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 2)) (0.18.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.7.0->-r requirements.txt (line 4)) (7.2.0)\u001B[0m\n",
      "\u001B[34mInstalling collected packages: torchdata\u001B[0m\n",
      "\u001B[34mSuccessfully installed torchdata-0.2.0\u001B[0m\n",
      "\u001B[34m2020-10-21 01:26:18,203 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001B[0m\n",
      "\u001B[34mTraining Env:\n",
      "\u001B[0m\n",
      "\u001B[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 32,\n",
      "        \"layer-cfg\": \"D\",\n",
      "        \"img-width\": 128,\n",
      "        \"epochs\": 8,\n",
      "        \"img-height\": 72\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-10-21-01-16-52-935\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-283211002347/pytorch-training-2020-10-21-01-16-52-935/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001B[0m\n",
      "\u001B[34m}\n",
      "\u001B[0m\n",
      "\u001B[34mEnvironment variables:\n",
      "\u001B[0m\n",
      "\u001B[34mSM_HOSTS=[\"algo-1\"]\u001B[0m\n",
      "\u001B[34mSM_NETWORK_INTERFACE_NAME=eth0\u001B[0m\n",
      "\u001B[34mSM_HPS={\"batch-size\":32,\"epochs\":8,\"img-height\":72,\"img-width\":128,\"layer-cfg\":\"D\"}\u001B[0m\n",
      "\u001B[34mSM_USER_ENTRY_POINT=train.py\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_PARAMS={}\u001B[0m\n",
      "\u001B[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001B[0m\n",
      "\u001B[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001B[0m\n",
      "\u001B[34mSM_CHANNELS=[\"train\"]\u001B[0m\n",
      "\u001B[34mSM_CURRENT_HOST=algo-1\u001B[0m\n",
      "\u001B[34mSM_MODULE_NAME=train\u001B[0m\n",
      "\u001B[34mSM_LOG_LEVEL=20\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001B[0m\n",
      "\u001B[34mSM_INPUT_DIR=/opt/ml/input\u001B[0m\n",
      "\u001B[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DIR=/opt/ml/output\u001B[0m\n",
      "\u001B[34mSM_NUM_CPUS=4\u001B[0m\n",
      "\u001B[34mSM_NUM_GPUS=1\u001B[0m\n",
      "\u001B[34mSM_MODEL_DIR=/opt/ml/model\u001B[0m\n",
      "\u001B[34mSM_MODULE_DIR=s3://sagemaker-eu-central-1-283211002347/pytorch-training-2020-10-21-01-16-52-935/source/sourcedir.tar.gz\u001B[0m\n",
      "\u001B[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":32,\"epochs\":8,\"img-height\":72,\"img-width\":128,\"layer-cfg\":\"D\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-10-21-01-16-52-935\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-283211002347/pytorch-training-2020-10-21-01-16-52-935/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001B[0m\n",
      "\u001B[34mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"8\",\"--img-height\",\"72\",\"--img-width\",\"128\",\"--layer-cfg\",\"D\"]\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001B[0m\n",
      "\u001B[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001B[0m\n",
      "\u001B[34mSM_HP_BATCH-SIZE=32\u001B[0m\n",
      "\u001B[34mSM_HP_LAYER-CFG=D\u001B[0m\n",
      "\u001B[34mSM_HP_IMG-WIDTH=128\u001B[0m\n",
      "\u001B[34mSM_HP_EPOCHS=8\u001B[0m\n",
      "\u001B[34mSM_HP_IMG-HEIGHT=72\u001B[0m\n",
      "\u001B[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001B[0m\n",
      "\u001B[34mInvoking script with the following command:\n",
      "\u001B[0m\n",
      "\u001B[34m/opt/conda/bin/python train.py --batch-size 32 --epochs 8 --img-height 72 --img-width 128 --layer-cfg D\n",
      "\n",
      "\u001B[0m\n",
      "\u001B[34mEpoch 0/8\u001B[0m\n",
      "\u001B[34m----------\u001B[0m\n",
      "\u001B[34mTraining batch 0/1072\u001B[0m\n",
      "\u001B[34m[2020-10-21 01:26:28.869 algo-1:32 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001B[0m\n",
      "\u001B[34m[2020-10-21 01:26:28.869 algo-1:32 INFO hook.py:193] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001B[0m\n",
      "\u001B[34m[2020-10-21 01:26:28.869 algo-1:32 INFO hook.py:238] Saving to /opt/ml/output/tensors\u001B[0m\n",
      "\u001B[34m[2020-10-21 01:26:28.870 algo-1:32 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001B[0m\n",
      "\u001B[34m[2020-10-21 01:26:28.916 algo-1:32 INFO hook.py:398] Monitoring the collections: losses\u001B[0m\n",
      "\u001B[34m[2020-10-21 01:26:28.916 algo-1:32 INFO hook.py:459] Hook is writing from the hook with pid: 32\n",
      "\u001B[0m\n",
      "\u001B[34mTraining batch 100/1072\u001B[0m\n",
      "\u001B[34mTraining batch 200/1072\u001B[0m\n",
      "\u001B[34mTraining batch 300/1072\u001B[0m\n",
      "\u001B[34mTraining batch 400/1072\u001B[0m\n",
      "\u001B[34mTraining batch 500/1072\u001B[0m\n",
      "\u001B[34mTraining batch 600/1072\u001B[0m\n",
      "\u001B[34mTraining batch 700/1072\u001B[0m\n",
      "\u001B[34mTraining batch 800/1072\u001B[0m\n",
      "\u001B[34mTraining batch 900/1072\u001B[0m\n",
      "\u001B[34mTraining batch 1000/1072\u001B[0m\n",
      "\u001B[34mValidation batch 0/358\u001B[0m\n",
      "\u001B[34mValidation batch 100/358\u001B[0m\n",
      "\u001B[34mValidation batch 200/358\u001B[0m\n",
      "\u001B[34mValidation batch 300/358\u001B[0m\n",
      "\u001B[34mEpoch 0 result: \u001B[0m\n",
      "\u001B[34mAvg loss (train): 0.0110\u001B[0m\n",
      "\u001B[34mAvg acc (train): 0.8921\u001B[0m\n",
      "\u001B[34mAvg loss (val): 0.0066\u001B[0m\n",
      "\u001B[34mAvg acc (val): 0.9351\u001B[0m\n",
      "\u001B[34m----------\n",
      "\u001B[0m\n",
      "\u001B[34mEpoch 1/8\u001B[0m\n",
      "\u001B[34m----------\u001B[0m\n",
      "\u001B[34mTraining batch 0/1072\u001B[0m\n",
      "\u001B[34mTraining batch 100/1072\u001B[0m\n",
      "\u001B[34mTraining batch 200/1072\u001B[0m\n",
      "\u001B[34mTraining batch 300/1072\u001B[0m\n",
      "\u001B[34mTraining batch 400/1072\u001B[0m\n",
      "\u001B[34mTraining batch 500/1072\u001B[0m\n",
      "\u001B[34mTraining batch 600/1072\u001B[0m\n",
      "\u001B[34mTraining batch 700/1072\u001B[0m\n",
      "\u001B[34mTraining batch 800/1072\u001B[0m\n",
      "\u001B[34mTraining batch 900/1072\u001B[0m\n",
      "\u001B[34mTraining batch 1000/1072\u001B[0m\n",
      "\u001B[34mValidation batch 0/358\u001B[0m\n",
      "\u001B[34mValidation batch 100/358\u001B[0m\n",
      "\u001B[34mValidation batch 200/358\u001B[0m\n",
      "\u001B[34mValidation batch 300/358\u001B[0m\n",
      "\u001B[34mEpoch 1 result: \u001B[0m\n",
      "\u001B[34mAvg loss (train): 0.0064\u001B[0m\n",
      "\u001B[34mAvg acc (train): 0.9374\u001B[0m\n",
      "\u001B[34mAvg loss (val): 0.0053\u001B[0m\n",
      "\u001B[34mAvg acc (val): 0.9467\u001B[0m\n",
      "\u001B[34m----------\n",
      "\u001B[0m\n",
      "\u001B[34mEpoch 2/8\u001B[0m\n",
      "\u001B[34m----------\u001B[0m\n",
      "\u001B[34mTraining batch 0/1072\u001B[0m\n",
      "\u001B[34mTraining batch 100/1072\u001B[0m\n",
      "\u001B[34mTraining batch 200/1072\u001B[0m\n",
      "\u001B[34mTraining batch 300/1072\u001B[0m\n",
      "\u001B[34mTraining batch 400/1072\u001B[0m\n",
      "\u001B[34mTraining batch 500/1072\u001B[0m\n",
      "\u001B[34mTraining batch 600/1072\u001B[0m\n",
      "\u001B[34mTraining batch 700/1072\u001B[0m\n",
      "\u001B[34mTraining batch 800/1072\u001B[0m\n",
      "\u001B[34mTraining batch 900/1072\u001B[0m\n",
      "\u001B[34mTraining batch 1000/1072\u001B[0m\n",
      "\u001B[34mValidation batch 0/358\u001B[0m\n",
      "\u001B[34mValidation batch 100/358\u001B[0m\n",
      "\u001B[34mValidation batch 200/358\u001B[0m\n",
      "\u001B[34mValidation batch 300/358\u001B[0m\n",
      "\u001B[34mEpoch 2 result: \u001B[0m\n",
      "\u001B[34mAvg loss (train): 0.0048\u001B[0m\n",
      "\u001B[34mAvg acc (train): 0.9518\u001B[0m\n",
      "\u001B[34mAvg loss (val): 0.0043\u001B[0m\n",
      "\u001B[34mAvg acc (val): 0.9614\u001B[0m\n",
      "\u001B[34m----------\n",
      "\u001B[0m\n",
      "\u001B[34mEpoch 3/8\u001B[0m\n",
      "\u001B[34m----------\u001B[0m\n",
      "\u001B[34mTraining batch 0/1072\u001B[0m\n",
      "\u001B[34mTraining batch 100/1072\u001B[0m\n",
      "\u001B[34mTraining batch 200/1072\u001B[0m\n",
      "\u001B[34mTraining batch 300/1072\u001B[0m\n",
      "\u001B[34mTraining batch 400/1072\u001B[0m\n",
      "\u001B[34mTraining batch 500/1072\u001B[0m\n",
      "\u001B[34mTraining batch 600/1072\u001B[0m\n",
      "\u001B[34mTraining batch 700/1072\u001B[0m\n",
      "\u001B[34mTraining batch 800/1072\u001B[0m\n",
      "\u001B[34mTraining batch 900/1072\u001B[0m\n",
      "\u001B[34mTraining batch 1000/1072\u001B[0m\n",
      "\u001B[34mValidation batch 0/358\u001B[0m\n",
      "\u001B[34mValidation batch 100/358\u001B[0m\n",
      "\u001B[34mValidation batch 200/358\u001B[0m\n",
      "\u001B[34mValidation batch 300/358\u001B[0m\n",
      "\u001B[34mEpoch 3 result: \u001B[0m\n",
      "\u001B[34mAvg loss (train): 0.0040\u001B[0m\n",
      "\u001B[34mAvg acc (train): 0.9596\u001B[0m\n",
      "\u001B[34mAvg loss (val): 0.0042\u001B[0m\n",
      "\u001B[34mAvg acc (val): 0.9584\u001B[0m\n",
      "\u001B[34m----------\n",
      "\u001B[0m\n",
      "\u001B[34mEpoch 4/8\u001B[0m\n",
      "\u001B[34m----------\u001B[0m\n",
      "\u001B[34mTraining batch 0/1072\u001B[0m\n",
      "\u001B[34mTraining batch 100/1072\u001B[0m\n",
      "\u001B[34mTraining batch 200/1072\u001B[0m\n",
      "\u001B[34mTraining batch 300/1072\u001B[0m\n",
      "\u001B[34mTraining batch 400/1072\u001B[0m\n",
      "\u001B[34mTraining batch 500/1072\u001B[0m\n",
      "\u001B[34mTraining batch 600/1072\u001B[0m\n",
      "\u001B[34mTraining batch 700/1072\u001B[0m\n",
      "\u001B[34mTraining batch 800/1072\u001B[0m\n",
      "\u001B[34mTraining batch 900/1072\u001B[0m\n",
      "\u001B[34mTraining batch 1000/1072\u001B[0m\n",
      "\u001B[34mValidation batch 0/358\u001B[0m\n",
      "\u001B[34mValidation batch 100/358\u001B[0m\n",
      "\u001B[34mValidation batch 200/358\u001B[0m\n",
      "\u001B[34mValidation batch 300/358\u001B[0m\n",
      "\u001B[34mEpoch 4 result: \u001B[0m\n",
      "\u001B[34mAvg loss (train): 0.0033\u001B[0m\n",
      "\u001B[34mAvg acc (train): 0.9656\u001B[0m\n",
      "\u001B[34mAvg loss (val): 0.0036\u001B[0m\n",
      "\u001B[34mAvg acc (val): 0.9671\u001B[0m\n",
      "\u001B[34m----------\n",
      "\u001B[0m\n",
      "\u001B[34mEpoch 5/8\u001B[0m\n",
      "\u001B[34m----------\u001B[0m\n",
      "\u001B[34mTraining batch 0/1072\u001B[0m\n",
      "\u001B[34mTraining batch 100/1072\u001B[0m\n",
      "\u001B[34mTraining batch 200/1072\u001B[0m\n",
      "\u001B[34mTraining batch 300/1072\u001B[0m\n",
      "\u001B[34mTraining batch 400/1072\u001B[0m\n",
      "\u001B[34mTraining batch 500/1072\u001B[0m\n",
      "\u001B[34mTraining batch 600/1072\u001B[0m\n",
      "\u001B[34mTraining batch 700/1072\u001B[0m\n",
      "\u001B[34mTraining batch 800/1072\u001B[0m\n",
      "\u001B[34mTraining batch 900/1072\u001B[0m\n",
      "\u001B[34mTraining batch 1000/1072\u001B[0m\n",
      "\u001B[34mValidation batch 0/358\u001B[0m\n",
      "\u001B[34mValidation batch 100/358\u001B[0m\n",
      "\u001B[34mValidation batch 200/358\u001B[0m\n",
      "\u001B[34mValidation batch 300/358\u001B[0m\n",
      "\u001B[34mEpoch 5 result: \u001B[0m\n",
      "\u001B[34mAvg loss (train): 0.0029\u001B[0m\n",
      "\u001B[34mAvg acc (train): 0.9702\u001B[0m\n",
      "\u001B[34mAvg loss (val): 0.0032\u001B[0m\n",
      "\u001B[34mAvg acc (val): 0.9707\u001B[0m\n",
      "\u001B[34m----------\n",
      "\u001B[0m\n",
      "\u001B[34mEpoch 6/8\u001B[0m\n",
      "\u001B[34m----------\u001B[0m\n",
      "\u001B[34mTraining batch 0/1072\u001B[0m\n",
      "\u001B[34mTraining batch 100/1072\u001B[0m\n",
      "\u001B[34mTraining batch 200/1072\u001B[0m\n",
      "\u001B[34mTraining batch 300/1072\u001B[0m\n",
      "\u001B[34mTraining batch 400/1072\u001B[0m\n",
      "\u001B[34mTraining batch 500/1072\u001B[0m\n",
      "\u001B[34mTraining batch 600/1072\u001B[0m\n",
      "\u001B[34mTraining batch 700/1072\u001B[0m\n",
      "\u001B[34mTraining batch 800/1072\u001B[0m\n",
      "\u001B[34mTraining batch 900/1072\u001B[0m\n",
      "\u001B[34mTraining batch 1000/1072\u001B[0m\n",
      "\u001B[34mValidation batch 0/358\u001B[0m\n",
      "\u001B[34mValidation batch 100/358\u001B[0m\n",
      "\u001B[34mValidation batch 200/358\u001B[0m\n",
      "\u001B[34mValidation batch 300/358\u001B[0m\n",
      "\u001B[34mEpoch 6 result: \u001B[0m\n",
      "\u001B[34mAvg loss (train): 0.0025\u001B[0m\n",
      "\u001B[34mAvg acc (train): 0.9735\u001B[0m\n",
      "\u001B[34mAvg loss (val): 0.0037\u001B[0m\n",
      "\u001B[34mAvg acc (val): 0.9705\u001B[0m\n",
      "\u001B[34m----------\n",
      "\u001B[0m\n",
      "\u001B[34mEpoch 7/8\u001B[0m\n",
      "\u001B[34m----------\u001B[0m\n",
      "\u001B[34mTraining batch 0/1072\u001B[0m\n",
      "\u001B[34mTraining batch 100/1072\u001B[0m\n",
      "\u001B[34mTraining batch 200/1072\u001B[0m\n",
      "\u001B[34mTraining batch 300/1072\u001B[0m\n",
      "\u001B[34mTraining batch 400/1072\u001B[0m\n",
      "\u001B[34mTraining batch 500/1072\u001B[0m\n",
      "\u001B[34mTraining batch 600/1072\u001B[0m\n",
      "\u001B[34mTraining batch 700/1072\u001B[0m\n",
      "\u001B[34mTraining batch 800/1072\u001B[0m\n",
      "\u001B[34mTraining batch 900/1072\u001B[0m\n",
      "\u001B[34mTraining batch 1000/1072\u001B[0m\n",
      "\u001B[34mValidation batch 0/358\u001B[0m\n",
      "\u001B[34mValidation batch 100/358\u001B[0m\n",
      "\u001B[34mValidation batch 200/358\u001B[0m\n",
      "\u001B[34mValidation batch 300/358\u001B[0m\n",
      "\n",
      "2020-10-21 03:02:52 Uploading - Uploading generated training model\u001B[34mEpoch 7 result: \u001B[0m\n",
      "\u001B[34mAvg loss (train): 0.0022\u001B[0m\n",
      "\u001B[34mAvg acc (train): 0.9767\u001B[0m\n",
      "\u001B[34mAvg loss (val): 0.0029\u001B[0m\n",
      "\u001B[34mAvg acc (val): 0.9705\u001B[0m\n",
      "\u001B[34m----------\n",
      "\n",
      "\u001B[0m\n",
      "\u001B[34mTraining completed in 96m 18s\u001B[0m\n",
      "\u001B[34mBest acc: 0.9707\u001B[0m\n",
      "\u001B[34mSaving the model.\u001B[0m\n",
      "\u001B[34m2020-10-21 03:02:48,110 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001B[0m\n",
      "\n",
      "2020-10-21 03:04:10 Completed - Training job completed\n",
      "Training seconds: 6283\n",
      "Billable seconds: 6283\n",
      "CPU times: user 14.5 s, sys: 555 ms, total: 15 s\n",
      "Wall time: 1h 47min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# train the estimator on S3 training data\n",
    "estimator.fit({'train': input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-central-1-283211002347/cnn-wendy-model/pytorch-training-2020-10-21-01-16-52-935/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(estimator.model_data)\n",
    "model_data = estimator.model_data\n",
    "# model_data ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a model that can predict the class of an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the trained model\n",
    "\n",
    "We deploy our model to create a predictor. We'll use this to make predictions on our data and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# importing PyTorchModel\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.6',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir='letsplay_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!CPU times: user 39.5 s, sys: 5.32 s, total: 44.9 s\n",
      "Wall time: 10min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# deploy and create a predictor\n",
    "              \n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.p2.xlarge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the endpoint where the predictor is located\n",
    "endpoint_name = predictor.endpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is deployed, we check how the predictor performs on our full dataset,\n",
    "ensuring that the predictions make sense. We produce a classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-inference-2020-10-21-03-11-03-490\n"
     ]
    }
   ],
   "source": [
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 processed up to 251\n",
      "100 processed up to 492\n",
      "150 processed up to 697\n",
      "200 processed up to 1001\n",
      "250 processed up to 1246\n",
      "300 processed up to 1527\n",
      "350 processed up to 1769\n",
      "400 processed up to 2006\n",
      "450 processed up to 2349\n",
      "500 processed up to 2521\n",
      "550 processed up to 2833\n",
      "600 processed up to 3081\n",
      "650 processed up to 3290\n",
      "700 processed up to 3533\n",
      "750 processed up to 3721\n",
      "800 processed up to 3934\n",
      "850 processed up to 4144\n",
      "900 processed up to 4334\n",
      "950 processed up to 4566\n",
      "1000 processed up to 4856\n",
      "1050 processed up to 5146\n",
      "1100 processed up to 5353\n",
      "1150 processed up to 5610\n",
      "1200 processed up to 5828\n",
      "1250 processed up to 6059\n",
      "1300 processed up to 6279\n",
      "1350 processed up to 6451\n",
      "1400 processed up to 6720\n",
      "1450 processed up to 6917\n",
      "1500 processed up to 7201\n",
      "1550 processed up to 7439\n",
      "1600 processed up to 7681\n",
      "1650 processed up to 8058\n",
      "1700 processed up to 8344\n",
      "1750 processed up to 8617\n",
      "1800 processed up to 8941\n",
      "1850 processed up to 9207\n",
      "1900 processed up to 9390\n",
      "1950 processed up to 9667\n",
      "2000 processed up to 9839\n",
      "2050 processed up to 10121\n",
      "2100 processed up to 10380\n",
      "2150 processed up to 10663\n",
      "2200 processed up to 10978\n",
      "2250 processed up to 11242\n",
      "2300 processed up to 11553\n",
      "2350 processed up to 11820\n",
      "2400 processed up to 12097\n",
      "2450 processed up to 12303\n",
      "2500 processed up to 12508\n",
      "2550 processed up to 12765\n",
      "2600 processed up to 13052\n",
      "2650 processed up to 13290\n",
      "2700 processed up to 13660\n",
      "2750 processed up to 13899\n",
      "2800 processed up to 14267\n",
      "2850 processed up to 14519\n",
      "2900 processed up to 14829\n",
      "2950 processed up to 15136\n",
      "3000 processed up to 15436\n",
      "3050 processed up to 15625\n",
      "3100 processed up to 15878\n",
      "3150 processed up to 16101\n",
      "3200 processed up to 16372\n",
      "3250 processed up to 16713\n",
      "3300 processed up to 16931\n",
      "3350 processed up to 17200\n",
      "3400 processed up to 17466\n",
      "3450 processed up to 17725\n",
      "3500 processed up to 17930\n",
      "3550 processed up to 18218\n",
      "3600 processed up to 18525\n",
      "3650 processed up to 18746\n",
      "3700 processed up to 18979\n",
      "3750 processed up to 19233\n",
      "3800 processed up to 19509\n",
      "3850 processed up to 19802\n",
      "3900 processed up to 20134\n",
      "3950 processed up to 20429\n",
      "4000 processed up to 20706\n",
      "4050 processed up to 20936\n",
      "4100 processed up to 21160\n",
      "4150 processed up to 21397\n",
      "4200 processed up to 21729\n",
      "4250 processed up to 21978\n",
      "4300 processed up to 22224\n",
      "4350 processed up to 22526\n",
      "4400 processed up to 22829\n",
      "4450 processed up to 23109\n",
      "4500 processed up to 23329\n",
      "4550 processed up to 23634\n",
      "4600 processed up to 23958\n",
      "4650 processed up to 24238\n",
      "4700 processed up to 24485\n",
      "4750 processed up to 24683\n",
      "4800 processed up to 24941\n",
      "4850 processed up to 25304\n",
      "4900 processed up to 25474\n",
      "4950 processed up to 25741\n",
      "5000 processed up to 25946\n",
      "5050 processed up to 26167\n",
      "5100 processed up to 26495\n",
      "5150 processed up to 26697\n",
      "5200 processed up to 27076\n",
      "5250 processed up to 27339\n",
      "5300 processed up to 27514\n",
      "5350 processed up to 27743\n",
      "5400 processed up to 28081\n",
      "5450 processed up to 28274\n",
      "5500 processed up to 28587\n",
      "5550 processed up to 28910\n",
      "5600 processed up to 29124\n",
      "5650 processed up to 29363\n",
      "5700 processed up to 29578\n",
      "5750 processed up to 29861\n",
      "5800 processed up to 29996\n",
      "5850 processed up to 30222\n",
      "5900 processed up to 30433\n",
      "5950 processed up to 30647\n",
      "6000 processed up to 30827\n",
      "6050 processed up to 31130\n",
      "6100 processed up to 31361\n",
      "6150 processed up to 31558\n",
      "6200 processed up to 31838\n",
      "6250 processed up to 32139\n",
      "6300 processed up to 32413\n",
      "6350 processed up to 32650\n",
      "6400 processed up to 32882\n",
      "6450 processed up to 33127\n",
      "6500 processed up to 33305\n",
      "6550 processed up to 33465\n",
      "6600 processed up to 33631\n",
      "6650 processed up to 33850\n",
      "6700 processed up to 34273\n",
      "6750 processed up to 34545\n",
      "6800 processed up to 34854\n",
      "6850 processed up to 35086\n",
      "6900 processed up to 35345\n",
      "6950 processed up to 35590\n",
      "7000 processed up to 35926\n",
      "7050 processed up to 36259\n",
      "7100 processed up to 36514\n",
      "7150 processed up to 36715\n",
      "7200 processed up to 36961\n",
      "7250 processed up to 37144\n",
      "7300 processed up to 37487\n",
      "7350 processed up to 37674\n",
      "7400 processed up to 37943\n",
      "7450 processed up to 38154\n",
      "7500 processed up to 38351\n",
      "7550 processed up to 38643\n",
      "7600 processed up to 38886\n",
      "7650 processed up to 39101\n",
      "7700 processed up to 39310\n",
      "7750 processed up to 39531\n",
      "7800 processed up to 39710\n",
      "7850 processed up to 39902\n",
      "7900 processed up to 40214\n",
      "7950 processed up to 40417\n",
      "8000 processed up to 40634\n",
      "8050 processed up to 40836\n",
      "8100 processed up to 41027\n",
      "8150 processed up to 41294\n",
      "8200 processed up to 41644\n",
      "8250 processed up to 41883\n",
      "8300 processed up to 42144\n",
      "8350 processed up to 42382\n",
      "8400 processed up to 42727\n",
      "8450 processed up to 42969\n",
      "8500 processed up to 43235\n",
      "8550 processed up to 43480\n",
      "8600 processed up to 43715\n",
      "8650 processed up to 43944\n",
      "8700 processed up to 44189\n",
      "8750 processed up to 44452\n",
      "8800 processed up to 44675\n",
      "8850 processed up to 44980\n",
      "8900 processed up to 45261\n",
      "8950 processed up to 45475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       597\n",
      "           1       0.97      0.95      0.96       132\n",
      "           2       0.99      0.98      0.98      2956\n",
      "           3       0.96      1.00      0.98        25\n",
      "           4       0.97      0.98      0.98       703\n",
      "           5       0.29      0.67      0.40         3\n",
      "           6       0.85      0.90      0.88        70\n",
      "           7       0.80      0.67      0.73        12\n",
      "\n",
      "    accuracy                           0.98      4498\n",
      "   macro avg       0.85      0.89      0.86      4498\n",
      "weighted avg       0.98      0.98      0.98      4498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#endpoint_name='pytorch-inference-2020-10-20-02-20-28-656'\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from letsplay_classifier.endpoint import evaluate\n",
    "y_true, y_pred = evaluate(endpoint_name, 'wendy_cnn_frames_data', 0.1)\n",
    "report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Endpoint\n",
    "\n",
    "Finally, I've added a convenience function to delete prediction endpoints after we're done with them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a predictor endpoint as input\n",
    "# And deletes the endpoint by name\n",
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=endpoint_name)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already deleted: pytorch-inference-2020-10-21-03-11-03-490\n"
     ]
    }
   ],
   "source": [
    "# delete the predictor endpoint \n",
    "delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}