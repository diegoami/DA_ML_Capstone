{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in required libraries, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SageMaker Resources\n",
    "\n",
    "The below cell stores the SageMaker session and role (for creating estimators and models), and creates a default S3 bucket. After creating this bucket, you can upload any locally stored data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# default S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://da-youtube-ml.s3.eu-central-1.amazonaws.com/wendy-cnn/frames/wendy_cnn_frames_data.zip\n",
    "!unzip wendy_cnn_frames_data.zip -d wendy_cnn_frames_data \n",
    "!rm wendy_cnn_frames_data.zip\n",
    "\n",
    "# upload to S3\n",
    "input_data = sagemaker_session.upload_data(path='wendy_cnn_frames_data', bucket=bucket, key_prefix=prefix)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The next cell runs the above function to create a `train.csv` file in a specified directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell runs the above function to create a `train.csv` file in a specified directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check that you've uploaded the data, by printing the contents of the default bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, models, transforms\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mvgg\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m make_layers, VGG, cfgs\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mVGGLP\u001b[39;49;00m(VGG):\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, num_classes):\r\n",
      "        \u001b[36msuper\u001b[39;49;00m(VGGLP, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m(make_layers(cfgs[\u001b[33m'\u001b[39;49;00m\u001b[33mD\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], batch_norm=\u001b[34mTrue\u001b[39;49;00m))\r\n",
      "        num_features = \u001b[36mself\u001b[39;49;00m.classifier[\u001b[34m6\u001b[39;49;00m].in_features\r\n",
      "        features = \u001b[36mlist\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.classifier.children())[:-\u001b[34m1\u001b[39;49;00m]  \u001b[37m# Remove last layer\u001b[39;49;00m\r\n",
      "        features.extend([nn.Linear(num_features, num_classes)])  \u001b[37m# Add our layer with 4 outputs\u001b[39;49;00m\r\n",
      "        \u001b[36mself\u001b[39;49;00m.classifier = nn.Sequential(*features)  \u001b[37m# Replace the model classifier\u001b[39;49;00m\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize letsplay_classifier/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function \u001b[37m# future proof\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcopy\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "LOCAL = \u001b[34m1\u001b[39;49;00m\n",
      "\u001b[37m# pytorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mautograd\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Variable\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchdata\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, models, transforms\n",
      "\n",
      "\u001b[37m# import model\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m VGGLP\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# First, load the parameters used to create the model.\u001b[39;49;00m\n",
      "    model_info = {}\n",
      "    model_info_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model_info = torch.load(f)\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_info: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(model_info))\n",
      "\n",
      "    \u001b[37m# Determine the device and construct the model.\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    model = VGGLP(model_info.num_classes)\n",
      "\n",
      "    \u001b[37m# Load the stored model parameters.\u001b[39;49;00m\n",
      "    model_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model.load_state_dict(torch.load(f))\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\n",
      "\n",
      "\n",
      "\u001b[37m# Load the training data from a csv file\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_train_loader\u001b[39;49;00m(batch_size, data_dir):\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet data loader.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# read in csv file\u001b[39;49;00m\n",
      "    train_data = pd.read_csv(os.path.join(data_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), header=\u001b[34mNone\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# labels are first column\u001b[39;49;00m\n",
      "    train_y = torch.from_numpy(train_data[[\u001b[34m0\u001b[39;49;00m]].values).float().squeeze()\n",
      "    \u001b[37m# features are the rest\u001b[39;49;00m\n",
      "    train_x = torch.from_numpy(train_data.drop([\u001b[34m0\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m).values).float()\n",
      "\n",
      "    \u001b[37m# create dataset\u001b[39;49;00m\n",
      "    train_ds = torch.utils.data.TensorDataset(train_x, train_y)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(train_ds, batch_size=batch_size)\n",
      "\n",
      "\n",
      "\u001b[37m# Provided train function\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(model, train_loader, epochs, optimizer, criterion, device):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    This is the training method that is called by the PyTorch training script. The parameters\u001b[39;49;00m\n",
      "\u001b[33m    passed are as follows:\u001b[39;49;00m\n",
      "\u001b[33m    model        - The PyTorch model that we wish to train.\u001b[39;49;00m\n",
      "\u001b[33m    train_loader - The PyTorch DataLoader that should be used during training.\u001b[39;49;00m\n",
      "\u001b[33m    epochs       - The total number of epochs to train for.\u001b[39;49;00m\n",
      "\u001b[33m    optimizer    - The optimizer to use during training.\u001b[39;49;00m\n",
      "\u001b[33m    criterion    - The loss function used for training. \u001b[39;49;00m\n",
      "\u001b[33m    device       - Where the model and data should be loaded (gpu or cpu).\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, epochs + \u001b[34m1\u001b[39;49;00m):\n",
      "        model.train()\n",
      "        total_loss = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m batch_idx, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader, \u001b[34m1\u001b[39;49;00m):\n",
      "            \u001b[37m# prep data\u001b[39;49;00m\n",
      "            data, target = data.to(device), target.to(device)\n",
      "            optimizer.zero_grad() \u001b[37m# zero accumulated gradients\u001b[39;49;00m\n",
      "            \u001b[37m# get output of SimpleNet\u001b[39;49;00m\n",
      "            output = model(data)\n",
      "            \u001b[37m# calculate loss and perform backprop\u001b[39;49;00m\n",
      "            loss = criterion(output, target)\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "    \n",
      "            total_loss += loss.item()\n",
      "        \n",
      "        \u001b[37m# print loss stats\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m, Loss: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch, total_loss / \u001b[36mlen\u001b[39;49;00m(train_loader)))\n",
      "\n",
      "    \u001b[37m# save trained model, after all epochs\u001b[39;49;00m\n",
      "    save_model(model, args.model_dir)\n",
      "\n",
      "\n",
      "\u001b[37m# Provided model saving functions\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(model, model_dir):\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[37m# save state dictionary\u001b[39;49;00m\n",
      "    torch.save(model.cpu().state_dict(), path)\n",
      "    \n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model_params\u001b[39;49;00m(num_classes):\n",
      "    model_info_path = os.path.join(args.model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model_info = {\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mnum_classes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: num_classes,\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mimg_width\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.img_width,\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mimg_height\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.img_height\n",
      "        }\n",
      "        torch.save(model_info, f)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_data_loaders\u001b[39;49;00m(img_dir, img_height=\u001b[34m256\u001b[39;49;00m, img_width=\u001b[34m256\u001b[39;49;00m, batch_size=\u001b[34m8\u001b[39;49;00m):\n",
      "    NUM_WORKER = \u001b[34m2\u001b[39;49;00m\n",
      "    root = img_dir\n",
      "    total_count = \u001b[36msum\u001b[39;49;00m([\u001b[36mlen\u001b[39;49;00m(files) \u001b[34mfor\u001b[39;49;00m r, d, files \u001b[35min\u001b[39;49;00m os.walk(root)])\n",
      "\n",
      "    data_transform = torchvision.transforms.Compose(\n",
      "        [\n",
      "            transforms.Resize((img_height, img_width)),\n",
      "            transforms.ToTensor()\n",
      "        ]\n",
      "    )\n",
      "    model_dataset = td.datasets.WrapDataset(torchvision.datasets.ImageFolder(root, transform=data_transform))\n",
      "    \u001b[37m# Also you shouldn't use transforms here but below\u001b[39;49;00m\n",
      "    train_count = \u001b[36mint\u001b[39;49;00m(\u001b[34m0.75\u001b[39;49;00m * total_count)\n",
      "    valid_count = total_count - train_count\n",
      "\n",
      "    train_dataset, valid_dataset= torch.utils.data.random_split(\n",
      "        model_dataset, (train_count, valid_count)\n",
      "    )\n",
      "\n",
      "\n",
      "\n",
      "    train_dataset_loader = torch.utils.data.DataLoader(\n",
      "        train_dataset, batch_size=batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m, num_workers=NUM_WORKER\n",
      "    )\n",
      "    valid_dataset_loader = torch.utils.data.DataLoader(\n",
      "        valid_dataset, batch_size=batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m, num_workers=NUM_WORKER\n",
      "    )\n",
      "\n",
      "\n",
      "    dataloaders = {\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: train_dataset_loader,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: valid_dataset_loader\n",
      "    }\n",
      "    dataset_sizes = {\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: train_count,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: valid_count\n",
      "    }\n",
      "    class_names = model_dataset.classes\n",
      "    \u001b[34mreturn\u001b[39;49;00m dataloaders, dataset_sizes, class_names\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \\\n",
      "        \u001b[32mtrain_model\u001b[39;49;00m(vgg, dataloaders, dataset_sizes, criterion, optimizer,  num_epochs=\u001b[34m15\u001b[39;49;00m):\n",
      "    use_gpu = torch.cuda.is_available()\n",
      "    since = time.time()\n",
      "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
      "    best_acc = \u001b[34m0.0\u001b[39;49;00m\n",
      "    train_batches = \u001b[36mlen\u001b[39;49;00m(dataloaders[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    val_batches = \u001b[36mlen\u001b[39;49;00m(dataloaders[\u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(num_epochs):\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch, num_epochs))\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m * \u001b[34m10\u001b[39;49;00m)\n",
      "\n",
      "        loss_train = \u001b[34m0\u001b[39;49;00m\n",
      "        loss_val = \u001b[34m0\u001b[39;49;00m\n",
      "        acc_train = \u001b[34m0\u001b[39;49;00m\n",
      "        acc_val = \u001b[34m0\u001b[39;49;00m\n",
      "\n",
      "        vgg.train(\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "        \u001b[34mfor\u001b[39;49;00m i, data \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(dataloaders[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]):\n",
      "            \u001b[34mif\u001b[39;49;00m i % \u001b[34m100\u001b[39;49;00m == \u001b[34m0\u001b[39;49;00m:\n",
      "                \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\r\u001b[39;49;00m\u001b[33mTraining batch \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(i, train_batches ), end=\u001b[33m'\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, flush=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\n",
      "            inputs, labels = data\n",
      "\n",
      "            \u001b[34mif\u001b[39;49;00m use_gpu:\n",
      "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
      "            \u001b[34melse\u001b[39;49;00m:\n",
      "                inputs, labels = Variable(inputs), Variable(labels)\n",
      "\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            outputs = vgg(inputs)\n",
      "\n",
      "            _, preds = torch.max(outputs.data, \u001b[34m1\u001b[39;49;00m)\n",
      "            loss = criterion(outputs, labels)\n",
      "\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "\n",
      "            loss_train += loss.data\n",
      "            acc_train += torch.sum(preds == labels.data)\n",
      "\n",
      "            \u001b[34mdel\u001b[39;49;00m inputs, labels, outputs, preds\n",
      "            torch.cuda.empty_cache()\n",
      "\n",
      "        \u001b[36mprint\u001b[39;49;00m()\n",
      "\n",
      "        avg_loss = torch.true_divide(loss_train, dataset_sizes[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "        avg_acc = torch.true_divide(acc_train, dataset_sizes[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "        vgg.train(\u001b[34mFalse\u001b[39;49;00m)\n",
      "        vgg.eval()\n",
      "\n",
      "        \u001b[34mfor\u001b[39;49;00m i, data \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(dataloaders[\u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]):\n",
      "            \u001b[34mif\u001b[39;49;00m i % \u001b[34m100\u001b[39;49;00m == \u001b[34m0\u001b[39;49;00m:\n",
      "                \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\r\u001b[39;49;00m\u001b[33mValidation batch \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(i, val_batches), end=\u001b[33m'\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, flush=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "            inputs, labels = data\n",
      "\n",
      "            \u001b[34mif\u001b[39;49;00m use_gpu:\n",
      "                inputs, labels = Variable(inputs.cuda(), volatile=\u001b[34mTrue\u001b[39;49;00m), Variable(labels.cuda(), volatile=\u001b[34mTrue\u001b[39;49;00m)\n",
      "            \u001b[34melse\u001b[39;49;00m:\n",
      "                inputs, labels = Variable(inputs, volatile=\u001b[34mTrue\u001b[39;49;00m), Variable(labels, volatile=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            outputs = vgg(inputs)\n",
      "\n",
      "            _, preds = torch.max(outputs.data, \u001b[34m1\u001b[39;49;00m)\n",
      "            loss = criterion(outputs, labels)\n",
      "\n",
      "            loss_val += loss.data\n",
      "            acc_val += torch.sum(preds == labels.data)\n",
      "\n",
      "            \u001b[34mdel\u001b[39;49;00m inputs, labels, outputs, preds\n",
      "            torch.cuda.empty_cache()\n",
      "\n",
      "        avg_loss_val = torch.true_divide(loss_val, dataset_sizes[\u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "        avg_acc_val = torch.true_divide(acc_val, dataset_sizes[\u001b[33m'\u001b[39;49;00m\u001b[33mval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "        \u001b[36mprint\u001b[39;49;00m()\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m result: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch))\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mAvg loss (train): \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(avg_loss))\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mAvg acc (train): \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(avg_acc))\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mAvg loss (val): \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(avg_loss_val))\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mAvg acc (val): \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(avg_acc_val))\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m * \u001b[34m10\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m()\n",
      "\n",
      "        \u001b[34mif\u001b[39;49;00m avg_acc_val > best_acc:\n",
      "            best_acc = avg_acc_val\n",
      "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
      "\n",
      "    elapsed_time = time.time() - since\n",
      "    \u001b[36mprint\u001b[39;49;00m()\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mTraining completed in \u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33mm \u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(elapsed_time // \u001b[34m60\u001b[39;49;00m, elapsed_time % \u001b[34m60\u001b[39;49;00m))\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mBest acc: \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(best_acc))\n",
      "\n",
      "    vgg.load_state_dict(best_model_wts)\n",
      "    \u001b[34mreturn\u001b[39;49;00m vgg\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    \u001b[37m# All of the model parameters and training parameters are sent as arguments\u001b[39;49;00m\n",
      "    \u001b[37m# when this script is executed, during a training job\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m# Here we set up an argument parser to easily access the parameters\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# SageMaker parameters, like the directories for training data and saving models; set automatically\u001b[39;49;00m\n",
      "    \u001b[37m# Do not need to change\u001b[39;49;00m\n",
      "\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Training Parameters, given\u001b[39;49;00m\n",
      "\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--img-width\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m256\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mwidth of image (default: 256)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--img-height\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m256\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mheight of image (default: 256)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m8\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for training (default: 8)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m15\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 15)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.001\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mlearning rate (default: 0.001)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[37m# set the seed for generating random numbers\u001b[39;49;00m\n",
      "    torch.manual_seed(args.seed)\n",
      "    \u001b[34mif\u001b[39;49;00m torch.cuda.is_available():\n",
      "        torch.cuda.manual_seed(args.seed)\n",
      "        \n",
      "    \u001b[37m# get train loader\u001b[39;49;00m\n",
      "    \u001b[37m#train_loader = _get_train_loader(args.batch_size, args.data_dir) # data_dir from above..\u001b[39;49;00m\n",
      "\n",
      "    dataloaders, dataset_sizes, class_names = get_data_loaders(img_dir=args.data_dir, img_width=args.img_width, img_height=args.img_height, batch_size=args.batch_size )\n",
      "\n",
      "    \u001b[37m# To get params from the parser, call args.argument_name, ex. args.epochs or ards.hidden_dim\u001b[39;49;00m\n",
      "    \u001b[37m# Don't forget to move your model .to(device) to move to GPU , if appropriate\u001b[39;49;00m\n",
      "\n",
      "    model = VGGLP(\u001b[36mlen\u001b[39;49;00m(class_names))\n",
      "    \u001b[34mif\u001b[39;49;00m torch.cuda.is_available():\n",
      "        model.cuda()\n",
      "\n",
      "\n",
      "\n",
      "    optimizer_ft = optim.SGD(model.parameters(), lr=args.lr, momentum=\u001b[34m0.9\u001b[39;49;00m)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \u001b[37m#optimizer_ft = optim.Adam(model.parameters(), lr=args.lr)\u001b[39;49;00m\n",
      "    \u001b[37m#criterion = nn.BCELoss()\u001b[39;49;00m\n",
      "\n",
      "\n",
      "    model = train_model(model, dataloaders, dataset_sizes, criterion, optimizer_ft, num_epochs=args.epochs)\n",
      "    save_model(model, args.model_dir)\n",
      "\n",
      "    \u001b[37m# Given: save the parameters used to construct the model\u001b[39;49;00m\n",
      "    save_model_params(num_classes=\u001b[36mlen\u001b[39;49;00m(class_names))\n",
      "\n",
      "\n",
      "    \n",
      "    \u001b[37m# Trains the model (given line of code, which calls the above training function)\u001b[39;49;00m\n",
      "    \u001b[37m# This function *also* saves the model state dictionary\u001b[39;49;00m\n",
      "    \u001b[37m#train(model, train_loader, args.epochs, optimizer, criterion, device)\u001b[39;49;00m\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "!pygmentize letsplay_classifier/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### EXERCISE: Create a PyTorch Estimator\n",
    "\n",
    "You've had some practice instantiating built-in models in SageMaker. All estimators require some constructor arguments to be passed in. When a custom model is constructed in SageMaker, an **entry point** must be specified. The entry_point is the training script that will be executed when the model is trained; the `train.py` function you specified above! \n",
    "\n",
    "See if you can complete this task, instantiating a PyTorch estimator, using only the [PyTorch estimator documentation](https://sagemaker.readthedocs.io/en/stable/sagemaker.pytorch.html) as a resource. It is suggested that you use the **latest version** of PyTorch as the optional `framework_version` parameter.\n",
    "\n",
    "#### Instance Types\n",
    "\n",
    "It is suggested that you use instances that are available in the free tier of usage: `'ml.c4.xlarge'` for training and `'ml.t2.medium'` for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "# prefix is specified above\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='letsplay_classifier', # this should be just \"source\" for your code\n",
    "                    role=role,\n",
    "                    framework_version='1.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c4.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'img-width': 128,\n",
    "                        'img-height': 72,\n",
    "                        'batch-size': 16,\n",
    "                        'epochs': 10\n",
    "'\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sagemaker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ffc9eedaeaa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import a PyTorch wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# specify an output path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# prefix is specified above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sagemaker'"
     ]
    }
   ],
   "source": [
    "## Train the Estimator\n",
    "\n",
    "After instantiating your estimator, train it with a call to `.fit()`. The `train.py` file explicitly loads in `.csv` data, so you do not need to convert the input data to any other format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Estimator\n",
    "\n",
    "After instantiating your estimator, train it with a call to `.fit()`. The `train.py` file explicitly loads in `.csv` data, so you do not need to convert the input data to any other format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-pytorch-2019-03-12-03-20-56-668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-12 03:20:56 Starting - Starting the training job...\n",
      "2019-03-12 03:21:00 Starting - Launching requested ML instances......\n",
      "2019-03-12 03:22:00 Starting - Preparing the instances for training......\n",
      "2019-03-12 03:23:24 Downloading - Downloading input data\n",
      "2019-03-12 03:23:24 Training - Training image download completed. Training in progress.\n",
      "2019-03-12 03:23:24 Uploading - Uploading generated training model\n",
      "\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-03-12 03:23:14,349 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-03-12 03:23:14,352 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-03-12 03:23:14,368 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-03-12 03:23:15,772 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-03-12 03:23:16,040 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-03-12 03:23:16,040 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-03-12 03:23:16,040 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-03-12 03:23:16,040 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wii_guhj/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built train\u001b[0m\n",
      "\u001b[31mInstalling collected packages: train\u001b[0m\n",
      "\u001b[31mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.0.3 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-03-12 03:23:17,599 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-03-12 03:23:17,612 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"input_dim\": 2,\n",
      "        \"hidden_dim\": 20,\n",
      "        \"epochs\": 80,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2019-03-12-03-20-56-668\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-1-467380521728/sagemaker-pytorch-2019-03-12-03-20-56-668/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"ethwe\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=ethwe\u001b[0m\n",
      "\u001b[31mSM_HPS={\"epochs\":80,\"hidden_dim\":20,\"input_dim\":2,\"output_dim\":1}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-west-1-467380521728/sagemaker-pytorch-2019-03-12-03-20-56-668/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":80,\"hidden_dim\":20,\"input_dim\":2,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-03-12-03-20-56-668\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-1-467380521728/sagemaker-pytorch-2019-03-12-03-20-56-668/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"ethwe\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--epochs\",\"80\",\"--hidden_dim\",\"20\",\"--input_dim\",\"2\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_INPUT_DIM=2\u001b[0m\n",
      "\u001b[31mSM_HP_HIDDEN_DIM=20\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=80\u001b[0m\n",
      "\u001b[31mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train --epochs 80 --hidden_dim 20 --input_dim 2 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mGet data loader.\u001b[0m\n",
      "\u001b[31mEpoch: 1, Loss: 0.8094824403524399\u001b[0m\n",
      "\u001b[31mEpoch: 2, Loss: 0.8087087497115135\u001b[0m\n",
      "\u001b[31mEpoch: 3, Loss: 0.81452776491642\u001b[0m\n",
      "\u001b[31mEpoch: 4, Loss: 0.7784294486045837\u001b[0m\n",
      "\u001b[31mEpoch: 5, Loss: 0.7738661542534828\u001b[0m\n",
      "\u001b[31mEpoch: 6, Loss: 0.7469970062375069\u001b[0m\n",
      "\u001b[31mEpoch: 7, Loss: 0.7502057999372482\u001b[0m\n",
      "\u001b[31mEpoch: 8, Loss: 0.7338991761207581\u001b[0m\n",
      "\u001b[31mEpoch: 9, Loss: 0.7060637846589088\u001b[0m\n",
      "\u001b[31mEpoch: 10, Loss: 0.70991051197052\u001b[0m\n",
      "\u001b[31mEpoch: 11, Loss: 0.6829910576343536\u001b[0m\n",
      "\u001b[31mEpoch: 12, Loss: 0.6872642189264297\u001b[0m\n",
      "\u001b[31mEpoch: 13, Loss: 0.6796583235263824\u001b[0m\n",
      "\u001b[31mEpoch: 14, Loss: 0.6750186383724213\u001b[0m\n",
      "\u001b[31mEpoch: 15, Loss: 0.6474509462714195\u001b[0m\n",
      "\u001b[31mEpoch: 16, Loss: 0.6489695161581039\u001b[0m\n",
      "\u001b[31mEpoch: 17, Loss: 0.6278565004467964\u001b[0m\n",
      "\u001b[31mEpoch: 18, Loss: 0.6373456940054893\u001b[0m\n",
      "\u001b[31mEpoch: 19, Loss: 0.6274193376302719\u001b[0m\n",
      "\u001b[31mEpoch: 20, Loss: 0.6120161935687065\u001b[0m\n",
      "\u001b[31mEpoch: 21, Loss: 0.6031808331608772\u001b[0m\n",
      "\u001b[31mEpoch: 22, Loss: 0.5973624065518379\u001b[0m\n",
      "\u001b[31mEpoch: 23, Loss: 0.5929201915860176\u001b[0m\n",
      "\u001b[31mEpoch: 24, Loss: 0.5777265653014183\u001b[0m\n",
      "\u001b[31mEpoch: 25, Loss: 0.58209378272295\u001b[0m\n",
      "\u001b[31mEpoch: 26, Loss: 0.5992862954735756\u001b[0m\n",
      "\u001b[31mEpoch: 27, Loss: 0.5764492303133011\u001b[0m\n",
      "\u001b[31mEpoch: 28, Loss: 0.5612449124455452\u001b[0m\n",
      "\u001b[31mEpoch: 29, Loss: 0.5468951836228371\u001b[0m\n",
      "\u001b[31mEpoch: 30, Loss: 0.5476799719035625\u001b[0m\n",
      "\u001b[31mEpoch: 31, Loss: 0.5541884526610374\u001b[0m\n",
      "\u001b[31mEpoch: 32, Loss: 0.5619134604930878\u001b[0m\n",
      "\u001b[31mEpoch: 33, Loss: 0.5442568808794022\u001b[0m\n",
      "\u001b[31mEpoch: 34, Loss: 0.5280377380549908\u001b[0m\n",
      "\u001b[31mEpoch: 35, Loss: 0.5323713757097721\u001b[0m\n",
      "\u001b[31mEpoch: 36, Loss: 0.5295680649578571\u001b[0m\n",
      "\u001b[31mEpoch: 37, Loss: 0.5200584568083286\u001b[0m\n",
      "\u001b[31mEpoch: 38, Loss: 0.5405271053314209\u001b[0m\n",
      "\u001b[31mEpoch: 39, Loss: 0.526910662651062\u001b[0m\n",
      "\u001b[31mEpoch: 40, Loss: 0.517667829990387\u001b[0m\n",
      "\u001b[31mEpoch: 41, Loss: 0.5065649971365929\u001b[0m\n",
      "\u001b[31mEpoch: 42, Loss: 0.5186041817069054\u001b[0m\n",
      "\u001b[31mEpoch: 43, Loss: 0.48348696157336235\u001b[0m\n",
      "\u001b[31mEpoch: 44, Loss: 0.4920388348400593\u001b[0m\n",
      "\u001b[31mEpoch: 45, Loss: 0.48314499482512474\u001b[0m\n",
      "\u001b[31mEpoch: 46, Loss: 0.4986172467470169\u001b[0m\n",
      "\u001b[31mEpoch: 47, Loss: 0.4838500805199146\u001b[0m\n",
      "\u001b[31mEpoch: 48, Loss: 0.5062692202627659\u001b[0m\n",
      "\u001b[31mEpoch: 49, Loss: 0.4790864698588848\u001b[0m\n",
      "\u001b[31mEpoch: 50, Loss: 0.4843643642961979\u001b[0m\n",
      "\u001b[31mEpoch: 51, Loss: 0.48715561255812645\u001b[0m\n",
      "\u001b[31mEpoch: 52, Loss: 0.4674951285123825\u001b[0m\n",
      "\u001b[31mEpoch: 53, Loss: 0.4855138994753361\u001b[0m\n",
      "\u001b[31mEpoch: 54, Loss: 0.4692947752773762\u001b[0m\n",
      "\u001b[31mEpoch: 55, Loss: 0.47163090109825134\u001b[0m\n",
      "\u001b[31mEpoch: 56, Loss: 0.46736880764365196\u001b[0m\n",
      "\u001b[31mEpoch: 57, Loss: 0.4675491377711296\u001b[0m\n",
      "\u001b[31mEpoch: 58, Loss: 0.4782943092286587\u001b[0m\n",
      "\u001b[31mEpoch: 59, Loss: 0.45643892511725426\u001b[0m\n",
      "\u001b[31mEpoch: 60, Loss: 0.46863533183932304\u001b[0m\n",
      "\u001b[31mEpoch: 61, Loss: 0.46333420276641846\u001b[0m\n",
      "\u001b[31mEpoch: 62, Loss: 0.48059647530317307\u001b[0m\n",
      "\u001b[31mEpoch: 63, Loss: 0.45397504046559334\u001b[0m\n",
      "\u001b[31mEpoch: 64, Loss: 0.45192109420895576\u001b[0m\n",
      "\u001b[31mEpoch: 65, Loss: 0.46614759787917137\u001b[0m\n",
      "\u001b[31mEpoch: 66, Loss: 0.4529973901808262\u001b[0m\n",
      "\u001b[31mEpoch: 67, Loss: 0.4322005622088909\u001b[0m\n",
      "\u001b[31mEpoch: 68, Loss: 0.44345563650131226\u001b[0m\n",
      "\u001b[31mEpoch: 69, Loss: 0.44864876195788383\u001b[0m\n",
      "\u001b[31mEpoch: 70, Loss: 0.4391746446490288\u001b[0m\n",
      "\u001b[31mEpoch: 71, Loss: 0.4342072270810604\u001b[0m\n",
      "\u001b[31mEpoch: 72, Loss: 0.4262286312878132\u001b[0m\n",
      "\u001b[31mEpoch: 73, Loss: 0.4268296808004379\u001b[0m\n",
      "\u001b[31mEpoch: 74, Loss: 0.4437255598604679\u001b[0m\n",
      "\u001b[31mEpoch: 75, Loss: 0.43882467597723007\u001b[0m\n",
      "\u001b[31mEpoch: 76, Loss: 0.44645144790410995\u001b[0m\n",
      "\u001b[31mEpoch: 77, Loss: 0.4345819540321827\u001b[0m\n",
      "\u001b[31mEpoch: 78, Loss: 0.4224093407392502\u001b[0m\n",
      "\u001b[31mEpoch: 79, Loss: 0.4226452559232712\u001b[0m\n",
      "\u001b[31mEpoch: 80, Loss: 0.42246998474001884\u001b[0m\n",
      "\u001b[31mSaving the model.\u001b[0m\n",
      "\u001b[31m2019-03-12 03:23:19,489 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-03-12 03:23:29 Completed - Training job completed\n",
      "Billable seconds: 30\n",
      "CPU times: user 431 ms, sys: 20.8 ms, total: 451 ms\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# train the estimator on S3 training data\n",
    "estimator.fit({'train': input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Trained Model\n",
    "\n",
    "PyTorch models do not automatically come with `.predict()` functions attached (as many Scikit-learn models do, for example) and you may have noticed that you've been give a `predict.py` file. This file is responsible for loading a trained model and applying it to passed in, numpy data. When you created a PyTorch estimator, you specified where the training script, `train.py` was located. \n",
    "\n",
    "> How can we tell a PyTorch model where the `predict.py` file is?\n",
    "\n",
    "Before you can deploy this custom PyTorch model, you have to take one more step: creating a `PyTorchModel`. In earlier exercises you could see that a call to `.deploy()` created both a **model** and an **endpoint**, but for PyTorch models, these steps have to be separate.\n",
    "\n",
    "### EXERCISE: Instantiate a `PyTorchModel`\n",
    "\n",
    "You can create a `PyTorchModel` (different that a PyTorch estimator) from your trained, estimator attributes. This model is responsible for knowing how to execute a specific `predict.py` script. And this model is what you'll deploy to create an endpoint.\n",
    "\n",
    "#### Model Parameters\n",
    "\n",
    "To instantiate a `PyTorchModel`, ([documentation, here](https://sagemaker.readthedocs.io/en/stable/sagemaker.pytorch.html#sagemaker.pytorch.model.PyTorchModel)) you pass in the same arguments as your PyTorch estimator, with a few additions/modifications:\n",
    "* **model_data**: The trained `model.tar.gz` file created by your estimator, which can be accessed as `estimator.model_data`.\n",
    "* **entry_point**: This time, this is the path to the Python script SageMaker runs for **prediction** rather than training, `predict.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing PyTorchModel\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.0',\n",
    "                     entry_point='predict_fromfile.py',\n",
    "                     source_dir='letsplay_classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Deploy the trained model\n",
    "\n",
    "Deploy your model to create a predictor. We'll use this to make predictions on our test data and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-pytorch-2019-03-12-03-24-09-384\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-pytorch-2019-03-12-03-24-09-384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------!CPU times: user 591 ms, sys: 62.9 ms, total: 654 ms\n",
      "Wall time: 7min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# deploy and create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_fromfile import model_fn, predict_fn, input_fn, output_fn\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "index = 0\n",
    "loss_test = 0\n",
    "acc_test = 0\n",
    "count = 0\n",
    "cur_data_dir = 'wendy_cnn_frames_data'\n",
    "dirs = sorted(os.listdir(cur_data_dir))\n",
    "for dir in dirs:\n",
    "    labels = torch.empty(1, dtype=int)\n",
    "    labels[0] = index\n",
    "    print(labels)\n",
    "    curr_img_dir = os.path.join(args.data_dir, dir)\n",
    "    images = os.listdir(curr_img_dir)\n",
    "    for image in images:\n",
    "        curr_img = os.path.join(curr_img_dir, image)\n",
    "\n",
    "        with open(curr_img, 'rb') as f:\n",
    "            image_data = Image.open(f)\n",
    "           \n",
    "            prediction_from_ep = predictor.predict(image_data)  \n",
    "            prediction = torch.FloatTensor(prediction_from_ep).unsqueeze(0)\n",
    "\n",
    "            _, preds = torch.max(prediction.data, 1)\n",
    "            loss = criterion(prediction, labels)\n",
    "\n",
    "            loss_test += loss.data\n",
    "            acc_test += torch.sum(preds == labels.data)\n",
    "            count += 1\n",
    "            avg_loss = torch.true_divide(loss_test, count)\n",
    "            avg_acc = torch.true_divide(acc_test, count)\n",
    "            print(\"{} processed\".format(count))\n",
    "            print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n",
    "            print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluating Your Model\n",
    "\n",
    "Once your model is deployed, you can see how it performs when applied to the test data.\n",
    "\n",
    "The provided function below, takes in a deployed predictor, some test features and labels, and returns a dictionary of metrics; calculating false negatives and positives as well as recall, precision, and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from letsplay_classifiers.train import get_data_loaders\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def eval_predictor(predictor, dataloaders):\n",
    "    \n",
    "    test_batches = len(dataloaders['val'])\n",
    "    print(\"Evaluating model\")\n",
    "    print('-' * 10)\n",
    "\n",
    "    for i, data in enumerate(dataloaders['val']):\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "\n",
    "\n",
    "dataloaders, dataset_sizes, class_names = get_data_loaders(\n",
    "    img_dir='wendy-cnn-data', 256, 256, 8 )\n",
    "\n",
    "eval_predictor(predictor) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results\n",
    "\n",
    "The cell below runs the `evaluate` function. \n",
    "\n",
    "The code assumes that you have a defined `predictor` and `X_test` and `Y_test` from previously-run cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions  0.0  1.0\n",
      "actuals              \n",
      "0             53   18\n",
      "1             11   68\n",
      "\n",
      "Recall:     0.861\n",
      "Precision:  0.791\n",
      "Accuracy:   0.807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get metrics for custom predictor\n",
    "metrics = evaluate(predictor, X_test, Y_test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Endpoint\n",
    "\n",
    "Finally, I've add a convenience function to delete prediction endpoints after we're done with them. And if you're done evaluating the model, you should delete your model endpoint!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a predictor endpoint as input\n",
    "# And deletes the endpoint by name\n",
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2019-03-12-03-24-09-384\n"
     ]
    }
   ],
   "source": [
    "# delete the predictor endpoint \n",
    "delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Cleanup!\n",
    "\n",
    "* Double check that you have deleted all your endpoints.\n",
    "* I'd also suggest manually deleting your S3 bucket, models, and endpoint configurations directly from your AWS console.\n",
    "\n",
    "You can find thorough cleanup instructions, [in the documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Conclusion\n",
    "\n",
    "In this notebook, you saw how to train and deploy a custom, PyTorch model in SageMaker. SageMaker has many built-in models that are useful for common clustering and classification tasks, but it is useful to know how to create custom, deep learning models that are flexible enough to learn from a variety of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
