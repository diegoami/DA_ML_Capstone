/home/diego/anaconda3/envs/cnn-wendy/bin/python /home/diego/projects/DA_ML_Capstone/letsplay_classifier/driver.py --img-width=64 --img-height=64 --batch-size=32
Loading model.
model_info: {'num_classes': 8, 'img_width': 64, 'img_height': 64}
Done loading model.
Evaluating model
----------
Test batch 0/358torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
/home/diego/projects/DA_ML_Capstone/letsplay_classifier/driver.py:36: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)
tensor([[ -3.7789,  -7.3143,  16.2968, -10.3733,   3.2332,   0.6679,   4.6369,
          -2.8380],
        [  0.5653,  -4.5944,   3.8928,  -4.6929,  13.7102,  -4.5578,  -0.4134,
          -3.1860],
        [ -2.0001,  -4.3537,   3.8680,  -5.5043,  21.0035,  -7.3395,  -0.4260,
          -4.2129],
        [ -2.4697,  -7.1379,  16.8343, -10.5724,   2.9041,   0.5764,   3.6737,
          -3.1260],
        [ -2.6427,  15.5681,  -2.6577,   2.5992,  -4.9406,  -4.9400,  -6.5137,
           3.9001],
        [ -2.3899,  -6.3009,  14.6612,  -7.8622,   2.7487,   1.4354,   1.5326,
          -2.7840],
        [ -0.9276,  -7.8219,  14.7141,  -9.3225,   2.3700,   2.2523,   1.9329,
          -3.0288],
        [ 11.3646,  -4.0498,   4.4024,  -1.0430,  -3.3689,  -1.7951,  -4.6356,
          -2.3749],
        [ -1.7863,  -7.9515,  15.6059,  -9.5907,   3.2933,   2.3025,   0.9187,
          -2.0102],
        [ -3.9065,  -1.9165,   2.7719,  -3.9016,   8.4299,  -2.3535,   0.8312,
           0.3634],
        [ -3.2805,  -6.9624,  17.1616, -10.9697,   3.0547,   0.4109,   4.1521,
          -2.9513],
        [ -1.9537,  11.9832,  -1.9602,   1.5659,  -4.5073,  -3.4648,  -5.3240,
           3.9073],
        [ 13.3501,  -3.2767,   4.2270,  -3.2504,  -2.7665,  -2.9034,  -3.7102,
          -3.0976],
        [ -3.6697,  -7.4242,  16.8602, -10.5044,   3.8391,   0.2876,   4.4481,
          -3.1809],
        [ -3.8109,  -6.5137,  15.2338, -10.1393,   2.5635,   0.0907,   5.4062,
          -2.4022],
        [ -5.5574,  -4.6824,  13.0548,  -8.3777,   3.4456,   0.1084,   3.8015,
          -1.4960],
        [ -4.0681,  -7.9046,  17.2641, -10.8363,   3.8310,   0.4601,   4.6125,
          -3.1371],
        [ -1.1331,  -7.4781,   5.2362,  -6.6838,  22.1608,  -7.4993,   1.5627,
          -5.3415],
        [ -1.1240,  -7.1402,  15.6300,  -8.8429,   2.7598,   1.7168,   1.0573,
          -3.3402],
        [ -6.4929,  -4.4197,  17.6230, -11.6264,   6.6328,  -1.4009,   1.3722,
          -1.9775],
        [ -4.6890,  -7.4797,  17.6552, -11.0778,   3.9647,   0.3636,   5.1510,
          -2.9580],
        [ -2.3579,  -6.0032,  12.7693,  -7.2782,   2.6687,   2.1037,   0.7977,
          -1.9835],
        [ -3.3704,  -6.5594,  16.4091, -10.4087,   3.3723,   0.3619,   3.4348,
          -2.6800],
        [  7.3144,  -2.9869,   2.2125,  -2.4371,  -1.2925,   0.5276,  -3.4541,
          -0.5237],
        [ -1.2722,  -1.8426,   9.0293,  -4.3981,   1.9662,  -0.4337,  -0.8936,
          -1.7600],
        [ -2.3762,  -4.6213,   3.5214,  -4.7885,  19.8051,  -7.1600,   0.7466,
          -4.2218],
        [ -2.6628,  -6.0038,   4.4333,  -5.9664,  24.0898,  -8.2375,   0.1974,
          -4.6792],
        [ -0.8151,  -4.9803,   3.8741,  -4.8887,  18.9255,  -6.4188,  -0.7810,
          -4.0441],
        [ -4.0637,  -4.8059,  11.7488,  -8.4148,   3.0385,  -0.7194,   4.8032,
          -1.4332],
        [ 11.4876,   1.7618,   2.9327,  -0.0336,  -6.0580,  -3.3391,  -6.3719,
          -1.7290],
        [ -1.7571,  -7.3234,  15.9871,  -8.6053,   2.8145,   1.7674,   1.3074,
          -3.2678],
        [ -3.2507,  -8.4048,  17.7300, -10.9980,   3.8412,   0.6718,   4.1355,
          -3.4740]], device='cuda:0', grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 4, 4, 2, 1, 2, 2, 0, 2, 4, 2, 1, 0, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 0,
        2, 4, 4, 4, 2, 0, 2, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-2.7179e+00,  1.6578e-02,  1.3008e+00, -3.2806e+00,  1.6713e+01,
         -6.8443e+00, -2.7293e+00, -1.8965e+00],
        [-7.4586e-01, -3.9712e+00,  8.1314e+00, -4.5978e+00,  2.3505e+00,
         -3.4219e-01,  1.6586e+00, -2.3124e+00],
        [-2.1756e+00, -6.9603e+00,  1.5945e+01, -8.4758e+00,  3.1083e+00,
          1.5456e+00,  1.3142e+00, -3.1371e+00],
        [-3.2179e+00, -7.2339e+00,  1.4033e+01, -7.7857e+00,  3.4386e+00,
          9.6178e-01,  3.8638e+00, -3.0627e+00],
        [-6.0033e+00, -7.3060e+00,  1.7433e+01, -1.1484e+01,  6.3237e+00,
         -3.0862e-01,  4.4260e+00, -2.8732e+00],
        [-1.7234e+00, -5.3878e+00,  1.3963e+01, -7.5049e+00,  3.3629e+00,
          8.4666e-01, -6.5855e-02, -2.8601e+00],
        [-3.4219e+00, -7.2313e+00,  1.5559e+01, -9.7997e+00,  3.0407e+00,
          2.7517e-01,  5.2978e+00, -2.9489e+00],
        [-3.8261e+00, -8.5387e+00,  1.7043e+01, -1.0659e+01,  3.5802e+00,
          2.4882e+00,  2.8684e+00, -2.1304e+00],
        [ 1.2289e+01, -1.5052e+00,  4.1023e+00, -2.9416e+00, -4.5477e+00,
         -2.3138e+00, -4.2353e+00, -2.1709e+00],
        [-2.1125e+00, -2.8683e+00,  5.8453e+00, -3.0974e+00,  3.8918e+00,
         -1.1380e+00,  1.5959e+00, -1.6796e+00],
        [ 9.9069e+00, -4.0502e+00,  3.7227e+00, -3.0236e+00, -1.5255e+00,
         -6.8554e-01, -3.5370e+00, -1.8070e+00],
        [-1.7945e+00, -2.5206e+00,  3.1600e+00, -2.1250e+00,  4.2099e+00,
         -1.5954e+00,  2.4122e+00, -1.3901e+00],
        [-9.5480e-01, -5.2792e+00,  1.0299e+01, -6.2082e+00,  3.1478e+00,
          1.8798e+00, -5.2524e-01, -1.8292e+00],
        [-4.2359e+00, -6.5865e+00,  1.4510e+01, -8.8817e+00,  2.9810e+00,
          8.2267e-01,  4.8499e+00, -2.5057e+00],
        [-2.8813e+00, -4.4647e+00,  1.4626e+01, -9.9970e+00,  3.8715e+00,
         -1.1288e+00,  2.1264e+00, -2.2989e+00],
        [-1.9778e+00, -2.8404e+00,  5.1341e+00, -2.8445e+00,  3.0154e+00,
         -9.3023e-01,  2.4630e+00, -1.5355e+00],
        [-2.1846e+00, -2.9351e+00,  4.6076e+00, -2.7492e+00,  2.5905e+00,
         -8.8818e-01,  3.4713e+00, -1.4337e+00],
        [-2.9751e+00, -6.3840e+00,  1.2711e+01, -7.1309e+00,  3.5780e+00,
          4.7065e-01,  3.5568e+00, -2.8077e+00],
        [-1.8195e+00, -4.8102e+00,  3.9457e+00, -5.2886e+00,  1.8500e+01,
         -6.5895e+00,  1.0318e+00, -3.8107e+00],
        [-1.3601e+00, -2.2747e+00,  9.3933e+00, -4.3757e+00,  2.1148e+00,
         -3.4055e-01, -9.9082e-01, -1.9530e+00],
        [-3.5150e+00, -2.7947e+00,  1.1343e+01, -6.1976e+00,  2.0071e+00,
          7.3598e-01, -1.0309e+00, -4.6305e-01],
        [-3.8336e+00, -6.1125e+00,  1.7214e+01, -1.0873e+01,  3.9748e+00,
         -5.9676e-02,  2.7060e+00, -2.7340e+00],
        [ 1.3471e+01, -5.0455e+00,  4.8360e+00, -3.7423e+00, -7.2926e-01,
         -2.2684e+00, -4.7246e+00, -3.3062e+00],
        [-3.1347e+00, -4.0341e+00,  3.4860e+00, -5.2763e+00,  1.9650e+01,
         -6.9235e+00,  9.4753e-01, -3.5943e+00],
        [-5.2889e+00, -6.3941e+00,  1.5948e+01, -1.0082e+01,  4.8841e+00,
         -2.4512e-01,  4.3100e+00, -2.8624e+00],
        [ 4.9744e-01, -4.1317e+00,  4.2477e+00, -3.9014e+00, -9.6184e-01,
          4.1021e+00, -8.6260e-01,  9.0170e-01],
        [-3.2067e+00, -7.6629e+00,  1.7570e+01, -1.1006e+01,  3.0640e+00,
          2.4840e+00,  1.3351e+00, -1.9458e+00],
        [-1.8364e+00, -5.3686e+00,  1.4427e+01, -7.7063e+00,  2.9405e+00,
          1.1110e+00, -7.4256e-02, -2.8212e+00],
        [-6.5295e+00, -6.0208e+00,  1.7132e+01, -1.1523e+01,  6.5937e+00,
         -6.9928e-01,  3.5202e+00, -2.2496e+00],
        [ 7.8419e+00, -2.0131e+00,  3.1818e+00, -3.0768e+00, -3.7279e+00,
         -1.4717e+00, -1.0570e+00, -6.2580e-01],
        [-6.5390e-01, -2.8192e+00,  8.3120e+00, -4.6482e+00,  1.4319e+00,
          8.4370e-02,  2.7870e-01, -1.6244e+00],
        [-3.9539e+00, -5.2703e+00,  5.4556e+00, -5.3474e+00,  4.7682e-01,
         -2.0188e+00,  1.3214e+01, -1.4649e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([4, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 0, 4,
        2, 2, 2, 2, 2, 0, 2, 6], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-6.3304e+00, -7.3284e+00,  1.6826e+01, -1.1307e+01,  5.0828e+00,
          4.0707e-01,  5.4347e+00, -1.8648e+00],
        [-1.1824e+00, -3.8966e+00,  1.0831e+01, -6.4621e+00,  1.2320e+00,
         -3.7280e-01,  2.5920e+00, -2.1885e+00],
        [-3.2051e+00, -5.8676e+00,  1.5920e+01, -1.0381e+01,  3.5203e+00,
         -8.7247e-02,  3.2072e+00, -2.7210e+00],
        [-2.8748e+00, -6.1379e+00,  1.2531e+01, -6.9026e+00,  3.4764e+00,
          4.7812e-01,  3.0403e+00, -2.6908e+00],
        [-1.4808e+00, -2.4509e+00,  8.8133e+00, -4.1770e+00,  2.2696e+00,
         -3.4765e-01, -4.7200e-01, -1.8552e+00],
        [-3.8532e-01, -7.6801e+00,  4.4440e+00, -5.8024e+00,  2.4286e+01,
         -8.2012e+00, -2.7859e-01, -5.5992e+00],
        [-3.5729e+00, -6.5552e+00,  6.3587e+00, -7.3534e+00,  2.4047e+01,
         -7.9875e+00,  1.3435e+00, -5.0868e+00],
        [-1.4453e+00, -6.4059e+00,  1.4738e+01, -9.2879e+00,  2.6800e+00,
          1.7741e+00, -4.3831e-01, -1.6135e+00],
        [-3.6085e+00, -7.7457e+00,  1.7085e+01, -1.0705e+01,  3.1037e+00,
          2.5543e-01,  5.7797e+00, -3.2648e+00],
        [ 1.1329e+01, -2.0136e+00,  3.0449e+00, -2.3890e+00, -2.2188e+00,
         -3.0818e+00, -2.9599e+00, -2.7051e+00],
        [ 6.7090e+00, -5.2202e-01,  2.4867e+00, -1.4863e+00, -1.5143e+00,
         -1.9842e+00, -2.4588e+00, -1.5665e+00],
        [-7.4125e+00, -5.5544e+00,  1.8546e+01, -1.2101e+01,  6.2293e+00,
         -6.5029e-01,  3.1196e+00, -1.9196e+00],
        [-1.5964e+00, -2.6353e+00,  8.2364e+00, -4.0286e+00,  2.8505e+00,
         -5.3542e-01, -8.7103e-02, -1.8914e+00],
        [-1.1958e+00, -6.4575e+00,  1.5160e+01, -9.1736e+00,  1.6519e+00,
          1.9377e+00,  1.0536e+00, -2.5105e+00],
        [-2.1789e+00, -2.9392e+00,  4.4878e+00, -2.7037e+00,  2.3426e+00,
         -8.2693e-01,  3.6601e+00, -1.3623e+00],
        [-1.8610e+00, -2.9011e+00,  4.6947e+00, -2.9936e+00,  7.2159e+00,
         -2.4125e+00,  8.0905e-01, -2.1396e+00],
        [-2.7755e+00, -6.6570e+00,  1.4026e+01, -8.7392e+00,  2.5332e+00,
          6.5874e-01,  3.9507e+00, -2.5146e+00],
        [-1.3164e+00, -5.5131e+00,  1.2104e+01, -7.8980e+00,  1.8941e+00,
          1.9998e+00,  2.7824e-01, -1.2219e+00],
        [-3.4828e+00, -6.1219e+00,  5.3307e+00, -6.2839e+00,  2.0620e+01,
         -6.8207e+00,  2.1467e+00, -4.1363e+00],
        [-1.2541e+00, -5.9843e+00,  1.1155e+01, -6.7482e+00,  3.3039e+00,
          8.4545e-01,  1.4335e+00, -2.4420e+00],
        [-2.4549e+00, -5.9062e+00,  1.3292e+01, -7.2497e+00,  3.4549e+00,
          1.3563e+00,  9.5561e-01, -2.6526e+00],
        [-4.8062e+00, -7.1251e+00,  1.6757e+01, -1.0716e+01,  4.5607e+00,
         -1.6971e-03,  5.0673e+00, -3.1304e+00],
        [-3.0361e+00, -3.9671e+00,  8.2966e+00, -6.6427e+00,  7.5793e+00,
         -2.0400e+00,  1.3280e+00, -1.1347e+00],
        [-3.4951e+00, -5.6048e+00,  1.4188e+01, -9.1940e+00,  3.7271e+00,
         -3.4171e-01,  3.6565e+00, -2.5770e+00],
        [-9.1580e-01, -5.2673e+00,  1.3976e+01, -7.4346e+00,  2.6041e+00,
          1.1326e+00, -6.8540e-01, -2.9233e+00],
        [-1.8192e+00, -2.6541e+00,  4.4356e+00, -2.6644e+00,  3.8338e+00,
         -1.3609e+00,  2.2720e+00, -1.6166e+00],
        [ 1.0194e+01, -4.3099e+00,  4.4834e+00, -2.7586e+00, -1.5059e+00,
         -9.6874e-01, -4.0300e+00, -2.4200e+00],
        [-8.0692e-01, -6.0749e+00,  1.3915e+01, -7.2982e+00,  1.9591e+00,
          1.3218e+00,  4.5619e-01, -2.9369e+00],
        [-6.2581e-01, -2.6746e+00,  7.9988e+00, -4.2036e+00,  1.5926e+00,
         -1.7932e-01, -6.0807e-03, -1.6227e+00],
        [-2.1722e+00, -4.1442e+00,  9.7927e+00, -5.4396e+00,  2.6091e+00,
         -2.1733e-01,  2.4423e+00, -2.2366e+00],
        [-2.7324e+00, -6.8390e+00,  1.7556e+01, -1.0655e+01,  2.7699e+00,
          1.1907e+00,  1.9259e+00, -2.7533e+00],
        [ 1.2850e+01, -4.7054e+00,  5.3322e+00, -3.1698e+00, -2.8643e+00,
         -2.0036e+00, -3.4445e+00, -3.0766e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 0, 2, 2, 2, 6, 4, 2, 2, 4, 2, 2, 2, 2, 2,
        2, 2, 0, 2, 2, 2, 2, 0], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[ -4.4196,  -7.1671,  16.2482, -10.5258,   3.9122,   0.3264,   5.0834,
          -2.7939],
        [ -2.2402,  -6.5161,  14.8962,  -8.0170,   2.8723,   1.5748,   1.3612,
          -2.8683],
        [ -6.8763,  -6.9522,  17.6739, -11.7728,   6.9513,  -0.5475,   4.0372,
          -2.3749],
        [ -2.6388,  -5.6085,  13.9886,  -9.2696,   1.5310,   0.4169,   4.0613,
          -1.9374],
        [ -2.7096,  -5.8072,  14.6137,  -9.2955,   2.5173,   0.2367,   3.4293,
          -2.2208],
        [ -2.7605,  -5.0382,  13.6210,  -9.0627,   2.1448,  -0.1425,   3.3702,
          -2.2745],
        [ -0.6315,  -6.8787,  13.5749,  -7.6849,   2.3620,   1.8121,   1.3769,
          -3.1400],
        [ -5.6279,  -6.2703,  14.3240,  -8.9929,   4.5571,   0.0487,   4.9801,
          -2.2515],
        [ -1.9218,  -7.2314,  15.7264,  -9.9775,   2.2086,   0.2028,   4.9523,
          -3.3666],
        [ -6.6966,  -6.0045,  15.6925, -10.4907,   7.0727,  -0.2582,   1.9981,
          -1.5013],
        [ -2.9867,  -6.2272,  12.1771,  -6.8476,   3.5083,   0.4895,   3.5021,
          -2.6790],
        [  0.1441,  -2.5082,   2.1522,  -3.3130,  15.3216,  -6.2545,  -1.8928,
          -3.3459],
        [ 13.8923,  -2.6331,   6.0281,  -4.8518,  -4.0601,  -2.3547,  -4.7050,
          -2.6864],
        [ -2.0325,  -7.3681,  14.8452,  -9.2819,   2.9719,   2.1385,   0.8082,
          -1.5968],
        [ -4.6151,  -7.3871,  17.9732, -11.5206,   3.7826,   0.1655,   5.4418,
          -3.0577],
        [ -5.1577,  -8.1308,  17.7784, -11.4125,   4.6551,   0.1287,   6.3156,
          -3.4883],
        [ -2.0922,   1.0407,  -2.7304,  12.6381,  -3.0736,  -3.8276,  -3.4530,
           0.5130],
        [ 13.4579,  -4.6740,   4.8138,  -3.4271,  -2.7493,  -1.9932,  -3.7443,
          -3.0507],
        [ -2.7732,  -3.9287,   3.6324,  -5.3476,  20.1460,  -6.9368,   0.4550,
          -3.8032],
        [ -1.1714,  -2.5925,   6.5277,  -4.7618,   4.3809,  -1.5431,   1.2451,
          -1.7480],
        [ 11.8244,  -3.3394,   5.0804,  -2.8082,  -3.1298,  -2.1873,  -3.5769,
          -2.9578],
        [ -0.9199,  -6.4613,  14.4541,  -8.4805,   2.0987,   1.7558,   1.0753,
          -2.9614],
        [ -2.7152,  -5.5350,   4.5741,  -5.7920,  18.7078,  -6.4155,   1.9132,
          -3.9518],
        [ -2.5372,  -4.1585,   8.7447,  -5.8169,   4.9922,  -0.6241,   1.0906,
          -1.5475],
        [ -0.3715,  -6.7002,   4.9528,  -5.8387,  13.8071,  -4.4428,   3.1205,
          -3.8230],
        [ -3.1813,  -1.8619,   9.6061,  -4.6443,   1.4036,   0.1561,  -1.0978,
          -0.2868],
        [  9.7655,  -4.7829,   4.7019,  -3.9358,  -1.4058,  -1.2175,  -1.3593,
          -2.4880],
        [ 11.7334,  -4.6937,   4.5746,  -3.3498,  -2.3471,  -0.9579,  -3.6995,
          -2.4627],
        [ -1.8150,  -7.2784,  15.7098,  -8.4854,   3.1040,   1.6876,   1.2381,
          -3.3040],
        [ -3.8530,  -4.1665,   4.0671,  -5.7885,  19.8092,  -7.0385,   1.7928,
          -3.7206],
        [ -3.8174,  -8.0792,  17.9951, -11.2757,   3.6614,   0.5315,   5.3679,
          -3.4346],
        [ -2.0801,  -6.7070,  14.2405,  -8.6944,   2.2214,   1.4228,   2.7164,
          -2.2586]], device='cuda:0', grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 0, 2, 2, 2, 3, 0, 4, 2, 0, 2, 4, 2,
        4, 2, 0, 0, 2, 4, 2, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[ 9.3713e+00, -3.2000e+00,  3.9184e+00, -2.5205e+00, -3.0808e+00,
         -2.0393e+00, -7.6545e-01, -2.5855e+00],
        [-4.4809e+00, -8.0265e+00,  1.7135e+01, -1.0782e+01,  4.5052e+00,
          3.4480e-01,  5.6520e+00, -3.4985e+00],
        [ 1.1788e+01, -4.9082e+00,  5.0554e+00, -3.9662e+00, -2.7802e+00,
         -7.9349e-01, -2.9276e+00, -2.5745e+00],
        [-2.7122e+00, -6.8439e+00,  1.3399e+01, -8.9808e+00,  1.4949e+00,
          7.0741e-01,  5.3331e+00, -1.9782e+00],
        [-1.9673e+00, -6.1030e+00,  1.4409e+01, -1.0537e+01,  3.7410e+00,
         -9.1420e-01,  4.0216e+00, -2.9662e+00],
        [ 2.3570e-01, -5.9482e+00,  1.2119e+01, -7.3390e+00,  5.6475e-01,
          2.8751e+00, -1.4514e-01, -2.0649e+00],
        [-3.7180e+00, -7.7241e+00,  1.7657e+01, -1.1111e+01,  3.2897e+00,
          5.5047e-01,  4.8790e+00, -3.3348e+00],
        [-2.1163e+00, -2.9522e+00,  4.0579e+00, -2.6109e+00,  2.2945e+00,
         -9.4807e-01,  4.0671e+00, -1.3135e+00],
        [-8.5735e-01, -6.8341e+00,  1.5117e+01, -8.4996e+00,  2.2247e+00,
          2.0693e+00,  8.0351e-01, -3.0866e+00],
        [-1.7886e+00, -5.2407e+00,  5.1965e+00, -3.9214e+00, -7.3980e-01,
         -1.2380e+00,  1.0598e+01, -1.6527e+00],
        [ 1.0964e+01, -3.7617e+00,  4.6105e+00, -3.9595e+00, -2.0746e+00,
         -1.3534e+00, -3.3521e+00, -2.1642e+00],
        [-1.1817e+00, -6.8659e+00,  1.4579e+01, -8.0723e+00,  2.2455e+00,
          1.8387e+00,  1.5468e+00, -2.9653e+00],
        [ 1.2650e+01, -2.9681e-01,  2.1471e+00, -1.8125e+00, -2.6456e+00,
         -3.5998e+00, -5.4631e+00, -2.2447e+00],
        [-3.6028e+00, -7.1249e+00,  5.3745e+00, -7.2809e+00,  2.6545e+01,
         -9.0188e+00,  2.1285e+00, -5.4065e+00],
        [-7.1209e+00, -8.3299e+00,  1.8607e+01, -1.2688e+01,  6.3974e+00,
          2.8692e-01,  5.5662e+00, -2.5318e+00],
        [-1.0563e+00, -4.4113e+00,  2.5672e+00, -4.8599e+00,  2.1745e+01,
         -8.1007e+00, -8.0188e-02, -4.7259e+00],
        [-5.9910e+00, -6.7792e+00,  1.8329e+01, -1.1998e+01,  5.9167e+00,
         -1.8745e-01,  3.4118e+00, -2.6561e+00],
        [-1.7889e+00, -2.4593e+00,  1.0200e+01, -4.7033e+00,  2.4784e+00,
         -4.1099e-01, -7.8792e-01, -2.0966e+00],
        [-1.5200e+00, -4.9964e+00,  9.3578e+00, -5.6120e+00,  1.4551e+00,
          2.5380e+00,  1.4848e-01, -8.8945e-01],
        [-1.0589e+00, -7.0544e+00,  4.9369e+00, -6.6117e+00,  2.5439e+01,
         -8.7991e+00,  3.3765e-01, -5.6520e+00],
        [-3.0370e+00, -6.7729e+00,  1.3806e+01, -7.7426e+00,  3.5988e+00,
          7.0545e-01,  3.3514e+00, -3.0350e+00],
        [-2.6618e+00, -7.8913e+00,  1.7011e+01, -1.0417e+01,  3.1858e+00,
          2.7914e+00,  9.0622e-01, -1.9671e+00],
        [ 5.9439e+00, -3.2295e+00,  2.9146e+00, -1.8957e+00, -8.1748e-01,
          4.3737e-01, -2.8163e+00, -1.0623e+00],
        [ 1.6096e+01, -3.1556e+00,  4.8236e+00, -4.1583e+00, -3.7494e+00,
         -3.5990e+00, -4.3594e+00, -3.5322e+00],
        [-5.7594e+00, -7.6900e+00,  1.8341e+01, -1.1803e+01,  5.6947e+00,
         -4.6263e-01,  5.3552e+00, -3.4064e+00],
        [-5.9031e+00, -6.6404e-02,  9.4189e+00, -6.7845e+00,  3.9087e+00,
         -1.1878e+00,  1.3652e-01,  1.0061e+00],
        [ 2.1346e+00, -2.7157e+00,  6.9606e+00, -5.1829e+00,  2.5537e+00,
         -1.4390e+00, -5.3237e-01, -1.8422e+00],
        [-4.4800e+00, -7.2018e+00,  1.6878e+01, -1.0805e+01,  3.8924e+00,
          8.3755e-03,  5.5222e+00, -3.0656e+00],
        [-3.5830e+00, -6.0418e+00,  1.2307e+01, -8.6753e+00,  1.8719e+00,
         -1.4939e-02,  6.2963e+00, -1.6755e+00],
        [-5.9439e-01, -5.8598e+00,  1.1379e+01, -6.9532e+00,  3.1109e+00,
          1.6172e+00, -1.5912e-01, -2.2678e+00],
        [-1.3918e+00,  5.0309e-01,  2.0507e+00, -1.1662e+00, -2.6080e-02,
         -5.7107e-02, -2.6862e+00,  2.6307e+00],
        [-2.4705e+00, -5.5336e+00,  4.4869e+00, -5.0576e+00,  1.6359e+01,
         -5.3438e+00,  2.1823e+00, -3.5342e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([0, 2, 0, 2, 2, 2, 2, 2, 2, 6, 0, 2, 0, 4, 2, 4, 2, 2, 2, 4, 2, 2, 0, 0,
        2, 2, 2, 2, 2, 2, 2, 4], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[ 1.4283e+01, -4.9392e+00,  6.0180e+00, -4.3040e+00, -2.9540e+00,
         -2.2004e+00, -4.1478e+00, -3.2323e+00],
        [-3.3555e+00, -5.7576e+00,  1.3650e+01, -8.9463e+00,  2.9446e+00,
          3.4153e-01,  3.3447e+00, -1.7872e+00],
        [-2.6686e+00, -8.6111e+00,  1.7323e+01, -1.0882e+01,  3.2978e+00,
          2.8211e+00,  1.9102e+00, -2.3264e+00],
        [-5.2668e-01, -6.4911e+00,  1.2605e+01, -7.5163e+00,  2.6473e+00,
          1.6691e+00,  8.5936e-01, -2.8257e+00],
        [-1.0264e+00, -5.3899e+00,  1.0298e+01, -6.8341e+00,  2.2307e+00,
          1.2335e+00,  1.0837e+00, -1.6217e+00],
        [-1.9623e+00, -4.2960e+00,  6.6900e+00, -4.4513e+00,  2.2075e+00,
          2.2427e+00,  5.0919e-01, -3.5987e-01],
        [ 1.4412e+01, -2.4085e+00,  5.6903e+00, -4.2334e+00, -4.4755e+00,
         -2.3552e+00, -5.0842e+00, -2.7191e+00],
        [-1.5580e+00, -2.5981e+00,  7.6179e+00, -3.7244e+00,  2.3401e+00,
         -3.7782e-01,  3.1888e-01, -1.6842e+00],
        [ 3.6181e-02, -5.9086e+00,  1.2353e+01, -7.3351e+00,  4.2838e-01,
          3.2509e+00, -4.8853e-01, -1.8243e+00],
        [-3.1676e-01, -6.8255e+00,  1.5044e+01, -8.9430e+00,  2.2761e+00,
          1.1715e+00,  3.5287e-01, -2.6336e+00],
        [-3.1300e-01, -4.3177e+00,  9.4460e+00, -5.8564e+00,  1.9918e-01,
          2.8937e+00, -8.5094e-01, -8.7898e-01],
        [ 2.4020e-01, -4.8557e+00,  2.7066e+00, -4.3903e+00,  1.8179e+01,
         -6.5761e+00, -2.6203e-01, -4.0923e+00],
        [-1.9019e+00, -4.1845e+00,  7.2353e+00, -4.5291e+00,  3.8516e+00,
          9.9236e-01,  3.0736e-02, -1.0449e+00],
        [-1.9775e+00, -2.7626e+00,  5.4297e+00, -2.9201e+00,  4.3894e+00,
         -1.3920e+00,  1.2946e+00, -1.7115e+00],
        [-2.8189e+00, -5.8955e+00,  1.4147e+01, -9.3111e+00,  1.6003e+00,
          4.8602e-01,  4.0394e+00, -1.8380e+00],
        [-4.4812e+00, -7.2995e+00,  1.5199e+01, -9.8579e+00,  3.8136e+00,
         -6.8150e-02,  6.0807e+00, -2.7943e+00],
        [-2.1985e+00, -6.4826e+00,  1.4316e+01, -7.7313e+00,  2.5377e+00,
          1.3415e+00,  2.1250e+00, -2.8391e+00],
        [-5.3899e+00, -7.0417e+00,  1.7923e+01, -1.1456e+01,  5.6516e+00,
         -5.8512e-01,  4.5198e+00, -3.3263e+00],
        [-2.2272e+00, -6.4909e+00,  1.5043e+01, -8.1051e+00,  2.8472e+00,
          1.5410e+00,  1.2579e+00, -2.8567e+00],
        [-2.6915e+00, -7.0562e+00,  1.5641e+01, -9.6144e+00,  2.8264e+00,
          2.6987e+00, -5.1555e-03, -1.1742e+00],
        [-1.4169e+00, -4.0603e+00,  3.4183e+00, -4.7879e+00,  1.7833e+01,
         -6.4148e+00, -5.8022e-03, -3.7123e+00],
        [-2.3980e+00, -5.1117e+00,  1.5195e+01, -9.5485e+00,  2.6505e+00,
         -8.7646e-02,  2.0752e+00, -2.4734e+00],
        [-3.4886e+00, -6.2752e+00,  4.6037e+00, -6.7535e+00,  2.6666e+01,
         -9.3391e+00,  1.2192e+00, -5.0856e+00],
        [-2.2369e+00, -2.6120e+00,  3.1139e+00, -4.4666e+00,  1.9915e+01,
         -7.4327e+00, -1.8203e+00, -3.4193e+00],
        [-9.1667e-01, -6.1511e+00,  1.4438e+01, -7.8168e+00,  2.4116e+00,
          1.5044e+00,  8.4507e-02, -2.8571e+00],
        [-4.2680e+00, -5.5340e+00,  1.6937e+01, -1.1032e+01,  3.8749e+00,
         -1.7691e-01,  2.9309e+00, -2.3974e+00],
        [-4.1578e+00, -7.9083e+00,  1.7309e+01, -1.0940e+01,  3.9900e+00,
          4.2153e-01,  5.3571e+00, -3.2784e+00],
        [-2.9924e+00, -6.8581e+00,  1.6029e+01, -9.8666e+00,  3.2909e+00,
          5.5816e-01,  3.6330e+00, -2.9753e+00],
        [ 1.1305e+01, -4.4602e+00,  4.1005e+00, -3.5582e+00, -1.9563e+00,
         -1.0159e+00, -3.2346e+00, -2.2046e+00],
        [-8.8445e-01, -6.6581e+00,  1.4662e+01, -8.9629e+00,  3.1177e+00,
          1.0734e+00,  4.3335e-01, -2.4507e+00],
        [-2.6428e+00, -6.5671e+00,  1.4596e+01, -8.8690e+00,  3.2425e+00,
          1.9923e+00,  6.8654e-01, -1.7160e+00],
        [ 1.5791e+01, -8.8717e-01,  4.6249e+00, -3.7028e+00, -5.0594e+00,
         -3.8304e+00, -5.3283e+00, -3.1803e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4,
        2, 2, 2, 2, 0, 2, 2, 0], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-8.8921e-01, -4.3036e+00,  8.8308e+00, -4.9329e+00,  2.9569e+00,
         -3.5702e-01,  1.5039e+00, -2.4955e+00],
        [-1.5589e+00, -4.4204e+00,  7.8877e+00, -4.7477e+00,  8.1419e-01,
          2.7332e+00,  3.7234e-01, -5.9662e-01],
        [-7.4761e-01, -5.4964e+00,  1.1992e+01, -7.0510e+00,  2.6309e+00,
          9.0120e-01,  8.5221e-01, -2.6810e+00],
        [-4.8939e+00, -6.3652e+00,  1.4019e+01, -9.5191e+00,  4.5649e+00,
         -1.8840e-01,  4.9234e+00, -2.1828e+00],
        [-1.1450e+00, -5.8940e+00,  1.4465e+01, -7.8432e+00,  1.5321e+00,
          2.5831e+00, -8.5509e-01, -2.3685e+00],
        [-5.6420e+00, -3.6696e+00,  1.0928e+01, -8.7805e+00,  6.4788e+00,
         -1.5654e+00,  2.7304e+00, -5.7162e-01],
        [ 1.1488e+01, -1.9541e+00,  3.9906e+00, -3.0617e+00, -2.2419e+00,
         -2.6705e+00, -3.7054e+00, -2.7507e+00],
        [-1.0160e+00, -2.1771e+00,  1.0415e+01, -4.9035e+00,  1.5264e+00,
          1.5255e-02, -1.7117e+00, -1.8528e+00],
        [ 1.1679e+01, -2.7813e+00,  4.4031e+00, -3.7817e+00, -1.5759e+00,
         -2.8504e+00, -2.9167e+00, -3.1712e+00],
        [-8.2980e+00, -9.5031e+00,  2.1801e+01, -1.4346e+01,  6.7229e+00,
          7.7429e-02,  7.0833e+00, -2.9810e+00],
        [-4.7752e-01, -5.6477e+00,  1.2216e+01, -7.2029e+00,  2.0861e+00,
          1.0945e+00,  1.0873e+00, -2.5831e+00],
        [-3.7751e+00, -7.2450e+00,  1.5171e+01, -1.0014e+01,  2.2403e+00,
          3.8164e-01,  6.7302e+00, -2.4401e+00],
        [-3.2318e+00, -5.9206e+00,  4.5617e+00, -6.0389e+00,  2.2286e+01,
         -7.8131e+00,  1.8478e+00, -4.4338e+00],
        [-1.9743e+00, -5.0525e+00,  3.6483e+00, -5.3417e+00,  1.9845e+01,
         -7.2137e+00,  1.2010e+00, -4.1372e+00],
        [ 3.2497e-01,  7.1807e-01, -2.2929e+00,  9.0688e+00, -3.5677e+00,
         -2.9869e+00, -2.4115e+00,  3.5270e-01],
        [-3.6027e+00, -7.4037e+00,  1.7106e+01, -1.0716e+01,  3.7053e+00,
          3.7196e-01,  4.3958e+00, -3.1282e+00],
        [-1.8959e+00, -5.5011e+00,  4.5082e+00, -5.9618e+00,  2.1123e+01,
         -7.5078e+00,  1.3169e+00, -4.5758e+00],
        [-3.0901e+00, -6.8147e+00,  1.3876e+01, -7.7494e+00,  3.6110e+00,
          8.2302e-01,  3.3290e+00, -2.9983e+00],
        [ 1.8759e+00,  9.1025e+00, -1.6287e+00,  2.3804e+00, -4.1854e+00,
         -3.6179e+00, -5.4193e+00,  1.4000e+00],
        [-1.0927e+00, -6.1663e+00,  1.5266e+01, -7.9089e+00,  2.6298e+00,
          1.8474e+00, -9.1493e-01, -2.8283e+00],
        [-3.1219e+00, -7.0965e+00,  1.6695e+01, -1.0383e+01,  4.1099e+00,
         -2.2948e-01,  3.7545e+00, -3.2309e+00],
        [-1.6109e+00, -6.2225e+00,  1.3899e+01, -8.4531e+00,  3.2584e+00,
          9.0641e-01,  6.6443e-01, -2.1694e+00],
        [ 9.4315e+00, -4.3788e+00,  4.1978e+00, -3.3228e+00, -1.2377e+00,
         -5.1753e-01, -3.0222e+00, -1.9598e+00],
        [-2.3033e+00, -6.9414e+00,  1.5745e+01, -8.4242e+00,  2.7018e+00,
          1.8155e+00,  1.4450e+00, -2.8766e+00],
        [-7.9711e+00, -7.2912e+00,  1.9619e+01, -1.3078e+01,  7.0460e+00,
         -4.2884e-01,  4.8008e+00, -2.4287e+00],
        [-1.2966e+00, -2.9974e+00,  3.5312e+00, -3.9505e+00,  1.3260e+01,
         -4.6217e+00, -7.7335e-01, -2.5754e+00],
        [-6.2524e-01, -6.5031e+00,  1.3929e+01, -7.2482e+00,  1.9902e+00,
          1.4521e+00,  8.4397e-01, -2.9413e+00],
        [ 1.0894e+01, -1.5724e+00,  3.9924e+00, -2.6245e+00, -2.9092e+00,
         -2.5075e+00, -3.8466e+00, -2.6056e+00],
        [-1.6095e+00, -4.6894e+00,  4.8326e+00, -5.0692e+00,  1.2970e+01,
         -4.6993e+00,  2.3594e+00, -3.3245e+00],
        [-5.7531e+00, -8.0403e+00,  1.7911e+01, -1.1411e+01,  4.9666e+00,
         -7.9793e-02,  6.3322e+00, -3.3258e+00],
        [-1.3195e+00, -4.1920e+00,  1.0207e+01, -5.9375e+00,  2.9650e+00,
          2.9104e-02,  8.9425e-01, -2.1418e+00],
        [-4.1480e+00, -4.6184e+00,  1.3117e+01, -9.0753e+00,  3.8750e+00,
         -2.6968e-01,  2.1093e+00, -1.1313e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 4, 4, 3, 2, 4, 2, 1, 2, 2, 2, 0, 2,
        2, 4, 2, 0, 4, 2, 2, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-1.6169e+00, -2.5173e+00,  4.6243e+00, -2.7739e+00,  3.6777e+00,
         -1.3305e+00,  1.9395e+00, -1.6666e+00],
        [-5.0871e+00, -6.9080e+00,  1.4790e+01, -9.1326e+00,  3.8141e+00,
          3.3788e-01,  5.8468e+00, -2.6043e+00],
        [-2.3303e+00, -7.4089e+00,  1.6856e+01, -8.7715e+00,  2.6914e+00,
          1.9013e+00,  1.2999e+00, -3.1185e+00],
        [-8.6824e-01, -4.0379e+00,  9.2639e+00, -5.1495e+00,  3.0791e+00,
         -3.0980e-01,  9.3186e-01, -2.3028e+00],
        [-1.8472e+00, -4.6924e+00,  1.2262e+01, -6.9292e+00,  1.9397e+00,
          2.0886e+00, -7.3981e-01, -1.6692e+00],
        [-2.3616e+00, -6.0125e+00,  1.3518e+01, -8.1614e+00,  1.0276e+00,
          1.6363e+00,  2.8559e+00, -1.6778e+00],
        [-3.2081e+00, -6.2000e+00,  1.4845e+01, -9.3671e+00,  2.7169e+00,
          6.5575e-01,  3.3998e+00, -2.2178e+00],
        [-1.9025e+00, -6.6103e+00,  1.3497e+01, -8.0269e+00,  1.7927e+00,
          1.4921e+00,  2.8765e+00, -1.9939e+00],
        [-4.5837e+00, -6.9460e+00,  1.7529e+01, -1.0722e+01,  4.2142e+00,
          5.8982e-01,  3.4551e+00, -2.7380e+00],
        [ 1.0723e+01, -3.7248e+00,  4.4201e+00, -3.0148e+00, -2.6074e+00,
         -1.1123e+00, -3.4217e+00, -2.2937e+00],
        [-6.2133e+00, -7.5908e+00,  1.7435e+01, -1.1464e+01,  6.7835e+00,
         -5.0020e-01,  4.6433e+00, -2.8758e+00],
        [-2.5281e+00, -7.7322e+00,  1.7549e+01, -1.0763e+01,  2.8101e+00,
          2.9513e+00,  2.5453e-01, -1.8525e+00],
        [-3.2858e+00, -6.5632e+00,  1.5502e+01, -1.0283e+01,  3.5265e+00,
         -3.6857e-01,  4.8157e+00, -2.8491e+00],
        [-2.6164e+00, -6.5061e+00,  9.9744e+00, -6.9704e+00,  2.0139e+00,
          2.1620e+00,  3.5946e+00, -1.1747e+00],
        [ 1.0427e+01, -2.4600e+00,  3.8128e+00, -3.5591e+00, -9.5237e-01,
         -2.4171e+00, -3.0876e+00, -2.6124e+00],
        [-1.9199e+00, -5.4962e+00,  4.5548e+00, -5.4912e+00,  1.9735e+01,
         -6.7147e+00, -2.7226e-03, -3.8664e+00],
        [-2.2586e+00, -7.3039e+00,  1.6641e+01, -1.0802e+01,  2.9848e+00,
          3.8257e-01,  4.2892e+00, -3.3297e+00],
        [-8.3116e-01,  1.4151e+01,  4.4411e-01, -8.3159e-01, -5.2119e+00,
         -3.9182e+00, -7.0412e+00,  3.8114e+00],
        [-1.2026e+00,  1.2985e+01, -2.6078e+00,  2.0415e+00, -4.2853e+00,
         -4.0522e+00, -6.6966e+00,  4.1128e+00],
        [-2.5723e+00, -6.5494e+00,  1.5441e+01, -9.3863e+00,  2.6948e+00,
          2.3292e+00,  2.4424e-01, -1.6156e+00],
        [-5.9520e-01, -4.2604e+00,  2.2397e+00, -3.3281e+00,  1.5239e+01,
         -5.5246e+00,  5.0411e-01, -3.4308e+00],
        [-5.0261e+00, -7.7143e+00,  1.8314e+01, -1.1856e+01,  4.6678e+00,
          2.8861e-03,  5.1495e+00, -3.2637e+00],
        [ 1.0559e+01, -4.6224e+00,  4.8286e+00, -3.0186e+00, -2.7488e+00,
         -2.3264e+00, -1.9067e-01, -3.1363e+00],
        [-9.7295e-01, -5.2986e+00,  1.2074e+01, -6.6923e+00,  2.1830e+00,
          1.2496e+00,  5.8885e-01, -2.6108e+00],
        [ 2.1952e+00,  1.2959e+01, -1.3844e-01, -4.8820e-01, -4.2265e+00,
         -4.7947e+00, -7.1387e+00,  1.6671e+00],
        [-7.4599e-02,  1.5164e+01, -2.4094e+00,  2.7320e+00, -4.0212e+00,
         -5.6785e+00, -7.8909e+00,  2.3839e+00],
        [ 9.4973e+00, -3.9490e+00,  4.1571e+00, -3.2902e+00, -1.7485e+00,
         -9.0193e-01, -2.2969e+00, -2.3315e+00],
        [-2.0757e+00, -5.1771e+00,  1.2391e+01, -8.3890e+00,  2.5320e+00,
         -3.1808e-02,  2.7084e+00, -1.8671e+00],
        [-7.8451e-01, -3.3047e+00,  1.6542e+00, -4.3651e+00,  1.8779e+01,
         -7.0588e+00, -4.0860e-01, -3.5628e+00],
        [ 1.2901e+01, -4.6687e+00,  5.0290e+00, -2.5656e+00, -3.8134e+00,
         -2.6780e+00, -2.3896e+00, -3.2977e+00],
        [-1.3157e+00, -6.3977e+00,  1.4525e+01, -7.7362e+00,  2.5687e+00,
          1.1543e+00,  9.0844e-01, -3.1624e+00],
        [-5.3170e+00, -5.4819e+00,  1.4568e+01, -9.9678e+00,  4.8154e+00,
         -9.4612e-01,  4.1755e+00, -1.9474e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 4, 2, 1, 1, 2, 4, 2, 0, 2,
        1, 1, 0, 2, 4, 0, 2, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-1.7709e+00, -6.9767e+00,  1.5562e+01, -8.4807e+00,  2.7161e+00,
          1.5192e+00,  1.4625e+00, -3.1227e+00],
        [-6.4231e+00, -7.3395e+00,  1.7975e+01, -1.1552e+01,  6.6209e+00,
         -7.2425e-01,  5.0869e+00, -3.2662e+00],
        [-1.9039e+00, -5.1640e+00,  1.1836e+01, -6.6408e+00,  1.7848e+00,
          1.3877e+00,  7.9732e-01, -1.4267e+00],
        [-1.3170e+00, -3.7193e+00,  6.6370e+00, -4.9065e+00,  1.0570e+00,
          2.3806e+00, -3.9707e-01,  3.4748e-01],
        [ 9.3463e+00, -2.2639e+00,  3.1183e+00, -2.3544e+00, -9.6280e-01,
         -2.3044e+00, -2.7544e+00, -2.4054e+00],
        [ 1.2088e+01, -3.1514e+00,  4.3682e+00, -2.9864e+00, -2.7454e+00,
         -2.2208e+00, -3.8830e+00, -2.7253e+00],
        [-4.4958e+00, -6.6285e+00,  1.7512e+01, -1.0877e+01,  5.1448e+00,
         -4.3731e-01,  3.1703e+00, -3.2543e+00],
        [-1.7303e+00, -7.0674e+00,  1.5331e+01, -8.1902e+00,  2.5581e+00,
          1.8788e+00,  1.1722e+00, -3.0138e+00],
        [-1.6609e+00, -7.1298e+00,  1.5465e+01, -9.2263e+00,  2.6492e+00,
          1.9569e+00,  7.1746e-01, -2.2371e+00],
        [-3.0031e+00, -6.7189e+00,  5.3448e+00, -7.1876e+00,  2.4722e+01,
         -8.1840e+00,  1.3205e+00, -5.1514e+00],
        [-1.5835e+00, -6.0889e+00,  4.7370e+00, -6.2322e+00,  2.1922e+01,
         -7.5534e+00,  4.4298e-01, -4.6633e+00],
        [ 1.1470e+01, -4.2499e+00,  4.1055e+00, -2.9097e+00, -1.5687e+00,
         -1.4876e+00, -3.9740e+00, -2.5254e+00],
        [-1.6013e+00, -2.3992e+00,  7.5027e+00, -3.6686e+00,  2.8509e+00,
         -6.4138e-01, -1.1784e-02, -1.7336e+00],
        [ 1.5029e+01, -1.0873e+00,  3.2605e+00, -2.4381e+00, -4.7828e+00,
         -3.5255e+00, -5.6084e+00, -2.5356e+00],
        [ 1.2913e+01, -4.3846e+00,  4.9218e+00, -3.9366e+00, -2.7439e+00,
         -1.6397e+00, -3.5502e+00, -2.7570e+00],
        [-1.2676e+00,  1.2979e+00,  4.8611e-01, -2.2844e+00,  1.2882e+01,
         -5.9531e+00, -3.6159e+00, -1.3286e+00],
        [-2.8187e+00, -7.4890e+00,  1.7284e+01, -1.0851e+01,  3.4516e+00,
          6.9108e-01,  3.3691e+00, -3.2984e+00],
        [-2.0680e+00, -5.5899e+00,  1.1254e+01, -7.3675e+00,  2.7767e+00,
          5.2432e-01,  2.2304e+00, -1.6632e+00],
        [ 8.4774e-03, -5.4642e+00,  2.9902e+00, -4.6757e+00,  1.9277e+01,
         -6.8238e+00, -9.0734e-02, -4.2658e+00],
        [-4.7248e+00, -7.7925e+00,  1.8567e+01, -1.1431e+01,  4.1346e+00,
          5.0795e-01,  5.0668e+00, -3.3153e+00],
        [ 1.4255e+01, -5.2077e+00,  5.5640e+00, -3.0362e+00, -4.1298e+00,
         -3.1823e+00, -1.5515e+00, -3.9039e+00],
        [-1.5568e+00, -5.6716e+00,  1.1241e+01, -6.7136e+00,  2.8714e+00,
          2.4175e+00, -2.1865e-02, -1.8883e+00],
        [-1.6107e+00, -6.4395e+00,  1.5407e+01, -8.1158e+00,  2.1236e+00,
          1.4643e+00,  1.0613e+00, -2.9003e+00],
        [-1.7434e+00, -2.6246e+00,  8.6622e+00, -4.2248e+00,  2.8774e+00,
         -4.7206e-01, -3.7319e-01, -1.8562e+00],
        [ 1.1783e+01, -3.9927e+00,  5.2637e+00, -3.8352e+00, -3.0917e+00,
         -2.3626e+00, -1.5738e+00, -3.1311e+00],
        [-1.6408e+00, -2.4476e+00,  8.4711e+00, -4.2049e+00,  2.2530e+00,
         -3.1447e-01, -1.1756e-01, -1.7058e+00],
        [-7.7477e-01, -4.3742e+00,  9.8112e+00, -5.5337e+00,  2.6201e+00,
          1.5469e-01,  1.0078e+00, -2.2566e+00],
        [-3.4708e+00, -8.5449e+00,  1.8502e+01, -1.1140e+01,  4.0395e+00,
          2.3721e+00,  1.5332e+00, -2.3787e+00],
        [-3.0110e+00, -6.7518e+00,  5.7363e+00, -7.0113e+00,  2.7433e+01,
         -9.2822e+00, -1.7414e-01, -5.3710e+00],
        [-4.1089e+00, -6.0155e+00,  1.5218e+01, -9.2982e+00,  4.4593e+00,
          1.9256e-01,  2.4614e+00, -2.6342e+00],
        [-3.8791e+00, -6.9164e+00,  1.4218e+01, -9.7360e+00,  3.7258e+00,
          1.7563e-01,  5.0562e+00, -2.1798e+00],
        [ 1.0570e-01,  1.4213e-01,  2.4843e+00, -3.0170e+00,  8.4333e+00,
         -4.2033e+00, -1.5581e+00, -2.0105e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 2, 2, 0, 0, 2, 2, 2, 4, 4, 0, 2, 0, 0, 4, 2, 2, 4, 2, 0, 2, 2, 2,
        0, 2, 2, 2, 4, 2, 2, 4], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[ -1.5244,  -5.9224,  15.2765,  -8.0041,   3.1371,   1.3306,  -0.3796,
          -3.1062],
        [ -1.0696,  -4.7736,  11.4310,  -6.6245,   1.3132,   2.7133,  -1.2649,
          -1.3064],
        [ -2.1434,  -6.8176,  15.4906,  -8.0886,   2.3859,   1.7676,   1.3379,
          -2.8672],
        [ -4.6526,  -7.3197,  15.0216,  -9.5798,   3.7298,   0.3679,   6.1498,
          -2.6954],
        [ -3.9027,  -8.0604,  18.5603, -11.3699,   3.4271,   0.9801,   4.3191,
          -3.1578],
        [ -6.3876,  -7.1890,  17.8487, -11.8277,   5.8824,  -0.3902,   4.9546,
          -2.5477],
        [ -2.7469,  -5.6385,  11.6746,  -6.4331,   3.9865,   1.1025,   1.3572,
          -2.3737],
        [ -1.4990,  -1.5559,   1.7450,  -2.7458,  12.7923,  -4.9887,  -1.3511,
          -1.9593],
        [ -4.5773,  -8.4033,  18.7377, -11.6762,   4.3993,   0.7971,   4.6782,
          -3.3304],
        [ -3.6142,  -6.8204,  16.5264, -10.1753,   3.4790,   0.3272,   3.8016,
          -2.8604],
        [ -1.5304,  -6.1952,  12.2068,  -7.4870,   2.7509,   2.1290,   0.6246,
          -2.0525],
        [ -3.8238,  -6.3347,  13.4331,  -9.3799,   4.0829,  -0.2416,   4.7477,
          -2.2140],
        [ -1.5381,  -2.4565,   6.8671,  -3.3822,   2.0744,  -0.3742,   0.6252,
          -1.5202],
        [ -0.6365,  -5.8452,   2.6996,  -4.3480,  24.7894,  -9.0956,  -1.7345,
          -5.2899],
        [ -3.6215,  -7.8117,  18.5513, -11.8596,   4.3872,   0.1589,   3.6979,
          -3.4630],
        [ -2.2617,  -6.7301,  15.2974,  -8.2226,   2.5291,   1.4949,   1.5592,
          -2.9271],
        [ -1.8222,  -3.3876,   9.0006,  -4.9788,   2.8809,  -0.3396,   1.3107,
          -2.1443],
        [ 10.0297,  -3.2700,   3.8108,  -2.6521,  -2.7858,  -2.6485,  -0.4372,
          -2.8594],
        [ -0.3142,  -7.0384,  12.9677,  -7.8092,   2.6683,   1.7125,   1.2125,
          -3.0423],
        [ -1.4921,  -2.3196,   6.1972,  -3.0476,   2.4443,  -0.6716,   0.7078,
          -1.5928],
        [ -1.7810,  -5.9070,  14.5487,  -7.5392,   3.2436,   1.2922,  -0.1180,
          -2.8473],
        [ -3.7729,  15.9593,  -3.7517,   2.9578,  -3.8051,  -4.8700,  -7.3908,
           5.4823],
        [ 10.9632,  -2.3024,   2.8246,  -0.7027,  -1.6858,  -2.5175,  -5.4950,
          -2.2327],
        [ -3.1463,  -5.5848,  15.4605, -10.0203,   3.2509,  -0.3416,   3.3161,
          -2.5256],
        [ -0.3542,  -5.4298,  12.1334,  -7.6383,   1.6911,   1.7550,  -0.3426,
          -1.3233],
        [  0.2432,  -4.2635,   2.6104,  -2.9961,   7.4819,  -1.3189,  -0.6201,
          -1.1924],
        [ 10.9373,  -2.6762,   3.9052,  -3.1402,  -2.1580,  -2.4513,  -2.6878,
          -2.6758],
        [ -1.7968,  -2.8864,   3.5233,  -2.4894,   1.8198,  -0.9688,   4.6111,
          -1.2453],
        [ -1.2956,  -4.5891,   9.2661,  -5.1849,   2.6875,   1.4017,  -0.1312,
          -1.5579],
        [ -0.8293,  -5.5647,  14.0942,  -7.1210,   2.6419,   1.3731,  -1.1216,
          -2.7083],
        [ -1.7219,  -1.4474,   0.6252,  -1.9362,  10.0126,  -4.2868,   0.9219,
          -1.5242],
        [ -5.2645,  -6.8793,  16.9135, -10.7217,   5.8122,  -0.5610,   4.0110,
          -3.2657]], device='cuda:0', grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 0, 2, 2, 2, 1, 0, 2,
        2, 4, 0, 6, 2, 2, 4, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[  1.0807,  -3.2444,   1.9293,  -3.6534,  19.4130,  -7.7485,  -2.7275,
          -4.2921],
        [ -3.1600,  -6.8246,  16.8426, -10.5104,   3.8793,   1.6511,   0.4712,
          -1.9916],
        [  8.5791,  -3.6697,   3.1919,  -2.9236,   0.9887,  -1.6845,  -2.9071,
          -2.3324],
        [ -3.0425,  -6.1576,  14.6806,  -9.2511,   1.5711,   0.8631,   3.5280,
          -1.8871],
        [ 13.1087,  -0.9175,   2.5768,  -2.0781,  -3.8134,  -3.1282,  -4.5931,
          -2.4271],
        [ 12.0614,  -4.7144,   3.7774,  -3.3017,  -0.0483,  -1.8802,  -4.6458,
          -2.6559],
        [ -5.7681,  -7.1151,  16.2929, -10.4550,   4.7127,   0.3929,   4.5511,
          -2.3321],
        [ -5.8578,  -7.8620,  18.4786, -12.1178,   5.0572,  -0.0315,   5.6675,
          -3.0263],
        [ -3.1613,  -7.5806,  15.2470,  -9.7444,   3.3227,   1.6194,   3.1354,
          -2.1996],
        [ -2.7341,  -5.3978,  15.1243,  -9.1444,   2.4257,   0.1184,   2.8352,
          -2.6495],
        [  9.8195,  -3.3445,   4.3711,  -2.6958,  -2.5905,  -1.3128,  -3.4246,
          -1.8688],
        [ -4.6018,  -8.7971,  18.6350, -11.6871,   4.7840,   0.6133,   5.0129,
          -3.6275],
        [ -3.4226,  -5.8771,   5.3716,  -4.3093,  -1.6416,  -1.1962,  13.0202,
          -1.0171],
        [ -3.9857,  -4.2732,  10.4240,  -6.7030,   1.8500,   0.2635,   4.2092,
          -1.2511],
        [ -4.6937,  -6.8881,  16.0562,  -9.9760,   4.4933,   0.0259,   4.7286,
          -2.9000],
        [  9.9695,  -2.5966,   3.6414,  -3.1013,  -1.7881,  -1.9948,  -2.7646,
          -2.2445],
        [ -2.0748,  -5.4693,  10.4432,  -7.1723,   0.7240,   0.1892,   5.9048,
          -1.7535],
        [ -1.0033,  -2.9492,   8.4546,  -4.7278,   1.3731,   0.3430,   0.5800,
          -1.5298],
        [ 12.8329,  -1.5631,   3.9426,  -2.0556,  -4.7961,  -2.9860,  -3.8907,
          -2.8833],
        [ -6.8482,  -7.7283,  19.4360, -13.0013,   7.3821,  -0.4685,   4.2083,
          -2.7818],
        [ -2.6803,  -6.8971,  15.1576,  -9.7402,   2.1453,   0.1581,   5.4089,
          -3.0417],
        [ -4.2347,  -6.0243,   5.3118,  -7.2756,  23.3253,  -8.2327,   3.0699,
          -4.4221],
        [ -1.6996,  -2.4842,   4.2378,  -2.5191,   4.6598,  -1.6028,   1.4937,
          -1.6670],
        [ -2.0678,  -3.4400,   6.7711,  -3.9069,   2.2986,  -0.5555,   3.2843,
          -1.8123],
        [ -1.2574,  -5.7951,  14.9189,  -7.7545,   2.8652,   1.5144,  -0.7690,
          -2.8335],
        [ -3.2981,  -4.3452,   4.4694,  -4.6237,   2.2947,  -2.3367,  10.4136,
          -1.6459],
        [ -1.4937,  -2.9306,   4.2695,  -4.8226,  14.1695,  -5.0973,  -0.2967,
          -2.8974],
        [ -0.5899,  -6.8158,  14.9637,  -8.0648,   2.3018,   1.8258,   0.5190,
          -3.1303],
        [ -1.1591,  -4.2051,   4.3557,  -5.3077,  18.1102,  -6.3492,  -1.0162,
          -3.8832],
        [ -2.2145,  18.0527,  -2.0131,   0.9351,  -4.7773,  -5.8819,  -7.6268,
           4.1893],
        [ -4.4746,  -8.2818,  19.4277, -11.9758,   4.7382,   0.5608,   3.9010,
          -3.4786],
        [ -1.8024,  -6.3796,   5.4790,  -6.2550,  19.1605,  -6.1752,   1.3316,
          -4.2148]], device='cuda:0', grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([4, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 6, 2, 2, 0, 2, 2, 0, 2, 2, 4, 4, 2,
        2, 6, 4, 2, 4, 1, 2, 4], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[ 9.5542e+00, -1.8938e+00,  4.3506e+00, -3.4525e+00, -2.1020e+00,
         -1.9216e+00, -3.2276e+00, -2.2010e+00],
        [-5.8446e+00, -6.4366e+00,  1.6252e+01, -1.0787e+01,  5.7580e+00,
         -1.0325e+00,  5.3195e+00, -3.0475e+00],
        [-2.3481e+00, -8.0079e+00,  1.7407e+01, -1.0508e+01,  3.4236e+00,
          2.5837e+00,  3.6720e-01, -2.1912e+00],
        [-4.5691e+00, -8.8263e+00,  1.9181e+01, -1.2179e+01,  4.8391e+00,
          3.8532e-01,  5.0346e+00, -3.7021e+00],
        [-3.0258e+00, -4.7710e+00,  4.5073e+00, -5.4787e+00,  1.5354e+01,
         -5.2175e+00,  2.8078e+00, -2.8374e+00],
        [ 7.0627e+00, -3.6491e+00,  3.7676e+00, -2.1340e+00, -1.1987e+00,
         -2.0414e+00,  1.6271e-01, -2.3555e+00],
        [-3.5831e+00, -6.0791e+00,  5.2140e+00, -6.1510e+00,  1.8939e+01,
         -6.5019e+00,  3.5753e+00, -4.0890e+00],
        [-1.5761e+00, -2.6030e+00,  7.5095e+00, -3.6531e+00,  2.5909e+00,
         -5.5059e-01,  3.1749e-01, -1.8292e+00],
        [-1.3640e+00, -6.1346e+00,  1.3329e+01, -7.3343e+00,  1.9920e+00,
          1.6175e+00,  1.4545e+00, -2.5553e+00],
        [-7.7233e-01, -4.1803e+00,  9.1048e+00, -5.9650e+00,  8.7484e-01,
         -5.7709e-01,  3.8722e+00, -1.9608e+00],
        [-1.6508e+00, -5.6752e+00,  1.0631e+01, -6.3575e+00,  3.1981e+00,
          2.1151e+00,  2.9373e-01, -1.8156e+00],
        [ 1.1580e+00, -4.8909e+00,  2.1479e+00, -1.5480e+00,  1.4514e+01,
         -5.8967e+00, -1.8744e+00, -3.8602e+00],
        [-6.5554e+00, -7.8496e+00,  1.9845e+01, -1.2553e+01,  5.5609e+00,
         -3.2876e-01,  5.6453e+00, -3.3509e+00],
        [-4.0070e+00,  1.0963e+01, -2.1071e+00,  1.4354e+00, -6.0962e-01,
         -3.5154e+00, -6.3696e+00,  4.9636e+00],
        [-7.1435e+00, -6.3734e+00,  1.8330e+01, -1.2233e+01,  7.9549e+00,
         -1.1742e+00,  3.5173e+00, -2.5286e+00],
        [-4.4573e+00, -6.1090e+00,  1.5128e+01, -9.7175e+00,  4.2383e+00,
          4.7221e-03,  3.7239e+00, -2.4026e+00],
        [-1.6639e+00, -4.9741e+00,  1.1110e+01, -5.8636e+00,  1.9470e+00,
          1.4733e+00,  5.7918e-01, -2.2210e+00],
        [-5.3171e+00, -7.6383e+00,  1.7608e+01, -1.1327e+01,  5.1362e+00,
         -2.8852e-01,  5.6655e+00, -3.4267e+00],
        [-2.8900e+00, -4.7314e+00,  4.9069e+00, -6.1440e+00,  2.0829e+01,
         -7.2034e+00,  3.7524e-01, -4.1844e+00],
        [ 1.3570e+00, -3.3270e+00,  1.5587e+00, -2.5502e+00,  1.7849e+01,
         -7.1517e+00, -3.4943e+00, -3.8436e+00],
        [-9.4060e-01, -3.2789e+00,  2.0637e+00, -3.9960e+00,  1.9013e+01,
         -6.8252e+00, -1.8444e+00, -3.4091e+00],
        [-4.5204e+00, -6.4932e+00,  1.6438e+01, -1.0204e+01,  3.9341e+00,
          3.1661e-01,  3.7333e+00, -2.5279e+00],
        [-5.5116e+00, -6.1447e+00,  1.4083e+01, -9.0004e+00,  3.9523e+00,
         -1.2067e-01,  5.8428e+00, -2.1788e+00],
        [-1.4047e+00, -4.8099e+00,  1.0863e+01, -6.6960e+00,  3.0399e+00,
          7.0171e-01,  4.7769e-01, -2.0416e+00],
        [-1.5966e+00, -7.0435e+00,  1.5689e+01, -8.2585e+00,  2.5470e+00,
          1.6227e+00,  1.1730e+00, -3.1564e+00],
        [-3.7257e+00, -5.5084e+00,  1.4992e+01, -1.0074e+01,  4.3693e+00,
         -9.6871e-01,  3.6423e+00, -2.5006e+00],
        [-4.5814e+00, -6.8443e+00,  1.6236e+01, -1.0251e+01,  3.5426e+00,
          4.4133e-01,  4.3386e+00, -2.3481e+00],
        [-2.4971e+00, -3.6908e+00,  2.5682e+00, -4.0176e+00,  2.0290e+01,
         -7.4689e+00, -5.3179e-01, -3.5248e+00],
        [-8.9715e-01, -5.7806e+00,  1.4104e+01, -7.6941e+00,  1.4863e+00,
          2.5015e+00, -8.7044e-01, -2.4093e+00],
        [-2.7095e+00, -5.1810e+00,  1.3932e+01, -8.9612e+00,  2.4207e+00,
         -4.4490e-02,  3.2294e+00, -2.4793e+00],
        [-4.1508e+00, -8.0975e+00,  1.7752e+01, -1.1207e+01,  3.8051e+00,
          7.4898e-01,  4.7335e+00, -3.0332e+00],
        [-2.2342e+00, -6.1821e+00,  4.0545e+00, -5.8671e+00,  2.4405e+01,
         -8.4173e+00, -3.9124e-02, -4.8783e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([0, 2, 2, 2, 4, 0, 4, 2, 2, 2, 2, 4, 2, 1, 2, 2, 2, 2, 4, 4, 4, 2, 2, 2,
        2, 2, 2, 4, 2, 2, 2, 4], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-5.4857e+00, -7.3314e+00,  1.8249e+01, -1.1616e+01,  5.6488e+00,
         -5.2452e-01,  4.7923e+00, -3.3935e+00],
        [ 5.6469e-01, -4.3514e+00,  1.0437e+01, -6.0742e+00, -3.2563e-01,
          2.7238e+00, -1.3920e+00, -1.1704e+00],
        [-6.3315e+00, -4.4887e+00,  1.6305e+01, -1.1363e+01,  3.9730e+00,
         -2.0745e-01,  2.1844e+00, -7.7273e-01],
        [-4.0585e+00, -1.6876e+00,  9.8653e+00, -6.5014e+00,  2.8798e+00,
         -7.3075e-01,  8.6430e-01, -6.4450e-01],
        [-4.0601e+00, -6.6529e+00,  1.6389e+01, -1.0309e+01,  3.0194e+00,
          6.0912e-01,  4.1118e+00, -2.5522e+00],
        [-4.0294e+00, -6.2130e+00,  1.7400e+01, -1.0925e+01,  3.8133e+00,
          9.1847e-02,  3.0336e+00, -2.8612e+00],
        [-3.0043e+00, -5.5837e+00,  5.0505e+00, -4.2605e+00, -7.0016e-01,
         -1.5239e+00,  1.2535e+01, -1.4602e+00],
        [-2.6825e+00, -6.7560e+00,  5.5379e+00, -6.4556e+00,  1.8727e+01,
         -6.3434e+00,  3.3357e+00, -4.4399e+00],
        [-2.6303e+00, -5.6461e+00,  1.5689e+01, -9.8705e+00,  1.9147e+00,
          6.2010e-01,  2.4344e+00, -2.0075e+00],
        [ 1.0637e+01, -3.5425e+00,  4.4029e+00, -3.8193e+00, -1.4263e-01,
         -2.4168e+00, -3.0824e+00, -2.7896e+00],
        [-3.0517e+00, -6.7698e+00,  1.4017e+01, -7.8143e+00,  3.6220e+00,
          7.8041e-01,  3.1950e+00, -3.0485e+00],
        [-7.9940e-01, -6.4162e+00,  1.2401e+01, -7.4134e+00,  2.5825e+00,
          1.5708e+00,  1.2905e+00, -2.8176e+00],
        [-1.7567e+00, -2.6281e+00,  7.9862e+00, -3.8647e+00,  2.7371e+00,
         -5.3486e-01,  1.2088e-01, -1.8399e+00],
        [-2.0364e+00, -8.0896e+00,  1.8451e+01, -1.1039e+01,  2.8124e+00,
          1.0535e+00,  3.2912e+00, -3.6025e+00],
        [-3.5999e+00, -5.6829e+00,  1.5843e+01, -9.7161e+00,  3.4615e+00,
          6.5392e-02,  2.5137e+00, -2.6539e+00],
        [ 1.1835e+01, -4.2697e+00,  5.0223e+00, -3.2509e+00, -2.4966e+00,
         -1.6571e+00, -3.4651e+00, -2.8362e+00],
        [-4.4724e+00,  1.5550e+01, -3.7650e+00,  2.4461e+00, -3.5995e+00,
         -4.8327e+00, -6.7828e+00,  5.8958e+00],
        [ 8.2068e-01, -4.2517e+00,  7.5425e+00, -5.6925e+00,  1.7574e-01,
          1.5606e-01,  3.5050e+00, -1.7829e+00],
        [-1.5560e+00, -4.5972e+00,  8.6422e+00, -4.8586e+00,  2.9178e+00,
          1.0447e+00,  7.7010e-01, -1.7126e+00],
        [-1.9094e+00, -4.4963e+00,  7.6083e+00, -4.9723e+00,  2.6276e+00,
          2.2473e+00,  1.0141e-01, -6.0852e-01],
        [ 1.4448e+01, -2.7711e+00,  4.3679e+00, -3.6789e+00, -2.8180e+00,
         -3.1596e+00, -4.5847e+00, -3.1540e+00],
        [-1.2826e+00, -2.5078e+00,  8.8255e+00, -4.1446e+00,  2.4843e+00,
         -3.9618e-01, -7.7523e-01, -1.9236e+00],
        [-2.0005e+00, -4.4627e+00,  1.0159e+01, -6.0427e+00,  1.9402e+00,
          1.7806e+00,  1.1846e-01, -1.1199e+00],
        [ 1.0719e+01, -3.7058e+00,  4.4251e+00, -2.6604e+00, -3.0489e+00,
         -1.7572e+00, -2.6427e+00, -2.4330e+00],
        [-5.2683e+00, -6.4244e+00,  1.5559e+01, -1.0363e+01,  5.4684e+00,
         -4.3587e-01,  3.9582e+00, -2.2050e+00],
        [-1.4502e-01, -5.6672e+00,  1.1886e+01, -7.3239e+00,  1.5324e-01,
          3.3590e+00, -3.8100e-01, -1.5035e+00],
        [-2.2594e+00, -7.2923e+00,  1.6462e+01, -9.9108e+00,  3.0486e+00,
          1.9537e+00,  6.6871e-01, -2.0633e+00],
        [-3.8152e+00, -5.2778e+00,  4.9454e+00, -6.0481e+00,  1.9261e+01,
         -6.5942e+00,  2.1948e+00, -3.7977e+00],
        [-4.2658e+00, -1.2351e+00,  6.5656e+00, -5.2466e+00,  2.7161e+00,
         -1.2242e+00,  1.9198e+00,  5.3600e-01],
        [-3.2022e+00,  8.0513e+00, -8.9200e-01,  6.0237e-03, -2.3103e+00,
         -2.6963e+00, -1.6739e+00,  2.7678e+00],
        [ 4.4333e-01, -6.0562e+00,  4.8351e+00, -5.5087e+00,  1.7452e+01,
         -6.1309e+00, -1.5197e-01, -4.2000e+00],
        [-4.6054e+00, -6.5110e+00,  1.5423e+01, -1.0009e+01,  4.2013e+00,
         -9.6640e-03,  4.5346e+00, -2.7525e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 2, 2, 2, 2, 6, 4, 2, 0, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 0, 2, 2, 0,
        2, 2, 2, 4, 2, 1, 4, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-7.6238e+00, -8.8133e+00,  2.0547e+01, -1.3661e+01,  6.9453e+00,
         -5.4239e-01,  6.5755e+00, -3.1121e+00],
        [-5.0913e+00, -7.0526e+00,  1.6830e+01, -1.1114e+01,  5.3907e+00,
         -3.3873e-01,  4.4056e+00, -2.8556e+00],
        [-1.6008e+00, -7.8815e+00,  1.7725e+01, -1.0798e+01,  3.1078e+00,
          2.1168e+00,  6.0300e-01, -2.5865e+00],
        [-1.5623e+00, -2.3502e+00,  9.3221e+00, -4.4731e+00,  2.1670e+00,
         -3.2979e-01, -6.0237e-01, -1.7892e+00],
        [-1.3316e+00, -2.3394e+00,  9.3390e+00, -4.5090e+00,  2.3149e+00,
         -1.6925e-01, -1.1127e+00, -1.7989e+00],
        [-5.5082e+00, -5.8435e+00,  1.3003e+01, -8.5330e+00,  4.9046e+00,
         -6.0138e-01,  5.4213e+00, -2.3677e+00],
        [-3.5179e+00, -4.6071e+00,  4.6782e+00, -6.0889e+00,  1.7152e+01,
         -6.2522e+00,  3.0881e+00, -3.2170e+00],
        [-3.4776e+00, -6.2123e+00,  4.9460e+00, -5.8731e+00,  2.1501e+01,
         -7.0821e+00,  1.9543e+00, -4.3215e+00],
        [ 1.3251e+01, -1.3434e+00,  4.0373e+00, -3.5482e+00, -3.0772e+00,
         -2.1287e+00, -6.6282e+00, -1.8096e+00],
        [-2.3232e+00, -7.0032e+00,  1.5687e+01, -8.3890e+00,  2.9699e+00,
          1.5741e+00,  1.7414e+00, -3.0908e+00],
        [ 1.2708e+01, -4.9249e+00,  5.8662e+00, -4.3657e+00, -2.1408e+00,
         -1.6948e+00, -3.4327e+00, -3.1363e+00],
        [-3.7601e+00, -7.0541e+00,  1.5165e+01, -1.0114e+01,  4.9089e+00,
          7.4920e-03,  3.4396e+00, -2.6923e+00],
        [-2.0284e+00, -6.3859e+00,  1.4737e+01, -7.9287e+00,  2.7445e+00,
          1.6309e+00,  1.0166e+00, -2.8087e+00],
        [-2.3218e+00, -5.7933e+00,  4.7216e+00, -6.2519e+00,  2.0885e+01,
         -7.0144e+00,  1.3411e+00, -4.2286e+00],
        [-9.1373e-01, -3.2859e+00,  2.0967e+00, -4.5480e+00,  1.8850e+01,
         -7.1402e+00, -9.4692e-01, -3.5637e+00],
        [-1.1254e+00, -6.4706e+00,  1.4415e+01, -8.1428e+00,  2.3936e+00,
          1.8530e+00,  7.0136e-01, -2.9148e+00],
        [-5.6357e+00, -5.9200e+00,  8.9011e+00, -7.3412e+00,  2.2876e+00,
         -5.6146e-01,  1.0577e+01, -1.1094e+00],
        [-3.2477e+00, -7.2550e+00,  1.4080e+01, -7.8280e+00,  3.4456e+00,
          9.5410e-01,  3.9188e+00, -3.0619e+00],
        [-9.7096e-01, -6.7496e+00,  1.3494e+01, -7.7643e+00,  2.5647e+00,
          1.4725e+00,  1.6984e+00, -3.1949e+00],
        [ 1.3484e+01, -3.8479e+00,  3.9862e+00, -2.9591e+00, -3.1105e+00,
         -1.4266e+00, -5.5660e+00, -2.0434e+00],
        [-1.4476e+00,  2.9712e+00, -2.5738e+00,  1.0558e+01, -2.2436e+00,
         -3.7764e+00, -5.1991e+00,  9.9173e-01],
        [ 9.7516e+00, -4.4014e+00,  4.2417e+00, -4.0332e+00, -1.5148e+00,
         -1.9771e+00,  1.1608e-01, -2.7951e+00],
        [-2.9348e+00, -6.0848e+00,  1.5554e+01, -9.6929e+00,  3.2350e+00,
          2.0366e-01,  3.0010e+00, -2.7250e+00],
        [-5.4491e+00, -7.4602e+00,  1.7503e+01, -1.1583e+01,  4.8022e+00,
         -3.3029e-01,  6.0405e+00, -3.1127e+00],
        [-7.2341e-01, -3.9965e+00,  3.4257e+00, -4.8411e+00,  1.6651e+01,
         -6.1182e+00, -2.0454e-01, -3.5398e+00],
        [-4.8749e+00, -7.7200e+00,  1.7617e+01, -1.1193e+01,  5.1575e+00,
          2.1963e-02,  5.0934e+00, -3.3687e+00],
        [-4.0939e-01, -6.5430e+00,  3.8962e+00, -4.1136e+00,  1.9395e+01,
         -6.6870e+00,  1.1421e-01, -4.7806e+00],
        [-1.9746e+00, -2.8632e+00,  3.3046e+00, -2.3691e+00,  2.0587e+00,
         -1.1263e+00,  4.7086e+00, -1.2053e+00],
        [-4.7964e+00, -6.7741e+00,  1.6685e+01, -1.0301e+01,  4.1750e+00,
          5.3838e-02,  4.3329e+00, -2.8437e+00],
        [-2.7546e+00, -3.5022e+00,  8.0211e+00, -6.6565e+00,  4.9403e+00,
         -1.2154e+00,  1.4772e+00, -4.3611e-01],
        [-4.3827e+00, -4.6730e+00,  1.4864e+01, -9.6299e+00,  1.8367e+00,
          2.0158e-01,  3.4489e+00, -1.3469e+00],
        [ 3.1701e-01, -5.4957e+00,  1.3049e+01, -7.5450e+00,  3.9433e-01,
          2.6343e+00, -8.1843e-01, -2.3279e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 2, 2, 2, 2, 4, 4, 0, 2, 0, 2, 2, 4, 4, 2, 2, 2, 2, 0, 3, 0, 2, 2,
        4, 2, 4, 6, 2, 2, 2, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[ 1.5723e+01, -3.0910e+00,  4.1914e+00, -3.2545e+00, -3.5994e+00,
         -3.2533e+00, -4.8592e+00, -3.2267e+00],
        [-3.5995e+00, -6.9091e+00,  1.4395e+01, -9.7929e+00,  3.4066e+00,
          3.6486e-01,  4.7917e+00, -2.1616e+00],
        [ 3.8030e-01, -1.7062e+00,  3.6848e+00, -2.1831e+00,  2.2988e+00,
         -1.0791e+00, -5.6897e-01, -8.2622e-01],
        [ 9.5161e+00, -1.5140e+00,  3.6253e+00, -2.6069e+00, -3.6281e+00,
         -1.7342e+00, -2.7397e+00, -1.8501e+00],
        [-1.5946e+00, -5.9370e+00,  1.2419e+01, -7.3136e+00,  2.1835e+00,
          1.7173e+00,  1.1890e+00, -2.3824e+00],
        [-7.0347e+00, -4.9462e+00,  1.6184e+01, -1.0374e+01,  6.8483e+00,
         -9.1522e-01,  2.1723e+00, -1.5858e+00],
        [-1.2729e+00, -4.9656e+00,  1.0859e+01, -5.5055e+00,  2.1757e+00,
          1.3634e+00,  2.8394e-01, -2.3935e+00],
        [-1.0291e+00, -5.3256e+00,  3.4699e+00, -5.8850e+00,  2.7183e+01,
         -9.9082e+00, -1.7515e+00, -5.7254e+00],
        [-3.0461e+00, -3.0769e+00,  3.5432e+00, -4.4842e+00,  1.9323e+01,
         -6.9865e+00, -9.3779e-01, -3.3834e+00],
        [-1.8895e+00, -2.3548e+00,  7.1227e+00, -5.0665e+00,  1.7241e+00,
         -1.4763e+00,  3.3612e+00, -1.3757e+00],
        [-4.3892e+00, -4.6258e+00,  1.3358e+01, -8.4851e+00,  3.3179e+00,
         -2.1266e-01,  3.3168e+00, -1.8989e+00],
        [-2.3341e+00, -7.1598e+00,  1.6299e+01, -8.5104e+00,  2.6253e+00,
          1.8230e+00,  1.4437e+00, -3.0777e+00],
        [-4.5221e+00, -6.6097e+00,  1.5421e+01, -1.0015e+01,  5.3223e+00,
         -4.8185e-01,  3.5665e+00, -2.6839e+00],
        [-2.8991e+00, -6.7925e+00,  1.4813e+01, -8.7602e+00,  2.4257e+00,
          1.6539e+00,  2.7697e+00, -2.0387e+00],
        [-6.3591e-01, -4.8239e+00,  1.1489e+01, -6.4320e+00,  6.8672e-01,
          2.0916e+00,  3.3842e-01, -2.0841e+00],
        [-3.0831e+00, -6.6547e+00,  1.3102e+01, -7.2452e+00,  3.4181e+00,
          8.0109e-01,  3.3377e+00, -2.7800e+00],
        [-3.3282e+00, -5.9201e+00,  1.6285e+01, -1.0067e+01,  2.8907e+00,
          5.5080e-01,  2.1980e+00, -2.3094e+00],
        [-1.3436e+00, -5.3860e+00,  1.4428e+01, -7.4810e+00,  2.6691e+00,
          1.3977e+00, -8.2236e-01, -2.6978e+00],
        [ 7.7117e+00, -1.7104e+00,  1.8423e+00, -1.0645e+00, -2.9327e+00,
         -6.8862e-01, -3.2125e+00, -9.8569e-01],
        [-4.0398e+00, -6.8681e+00,  1.0420e+01, -7.3891e+00,  2.4175e+00,
          2.4389e+00,  3.7324e+00, -4.6507e-01],
        [-4.2822e+00, -7.4474e+00,  1.8004e+01, -1.1264e+01,  4.5845e+00,
          4.9605e-01,  2.9493e+00, -3.1150e+00],
        [-5.0810e-01, -1.0499e+00,  2.1689e+00, -2.2828e+00,  4.1253e+00,
         -9.1519e-01, -2.6056e+00,  4.2712e-01],
        [-3.1591e+00, -6.1158e+00,  1.4447e+01, -9.1998e+00,  3.1449e+00,
          2.0793e-01,  3.3195e+00, -2.3875e+00],
        [-1.7300e+00, -2.4783e+00,  3.0329e+00, -2.1416e+00,  5.1178e+00,
         -1.8736e+00,  2.0733e+00, -1.5152e+00],
        [ 1.5041e+01, -3.0891e+00,  5.5170e+00, -4.6331e+00, -4.1724e+00,
         -3.1462e+00, -3.8805e+00, -3.4371e+00],
        [ 1.0749e+01, -3.2724e+00,  4.5191e+00, -2.8807e+00, -2.8553e+00,
         -2.2295e+00, -2.4108e+00, -2.8494e+00],
        [-1.6080e+00, -7.1341e+00,  1.5527e+01, -8.5559e+00,  3.0162e+00,
          1.8204e+00,  7.0101e-01, -3.3632e+00],
        [-8.0139e-01, -6.3109e+00,  1.3373e+01, -7.9854e+00,  2.7229e+00,
          1.4905e+00,  8.0009e-01, -2.8776e+00],
        [-4.3252e+00, -8.4884e+00,  1.8080e+01, -1.1201e+01,  5.6116e+00,
          4.6687e-01,  3.8466e+00, -3.5358e+00],
        [-5.4968e+00, -7.6965e+00,  1.8075e+01, -1.1547e+01,  5.1039e+00,
         -4.6529e-03,  5.1501e+00, -3.2044e+00],
        [-1.8860e+00, -6.2152e+00,  1.3629e+01, -7.8906e+00,  2.2256e+00,
          1.5733e+00,  1.6205e+00, -1.8867e+00],
        [-4.6841e+00, -4.4309e+00,  5.4079e+00, -5.8945e+00,  2.4331e+00,
         -1.7085e+00,  1.0545e+01, -8.1495e-01]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([0, 2, 2, 0, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 4, 2, 4,
        0, 0, 2, 2, 2, 2, 2, 6], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-2.9351e+00, -6.4073e+00,  1.2652e+01, -7.1393e+00,  3.5152e+00,
          5.2523e-01,  3.6418e+00, -2.7963e+00],
        [-1.8809e+00, -7.0208e+00,  1.6039e+01, -8.5332e+00,  2.9195e+00,
          1.6683e+00,  1.0971e+00, -3.2024e+00],
        [-7.6075e-01, -5.9655e+00,  1.3864e+01, -8.1601e+00,  1.2846e+00,
          1.6132e+00,  7.5088e-01, -1.9008e+00],
        [-4.4001e+00, -5.5927e+00,  1.3209e+01, -9.1599e+00,  3.5385e+00,
          5.7651e-03,  3.9646e+00, -1.4682e+00],
        [-2.3193e+00, -7.2182e+00,  1.6160e+01, -8.6337e+00,  3.2127e+00,
          1.4706e+00,  1.8027e+00, -3.4246e+00],
        [-1.2137e+00, -6.9150e+00,  1.4950e+01, -8.2056e+00,  2.8550e+00,
          1.6046e+00,  1.0341e+00, -3.2516e+00],
        [-2.1455e+00, -7.2556e+00,  1.6391e+01, -1.0297e+01,  3.3839e+00,
          1.9340e+00,  6.2738e-01, -2.0351e+00],
        [-6.5135e+00, -6.6528e+00,  1.6004e+01, -1.1265e+01,  6.7509e+00,
         -8.6200e-01,  4.7514e+00, -1.9924e+00],
        [-1.3958e+00, -2.7606e+00,  5.3562e+00, -2.8674e+00,  2.4980e+00,
         -7.6291e-01,  2.1852e+00, -1.5949e+00],
        [-3.6476e+00, -3.6218e+00,  3.8386e+00, -5.0412e+00,  1.5078e+01,
         -5.6432e+00,  2.8758e+00, -2.9040e+00],
        [-3.0666e+00, -6.4622e+00,  1.4199e+01, -9.0619e+00,  3.1424e+00,
          3.5328e-01,  3.9756e+00, -2.5763e+00],
        [ 1.0016e+01,  2.7684e-01,  2.7186e+00, -1.9078e+00, -4.9725e+00,
         -1.9027e+00, -4.1300e+00, -9.1225e-01],
        [ 1.2952e+01,  6.0240e-01,  2.5349e+00, -2.1284e+00, -1.3469e+00,
         -4.5392e+00, -5.9486e+00, -3.2171e+00],
        [-1.7264e+00,  7.9470e+00, -9.2432e-01,  7.9701e-01, -2.9012e+00,
         -3.0815e+00, -2.5284e+00,  2.7296e+00],
        [ 8.7149e-02,  2.2776e+00,  4.0485e-04,  6.9963e-01, -2.4455e+00,
         -1.7836e+00,  3.1325e-01,  6.8836e-01],
        [ 1.1066e+01, -4.6675e+00,  5.0334e+00, -4.4068e+00, -1.0643e+00,
         -1.2457e+00, -2.9390e+00, -2.5706e+00],
        [-1.9069e+00, -5.8545e+00,  3.0140e+00, -4.9108e+00,  2.3573e+01,
         -8.2891e+00,  3.4610e-01, -4.8552e+00],
        [-1.8151e+00, -4.6771e+00,  1.2374e+01, -6.9624e+00,  1.9560e+00,
          2.1192e+00, -7.2286e-01, -1.6740e+00],
        [-3.0288e+00, -5.5051e+00,  1.3960e+01, -9.2306e+00,  3.9002e+00,
         -5.1031e-01,  3.3125e+00, -2.7413e+00],
        [-2.4701e+00, -7.1368e+00,  1.6316e+01, -1.0256e+01,  2.4552e+00,
          2.4607e+00,  9.9153e-01, -1.6623e+00],
        [-3.0356e+00, -6.4773e+00,  1.5300e+01, -9.3755e+00,  2.7330e+00,
          1.9206e+00,  1.8458e+00, -1.9347e+00],
        [-5.6612e+00, -8.8462e+00,  1.7833e+01, -1.1870e+01,  5.8619e+00,
          2.5081e-01,  5.7282e+00, -2.8515e+00],
        [-8.2497e-01, -7.1034e+00,  1.5773e+01, -9.0609e+00,  2.7507e+00,
          1.9546e+00,  7.3222e-01, -3.3918e+00],
        [-1.5332e+00, -4.4570e+00,  7.6977e+00, -4.7548e+00,  6.5313e-01,
          2.8110e+00,  4.2393e-01, -3.8771e-01],
        [-2.0833e+00, -5.7731e+00,  1.4196e+01, -9.2652e+00,  1.8585e+00,
          1.7666e-01,  3.5561e+00, -2.2893e+00],
        [-6.2360e-01, -5.0179e+00,  1.0971e+01, -6.5417e+00,  1.6498e+00,
          2.6470e+00, -1.6640e+00, -1.2225e+00],
        [-3.4503e+00, -5.0074e+00,  1.3042e+01, -9.0379e+00,  3.0187e+00,
         -2.2545e-01,  3.3330e+00, -1.5950e+00],
        [ 7.0181e-02, -2.1197e+00,  1.7796e+00, -1.4926e+00,  7.1288e+00,
         -3.2256e+00, -7.0101e-03, -1.6646e+00],
        [-2.4369e+00, -3.9525e+00,  1.3368e+01, -8.7641e+00,  3.4148e+00,
         -6.4614e-01,  1.0342e+00, -1.8309e+00],
        [ 1.1024e+01, -4.3353e+00,  4.2894e+00, -3.3760e+00, -1.8708e+00,
         -9.0113e-01, -3.4818e+00, -2.2735e+00],
        [-2.3257e+00, -7.2636e+00,  1.6492e+01, -1.0201e+01,  3.1232e+00,
          2.3779e+00,  4.2194e-01, -1.8535e+00],
        [-2.2395e+00, -6.9850e+00,  1.5419e+01, -8.0778e+00,  2.6470e+00,
          1.6852e+00,  1.6634e+00, -2.9778e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 0, 0, 1, 1, 0, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 4, 2, 0, 2, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[ -2.3259,  -2.4091,  11.7006,  -6.6454,   1.5713,   0.8167,  -2.1185,
          -0.6658],
        [ -3.8967,  20.5635,  -1.7128,   1.0009,  -5.1343,  -6.3617,  -8.6305,
           5.0490],
        [ -2.9056,  -6.2632,  12.4782,  -6.9597,   3.4574,   0.7174,   3.1709,
          -2.6782],
        [ -4.8175,  -6.8235,  17.1452, -10.8873,   4.4807,   0.1460,   4.0081,
          -2.7167],
        [ -3.8886,  -6.3149,  16.3675, -10.2926,   3.3406,  -0.0350,   4.2271,
          -2.7660],
        [ -5.3997,  -7.8283,  18.1954, -11.7004,   4.7084,  -0.1856,   6.1199,
          -3.4017],
        [ -5.8018,  -7.0270,  17.7650, -11.4685,   5.3633,  -0.1756,   4.5993,
          -2.7113],
        [ -0.7524,  -5.1137,  11.2291,  -6.1625,   1.3895,   2.2020,   0.1083,
          -2.0219],
        [ 14.2743,  -3.6036,   5.4700,  -3.8389,  -3.5691,  -2.5425,  -4.6509,
          -3.1578],
        [ -1.8172,  -6.3290,  13.4208,  -7.3515,   2.9393,   1.9793,   0.5255,
          -2.5166],
        [ -1.3382,  -2.3051,   9.7845,  -4.5186,   1.9878,  -0.2838,  -1.0577,
          -1.9381],
        [ -3.2897,  -4.7790,   4.0719,  -6.0439,  22.1104,  -7.7772,   1.1809,
          -4.1768],
        [ -1.3533,  -2.4267,  10.9724,  -5.2394,   1.7917,   0.0787,  -1.5909,
          -1.9101],
        [ -1.8223,  -5.3812,  11.6324,  -6.4232,   2.0030,   1.8526,   0.9697,
          -1.8683],
        [ -2.1064,  -5.5194,  10.9800,  -6.7792,   3.7260,   1.1192,   0.8817,
          -2.0096],
        [ -3.9674,  -5.9175,  15.4608,  -9.8576,   3.4231,   0.8038,   1.9543,
          -1.6217],
        [ -3.4681,  -5.5657,  14.8175,  -9.7672,   3.0267,  -0.2074,   3.8551,
          -2.2343],
        [ -1.6684,  -5.5528,  14.1175,  -7.5048,   3.4497,   0.9584,  -0.2941,
          -2.9071],
        [ -0.9184,  -5.2002,   4.0587,  -4.7934,  16.4447,  -5.7763,   0.8354,
          -3.9211],
        [ -2.7055,  -6.5835,  14.6011,  -8.8133,   3.3907,   1.3552,   1.2686,
          -2.0279],
        [ -0.8845,  -5.7655,  14.3232,  -8.1658,   1.3002,   1.5499,   0.6726,
          -2.2412],
        [ -1.2869,  -7.2588,  15.2336,  -8.1807,   2.4776,   1.7948,   1.4228,
          -2.9968],
        [ -2.8182,  -6.9978,  14.2231,  -9.2413,   1.6732,   0.5216,   5.7363,
          -2.4216],
        [  0.3873,  -4.0437,   8.9354,  -4.9106,   1.9725,  -0.0957,   0.3736,
          -2.3620],
        [ 11.6997,  -4.8565,   5.0507,  -3.8015,  -1.8410,  -1.5780,  -2.6591,
          -2.9024],
        [ -1.9486,  -6.3412,   4.9930,  -6.7466,  24.6093,  -8.4522,   0.3000,
          -5.2738],
        [ -0.0735,  -5.1970,   4.0338,  -4.3507,  13.7066,  -4.7531,   0.5702,
          -3.4057],
        [ -3.0889,  -6.3992,  15.8287, -10.0653,   2.1789,   0.3052,   4.6738,
          -2.5304],
        [ -3.4699,  -7.4399,   6.4921,  -7.8695,  28.1387,  -9.3178,   0.7445,
          -5.8698],
        [ -1.6390,  -2.6119,   7.8317,  -3.7828,   2.5524,  -0.4895,   0.1538,
          -1.7989],
        [ -2.6981,  -8.0065,  14.8650,  -9.4802,   2.9292,   2.7367,   2.2100,
          -1.7000],
        [  9.9114,  -4.9221,   4.7995,  -3.8832,  -0.1517,  -2.0243,  -0.9545,
          -3.1333]], device='cuda:0', grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2,
        0, 4, 4, 2, 4, 2, 2, 0], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[  8.7683,  -3.1096,   4.4486,  -3.1420,  -3.6701,  -1.5979,  -0.4165,
          -2.3326],
        [ -1.8515,  -2.8229,   8.7008,  -4.2829,   2.5291,  -0.3523,   0.2211,
          -1.8526],
        [ -4.1779,  12.9897,  -2.2161,   1.4704,  -3.3159,  -3.5901,  -5.6537,
           5.1847],
        [ -0.5491,  -5.6584,  11.8484,  -6.7374,   2.3643,   0.9696,   0.7243,
          -2.6924],
        [ -3.2821,  -7.1322,  15.7653,  -9.9893,   2.8674,   0.4721,   4.6620,
          -2.8172],
        [ -3.5782,  -8.0836,  17.1628, -10.8826,   3.5012,   0.4221,   4.8825,
          -3.2330],
        [ -3.9207,  -2.0297,  11.8809,  -6.9669,   2.1354,   0.6640,  -1.4771,
          -0.2651],
        [ -5.4339,  -7.0616,  15.5166,  -9.7317,   4.1105,   0.2920,   5.7995,
          -2.5419],
        [ -3.7722,  -5.9889,  14.8894,  -9.5977,   3.3601,   0.0604,   3.9890,
          -2.4320],
        [ -4.7557,  -6.4874,  16.1487, -10.7817,   5.4515,  -0.7595,   4.2810,
          -2.9504],
        [ -2.2941,  -6.3872,  14.5875,  -9.8989,   1.7964,   0.1257,   5.3835,
          -2.6163],
        [ -5.6187,  -7.0888,  17.7090, -11.3973,   5.3949,  -0.7100,   5.2811,
          -3.3136],
        [ -1.9795,  -6.5513,  14.9699,  -8.0888,   2.9764,   1.5094,   1.2355,
          -3.0656],
        [ -0.5841,  -4.7295,   8.6995,  -5.0824,   2.2088,  -0.2300,   2.6577,
          -2.6424],
        [  6.9937,  -3.1589,   3.3966,  -2.8372,  -0.9432,   0.0553,  -3.4502,
          -0.6595],
        [ -4.0780,  -8.3291,  18.9144, -11.3973,   4.6577,   0.7740,   3.3457,
          -3.4097],
        [ -3.5809,  20.1772,  -1.1537,   0.3581,  -5.6480,  -6.2026,  -8.0518,
           4.9732],
        [ -1.8847,  -6.5912,  14.4374,  -7.7359,   2.6980,   1.4946,   1.4712,
          -2.8405],
        [ 12.8913,  -2.5959,   4.3160,  -3.3759,  -2.2863,  -2.6548,  -4.8029,
          -2.8445],
        [ 12.1229,  -0.0524,   3.8020,  -1.7460,  -5.9553,  -2.6382,  -4.6921,
          -2.0571],
        [  1.6980,  -5.3342,   2.9129,  -5.0046,  22.2444,  -8.4652,  -2.1671,
          -5.1473],
        [ -4.9418,  -6.4094,  16.2175, -10.7177,   5.1076,  -0.3604,   4.3555,
          -2.8649],
        [ -4.4147,  -6.7667,  16.5822, -10.8476,   5.5165,  -0.5608,   4.1009,
          -3.1885],
        [ -4.4349,  -6.9767,  15.4143, -10.5076,   4.9173,  -0.2088,   4.7454,
          -2.5610],
        [ -3.1460,  -6.5535,  14.2945,  -9.2524,   2.3575,   0.4854,   4.6483,
          -2.3751],
        [ -1.2986,  -6.0434,  15.6224,  -8.1969,   3.2728,   1.4136,  -0.7465,
          -3.1469],
        [  9.8962,  -2.5339,   2.9663,  -2.6623,  -1.3343,  -2.6254,  -2.0033,
          -2.5095],
        [ -5.2597,  -7.3517,  16.6463, -10.9338,   5.3198,  -0.5370,   5.4903,
          -3.1112],
        [ -0.3995,  -5.4019,  11.1308,  -7.8735,   0.7853,   0.3902,   3.2196,
          -1.7702],
        [ -4.7424,  -6.7857,  16.1037, -10.4267,   5.7467,  -0.3292,   3.7186,
          -2.9903],
        [ -2.8037,  -6.8266,  14.8885,  -8.0626,   3.9862,   0.9116,   1.8000,
          -3.3440],
        [ -2.2808,  -6.4597,  14.9047,  -8.0216,   2.8451,   1.5205,   1.3965,
          -2.8243]], device='cuda:0', grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 0, 0, 4, 2, 2, 2,
        2, 2, 0, 2, 2, 2, 2, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-2.6817e+00, -5.8891e+00,  1.2080e+01, -7.8148e+00,  3.0603e+00,
          2.8444e-01,  3.4250e+00, -2.0395e+00],
        [-5.7815e+00, -7.7777e+00,  1.8791e+01, -1.1707e+01,  5.6372e+00,
         -2.6279e-01,  5.3120e+00, -3.7684e+00],
        [-4.0038e+00, -2.8612e+00,  3.7132e+00, -5.4944e+00,  1.8719e+01,
         -7.0406e+00,  9.5716e-01, -3.2039e+00],
        [-3.5601e+00, -8.1502e+00,  1.7992e+01, -1.1410e+01,  4.4380e+00,
          1.6634e-01,  4.5350e+00, -3.5907e+00],
        [-2.1336e+00, -5.4754e+00,  5.5441e+00, -6.7088e+00,  2.2725e+01,
         -7.7907e+00, -2.1004e-01, -4.8646e+00],
        [-3.6324e+00, -5.5929e+00,  9.9234e+00, -6.9950e+00,  1.8149e+00,
          1.8639e+00,  3.4939e+00, -5.9726e-01],
        [-1.8789e+00, -6.4283e+00,  1.5533e+01, -8.0507e+00,  2.5037e+00,
          1.5907e+00,  4.6436e-01, -3.0399e+00],
        [-2.6577e+00, -7.8932e+00,  1.7464e+01, -1.1241e+01,  3.3993e+00,
          2.7253e-01,  4.4597e+00, -3.5583e+00],
        [-4.8615e+00, -8.1897e+00,  1.9350e+01, -1.2305e+01,  4.0639e+00,
          6.0901e-01,  5.3321e+00, -3.2150e+00],
        [ 1.2648e+01, -2.3529e+00,  4.1219e+00, -2.7967e+00, -4.1646e+00,
         -2.7859e+00, -3.1791e+00, -2.7303e+00],
        [-3.6555e-01, -3.3006e+00,  6.2135e+00, -3.7135e+00,  1.7813e+00,
         -4.3924e-01,  1.7604e+00, -1.8974e+00],
        [-1.0377e+00, -4.3739e+00,  4.3759e+00, -4.3300e+00,  1.2525e+01,
         -4.3936e+00,  9.7771e-01, -3.1147e+00],
        [-2.8475e+00, -6.6375e+00,  1.3344e+01, -7.4335e+00,  3.2792e+00,
          8.8069e-01,  3.2802e+00, -2.8076e+00],
        [ 1.1499e+01, -3.4722e+00,  4.0045e+00, -2.4452e+00, -2.0764e+00,
         -2.1908e+00, -3.6898e+00, -2.7419e+00],
        [-4.9773e-01, -4.1255e+00,  2.4249e+00, -3.7165e+00,  1.6283e+01,
         -5.7993e+00, -3.6111e-01, -3.6097e+00],
        [-1.0021e+00, -4.6267e+00,  1.0377e+01, -6.3283e+00,  1.8753e+00,
          2.3044e+00, -1.2906e+00, -1.1305e+00],
        [-4.4039e+00, -7.1721e+00,  6.1157e+00, -6.8788e+00,  2.0638e+01,
         -6.8905e+00,  4.2475e+00, -4.4561e+00],
        [-1.8614e-01, -6.3102e+00,  1.4589e+01, -8.9323e+00,  2.0023e+00,
          1.8553e+00, -5.1323e-01, -2.0459e+00],
        [-7.7374e-01, -6.0276e+00,  1.4185e+01, -7.6628e+00,  2.4670e+00,
          1.2694e+00,  2.4942e-01, -2.8991e+00],
        [-2.3153e+00, -3.3714e+00,  8.3284e+00, -5.2694e+00,  1.8986e+00,
         -1.2677e+00,  3.9663e+00, -1.5767e+00],
        [-5.3297e+00, -3.1850e+00,  1.1002e+01, -7.2470e+00,  4.6680e+00,
         -1.4300e+00,  2.7490e+00, -7.9595e-01],
        [-3.1614e+00, -6.7496e+00,  1.3100e+01, -9.1159e+00,  3.4756e+00,
          5.0581e-03,  5.0350e+00, -2.3083e+00],
        [-4.4699e+00, -4.6190e+00,  1.1118e+01, -7.9333e+00,  2.5720e+00,
         -3.7999e-01,  5.3675e+00, -1.2519e+00],
        [-1.6045e+00, -5.3622e+00,  1.0066e+01, -6.4361e+00,  2.1310e+00,
          1.7495e+00,  1.5929e+00, -1.7997e+00],
        [ 1.4719e+01, -1.8441e+00,  4.6150e+00, -3.2658e+00, -5.3980e+00,
         -3.2052e+00, -4.1678e+00, -3.0437e+00],
        [-3.9246e+00, -7.5802e+00,  1.6708e+01, -1.0510e+01,  3.3171e+00,
          6.9336e-01,  4.5419e+00, -2.8077e+00],
        [-3.3736e+00, -6.7167e+00,  1.5641e+01, -1.0277e+01,  3.4276e+00,
          1.9692e-01,  4.1534e+00, -2.6897e+00],
        [-2.4952e+00, -6.5173e+00,  1.4921e+01, -8.0661e+00,  2.9612e+00,
          1.5505e+00,  1.4848e+00, -2.8240e+00],
        [-2.0982e+00, -6.3462e+00,  1.5331e+01, -8.2361e+00,  2.8109e+00,
          2.3365e+00, -2.6898e-01, -2.6444e+00],
        [-4.9431e+00, -6.2771e+00,  1.6537e+01, -1.0349e+01,  5.2643e+00,
         -5.0492e-01,  3.5056e+00, -3.0018e+00],
        [ 1.2240e+01, -5.5056e+00,  4.6016e+00, -3.8398e+00, -7.5134e-01,
         -1.6909e+00, -3.2275e+00, -2.9972e+00],
        [-2.9107e+00, -6.4939e+00,  1.3956e+01, -9.2562e+00,  2.9831e+00,
          4.3071e-01,  3.8699e+00, -2.1181e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 4, 2, 4, 2, 2, 2, 2, 0, 2, 4, 2, 0, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2,
        0, 2, 2, 2, 2, 2, 0, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-3.8974e+00, -8.4608e+00,  1.7175e+01, -1.0793e+01,  4.0336e+00,
          6.8310e-01,  4.8380e+00, -3.2838e+00],
        [ 5.2535e-02, -5.0864e+00,  9.1874e+00, -5.5527e+00,  9.6292e-01,
          2.1540e+00,  1.0448e-01, -1.5379e+00],
        [ 3.0871e+00, -3.0006e+00,  3.5389e+00, -1.7963e+00, -5.5269e-01,
         -4.1465e-01,  7.6360e-02, -1.3116e+00],
        [-3.0313e+00, -7.6009e+00,  1.6151e+01, -1.0244e+01,  4.1076e+00,
          1.0373e-01,  3.8771e+00, -3.3530e+00],
        [-5.2411e+00, -5.1067e+00,  1.2810e+01, -9.0131e+00,  5.0862e+00,
         -8.2537e-01,  3.9181e+00, -1.4974e+00],
        [-4.7602e+00, -5.6504e+00,  1.3285e+01, -9.5313e+00,  5.0464e+00,
         -4.9721e-01,  3.3050e+00, -1.3253e+00],
        [-3.3511e+00, -7.0339e+00,  1.3997e+01, -7.7837e+00,  3.5293e+00,
          9.5837e-01,  3.7106e+00, -3.0054e+00],
        [-6.4906e-01, -2.5731e+00,  8.2480e+00, -4.6066e+00,  7.8402e-01,
          3.1845e-01,  2.9710e-01, -1.4496e+00],
        [ 1.2464e+01, -2.8337e+00,  4.8327e+00, -3.6463e+00, -2.9444e+00,
         -2.4848e+00, -3.5130e+00, -2.7848e+00],
        [-2.3762e+00, -2.4865e+00,  1.1658e+01, -6.6407e+00,  1.6206e+00,
          8.2484e-01, -1.9951e+00, -6.4075e-01],
        [ 1.3403e+01, -3.7026e+00,  4.3743e+00, -4.1796e+00, -1.9327e+00,
         -2.9950e+00, -3.1332e+00, -3.1317e+00],
        [-1.6884e+00, -5.8422e+00,  1.4882e+01, -7.7917e+00,  3.3452e+00,
          1.3517e+00, -4.5454e-01, -2.9547e+00],
        [-2.2025e-01, -1.7140e+00,  8.3760e+00, -3.7964e+00,  8.2959e-01,
         -1.0713e-01, -1.6803e+00, -1.5662e+00],
        [-2.8997e+00, -6.5995e+00,  1.4286e+01, -9.5707e+00,  4.0468e+00,
          2.4215e-01,  2.8091e+00, -2.2431e+00],
        [ 1.2254e+01, -8.1894e-01,  3.3459e+00, -2.4490e+00, -1.9299e+00,
         -3.1151e+00, -6.0274e+00, -2.5569e+00],
        [-1.2989e+00, -2.6444e+00,  9.2938e+00, -4.6466e+00,  1.9850e+00,
          8.2050e-03, -5.6585e-01, -1.9341e+00],
        [-1.3976e+00, -6.7678e+00,  5.1484e+00, -6.5055e+00,  2.1787e+01,
         -7.3253e+00,  9.1323e-01, -4.9173e+00],
        [-8.7686e-01, -6.2561e+00,  5.1462e+00, -6.0282e+00,  2.1154e+01,
         -7.0985e+00, -3.0817e-02, -5.0415e+00],
        [-6.0068e-01, -6.2231e+00,  1.4881e+01, -8.3462e+00,  1.4137e+00,
          2.9543e+00, -1.0526e+00, -2.5123e+00],
        [-6.1674e+00, -6.6142e+00,  1.5272e+01, -9.8313e+00,  3.8849e+00,
          3.3926e-01,  5.7092e+00, -1.8858e+00],
        [-3.2425e+00, -5.4998e+00,  5.0003e+00, -6.1619e+00,  2.0348e+01,
         -7.0640e+00,  1.6614e+00, -3.8742e+00],
        [-3.5745e+00, -3.9566e+00,  3.7703e+00, -5.2628e+00,  1.8857e+01,
         -6.5396e+00,  1.2124e+00, -3.2806e+00],
        [-3.7253e+00, -5.9411e+00,  5.0560e+00, -6.0127e+00,  2.0938e+01,
         -7.3294e+00,  2.4829e+00, -4.2946e+00],
        [-4.1901e+00, -6.4414e+00,  1.7188e+01, -1.0941e+01,  3.6572e+00,
         -3.3615e-02,  4.0582e+00, -2.9101e+00],
        [-5.1048e+00, -7.0577e+00,  1.9220e+01, -1.1942e+01,  4.9390e+00,
          6.5834e-02,  3.2800e+00, -3.0084e+00],
        [-8.2487e-01, -4.7532e+00,  3.2008e+00, -5.1909e+00,  2.3046e+01,
         -8.2943e+00, -1.6616e+00, -4.8247e+00],
        [-3.4016e+00, -6.6078e+00,  1.4934e+01, -9.5654e+00,  2.6503e+00,
          6.1813e-01,  4.0509e+00, -2.4027e+00],
        [-3.7317e+00, -7.4063e+00,  1.7065e+01, -1.0887e+01,  3.4551e+00,
          2.8645e-01,  5.2262e+00, -3.0998e+00],
        [-1.9884e+00, -7.3776e+00,  1.5806e+01, -9.9900e+00,  2.5488e+00,
          8.3099e-01,  3.6830e+00, -3.1393e+00],
        [-5.7153e+00, -7.7540e+00,  1.7289e+01, -1.1462e+01,  5.0573e+00,
         -4.2015e-01,  6.6884e+00, -3.1562e+00],
        [-2.4308e+00, -5.8631e+00,  1.3938e+01, -9.3126e+00,  1.4661e+00,
          4.6078e-01,  4.2895e+00, -2.0235e+00],
        [-8.9428e-01, -6.7240e+00,  1.4870e+01, -8.8012e+00,  1.3235e+00,
          1.9416e+00,  1.7159e+00, -2.5700e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 4, 4, 2, 2, 4, 4, 4, 2,
        2, 4, 2, 2, 2, 2, 2, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[ -2.3274,  -4.8555,  11.3658,  -6.6661,   3.4175,  -0.4789,   2.1769,
          -2.4833],
        [ -2.2242,  -6.7746,   5.3390,  -6.5766,  20.4318,  -7.0532,   2.7336,
          -4.6135],
        [ -2.9540,  -6.5504,  16.4412, -10.0959,   3.1795,   0.3915,   2.8095,
          -2.9320],
        [ -4.1264,  -6.9212,  16.4509, -10.5209,   4.9716,   0.0575,   3.0636,
          -2.8812],
        [  0.5162,  -5.2981,   2.2344,  -4.8725,  25.9705,  -9.8285,  -2.6304,
          -5.3054],
        [ -1.3401,  -6.0488,  12.2933,  -7.7579,   1.9275,   2.2530,   0.6434,
          -1.3423],
        [ 14.5795,   1.8017,   2.6529,  -1.7710,  -3.7220,  -4.7061,  -7.3253,
          -2.9376],
        [ -5.3939,  -6.2621,  13.8604,  -8.6231,   4.9314,  -0.1386,   4.6543,
          -2.5320],
        [ -0.9238,  -5.9287,   3.8089,  -5.4493,  26.0451,  -9.2301,  -1.9640,
          -5.1714],
        [ -0.6346,  -3.9861,   4.0126,  -5.2411,  20.2826,  -7.4390,  -1.6632,
          -4.5314],
        [  0.8131,  -1.5796,   6.6195,  -3.5046,   0.8029,  -0.2999,  -1.2835,
          -1.3509],
        [ -2.2340,  -5.3996,  12.6283,  -7.2785,   1.6183,   1.4905,   1.8293,
          -1.6110],
        [ -2.0086,  -6.7031,  15.8376,  -8.3631,   2.4538,   1.4840,   1.2181,
          -3.0757],
        [ -0.9746,  -5.6401,  11.2762,  -6.8370,   1.4837,   1.6938,   1.6372,
          -2.1702],
        [ -3.1878,  13.4308,  -2.7145,   2.0499,  -0.4345,  -5.3470,  -6.5645,
           3.4594],
        [ -1.7481,  -7.7320,  16.3499, -10.2222,   3.4788,   2.2078,   0.1499,
          -2.0537],
        [ -2.0962,  -5.6104,  11.8701,  -6.8206,   2.8416,   1.3786,   1.2300,
          -2.3117],
        [ -2.4385,  -4.3655,   8.4275,  -5.1363,   4.0475,   1.1281,   0.0760,
          -1.2463],
        [ -2.6245,  -6.3781,  14.2149,  -7.8629,   2.9948,   1.6582,   1.4945,
          -2.5842],
        [ -1.3376,  -4.9730,   3.1503,  -4.9083,  22.2748,  -8.1722,  -0.5817,
          -4.6884],
        [ -2.0998,  -3.1035,   3.1770,  -3.2253,   1.4635,  -2.0438,   7.7170,
          -1.0651],
        [ -1.1888,  -6.1504,  15.5398,  -9.2358,   1.7846,   1.2690,   1.5642,
          -2.6524],
        [ -5.5997,  -7.2333,  17.8395, -11.5635,   5.8125,  -0.7156,   4.9903,
          -3.3281],
        [ -3.7054,  -6.0014,  12.9293,  -9.3551,   3.4893,  -0.5914,   5.4878,
          -1.9537],
        [ -2.1162,  -7.2537,   5.4001,  -7.1682,  27.4336,  -9.4150,   0.5506,
          -5.6925],
        [ -1.6220,  -7.2350,  14.4278,  -8.8081,   3.4134,   1.5173,   0.9714,
          -2.3389],
        [ -2.1513,  -6.4980,  13.5604,  -7.7664,   1.6538,   1.1295,   3.4195,
          -2.4282],
        [ -0.3172,  -5.3260,   3.8301,  -4.8883,  16.0680,  -5.1511,  -0.1488,
          -3.5799],
        [ -1.3617,  -6.5507,  15.1305,  -8.0264,   2.4982,   1.5676,   0.8805,
          -3.2088],
        [ -0.3803,  -4.7279,   8.9683,  -5.8782,   2.1817,   1.5879,  -0.1276,
          -1.4111],
        [ -5.2348,  -7.1870,  17.0858, -10.8568,   4.6607,   0.3619,   4.5619,
          -2.7353],
        [ -0.2647,  -5.1325,  12.1076,  -7.0689,   0.2995,   3.1757,  -0.8750,
          -1.5850]], device='cuda:0', grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 4, 2, 2, 4, 2, 0, 2, 4, 4, 2, 2, 2, 2, 1, 2, 2, 2, 2, 4, 6, 2, 2, 2,
        4, 2, 2, 4, 2, 2, 2, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-1.3993e+00, -1.4641e+00,  9.0562e+00, -5.3296e+00,  5.7723e-01,
         -5.4357e-01, -4.4187e-01, -5.4528e-01],
        [-5.4958e+00, -5.9146e+00,  1.7714e+01, -1.1228e+01,  4.1161e+00,
         -3.6279e-01,  4.3465e+00, -2.5604e+00],
        [-5.6544e-01, -6.4309e+00,  1.2174e+01, -7.4275e+00,  2.1668e+00,
          1.7303e+00,  1.5533e+00, -2.6463e+00],
        [-2.4740e+00, -2.7689e+00,  1.3509e+01, -9.3581e+00,  1.8532e+00,
         -1.7166e-01, -2.0093e-01, -4.7116e-01],
        [-1.9437e+00, -4.6822e+00,  3.9979e+00, -6.1462e+00,  2.1780e+01,
         -7.8627e+00,  1.4093e-01, -4.2586e+00],
        [-2.6455e+00, -4.3351e+00,  4.7843e+00, -6.0501e+00,  1.8623e+01,
         -6.5200e+00,  1.0613e+00, -3.7339e+00],
        [ 8.2134e+00, -3.8746e+00,  4.0730e+00, -9.9037e-01, -2.3174e+00,
         -1.8661e+00, -1.5030e+00, -2.6081e+00],
        [-4.8657e-01,  1.2945e+01, -1.6773e+00,  1.0192e+00, -5.2662e+00,
         -4.1620e+00, -5.2806e+00,  3.0577e+00],
        [-1.6075e+00, -2.4884e+00,  3.7073e+00, -2.1832e+00,  3.6904e+00,
         -1.3246e+00,  1.9749e+00, -1.4549e+00],
        [-3.4370e+00, -5.1731e+00,  1.1038e+01, -7.7417e+00,  2.6099e+00,
         -5.3145e-01,  4.8414e+00, -1.5653e+00],
        [-4.1106e+00, -7.2121e+00,  1.7083e+01, -1.0691e+01,  3.7264e+00,
          2.4102e-01,  4.7206e+00, -2.9217e+00],
        [-4.2871e+00, -5.8218e+00,  1.6575e+01, -1.0638e+01,  4.0469e+00,
         -1.8643e-01,  3.3171e+00, -2.5918e+00],
        [-2.7893e+00, -5.4397e+00,  4.2372e+00, -5.1958e+00,  1.6491e+01,
         -5.7364e+00,  2.7481e+00, -3.4414e+00],
        [-1.3482e+00, -2.2572e+00,  8.6537e+00, -4.0105e+00,  2.2082e+00,
         -3.6283e-01, -8.3609e-01, -1.8051e+00],
        [-1.7660e+00, -2.4601e+00,  3.1461e+00, -2.1997e+00,  5.0743e+00,
         -1.8496e+00,  2.0667e+00, -1.5257e+00],
        [-4.1624e+00, -6.4604e+00,  1.7245e+01, -1.0981e+01,  3.6449e+00,
         -1.7300e-02,  4.0299e+00, -2.9229e+00],
        [-1.3421e+00, -7.3008e+00,  5.0526e+00, -6.6042e+00,  2.4575e+01,
         -8.1488e+00,  6.1719e-01, -5.4722e+00],
        [-1.9781e+00, -3.2921e+00,  3.4477e+00, -2.4078e+00,  1.6972e+00,
         -1.0031e+00,  5.0905e+00, -1.1460e+00],
        [ 1.1173e+01, -1.8336e+00,  3.6617e+00, -2.8477e+00, -2.7436e+00,
         -2.6197e+00, -3.2981e+00, -2.5236e+00],
        [-3.0970e+00, -6.4379e+00,  1.4288e+01, -8.6576e+00,  2.5466e+00,
          1.8144e+00,  2.3459e+00, -1.7889e+00],
        [-1.6427e+00, -6.5545e+00,  1.4810e+01, -7.8819e+00,  2.7299e+00,
          1.2158e+00,  1.1363e+00, -3.1706e+00],
        [ 1.1419e+01, -5.1121e-02,  3.0147e+00, -3.1315e+00, -3.4849e+00,
         -2.6201e+00, -4.6613e+00, -1.5030e+00],
        [ 7.9404e+00, -3.9192e+00,  4.1920e+00, -3.6468e+00, -1.0853e+00,
          1.4052e-01, -2.6972e+00, -1.5751e+00],
        [-5.2412e+00, -7.6448e+00,  1.6593e+01, -1.0266e+01,  4.5374e+00,
          4.2245e-01,  5.3367e+00, -3.0398e+00],
        [-8.8850e-01, -4.0263e+00,  8.2481e+00, -4.6035e+00,  3.0033e+00,
         -4.7835e-01,  1.4579e+00, -2.3803e+00],
        [-4.2778e+00, -7.4830e+00,  1.7304e+01, -1.0996e+01,  3.6494e+00,
          2.5849e-01,  4.8244e+00, -2.9279e+00],
        [ 6.0762e+00, -6.7567e-02,  1.6040e+00, -5.5466e-02, -4.0458e+00,
         -1.2586e+00, -2.8389e+00,  1.0665e-01],
        [-3.6087e+00, -7.1813e+00,  1.5682e+01, -9.9003e+00,  2.8120e+00,
          7.3513e-01,  4.8170e+00, -2.6644e+00],
        [-2.2136e+00, -5.8722e+00,  4.5873e+00, -5.8187e+00,  2.0377e+01,
         -7.1005e+00,  1.3366e+00, -4.3113e+00],
        [-5.7053e+00, -4.7738e+00,  1.4910e+01, -1.0308e+01,  6.7192e+00,
         -1.0088e+00,  1.8561e+00, -1.5939e+00],
        [-1.3424e+00, -6.0083e+00,  1.5215e+01, -7.9864e+00,  2.8580e+00,
          1.7097e+00, -6.3483e-01, -2.8932e+00],
        [-3.1991e+00, -5.5558e+00,  5.1561e+00, -6.5846e+00,  2.3021e+01,
         -7.6169e+00,  5.7775e-01, -4.2041e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 2, 2, 4, 4, 0, 1, 4, 2, 2, 2, 4, 2, 4, 2, 4, 6, 0, 2, 2, 0, 0, 2,
        2, 2, 0, 2, 4, 2, 2, 4], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-2.4919e+00, -6.5117e+00,  1.5416e+01, -9.6023e+00,  2.3001e+00,
          3.7877e-01,  4.2532e+00, -3.0348e+00],
        [-2.4289e+00,  2.6870e+00, -3.4841e+00,  1.1035e+01, -3.3766e+00,
         -3.5489e+00, -3.5414e+00,  1.3656e+00],
        [-3.6960e+00, -3.9734e+00,  3.2572e+00, -5.5939e+00,  2.3230e+01,
         -8.5093e+00,  4.5101e-01, -4.1913e+00],
        [-5.7181e+00, -7.9603e+00,  1.8583e+01, -1.1919e+01,  5.2898e+00,
         -3.6233e-01,  5.9864e+00, -3.4408e+00],
        [-6.9689e+00, -8.8645e+00,  1.9413e+01, -1.3015e+01,  7.0823e+00,
         -7.2099e-02,  5.9058e+00, -3.0341e+00],
        [-1.2383e+00, -4.5420e+00,  1.1132e+01, -6.7147e+00,  1.1707e+00,
          2.7018e+00, -1.2338e+00, -8.9896e-01],
        [ 9.0912e+00,  4.6457e-01,  6.7834e-01, -1.0505e+00,  1.2817e-01,
         -3.4648e+00, -5.3897e+00, -1.3684e+00],
        [-3.6661e+00, -5.8381e+00,  1.5858e+01, -1.0042e+01,  3.3269e+00,
         -3.6235e-01,  3.6897e+00, -2.6320e+00],
        [-4.7098e+00, -6.9446e+00,  1.6891e+01, -1.1114e+01,  4.5047e+00,
          1.9143e-02,  4.8647e+00, -2.8925e+00],
        [-8.5880e-01, -6.5683e+00,  4.0944e+00, -5.4874e+00,  2.4343e+01,
         -8.4832e+00, -8.2770e-01, -5.5025e+00],
        [-2.2721e+00, -7.2158e+00,  1.6778e+01, -1.0508e+01,  2.4491e+00,
          2.6208e+00,  4.7722e-01, -1.8553e+00],
        [-2.8798e+00, -5.3667e+00,  1.0444e+01, -6.9961e+00,  2.9321e+00,
          1.3002e+00,  1.6803e+00, -1.0647e+00],
        [-4.0627e-01, -5.1261e+00,  4.9163e+00, -5.5450e+00,  1.6018e+01,
         -5.6065e+00,  3.6921e-01, -3.8551e+00],
        [-4.6379e+00, -8.4660e+00,  1.8196e+01, -1.1717e+01,  4.2736e+00,
          6.4326e-01,  5.5542e+00, -3.3107e+00],
        [-2.4229e+00, -4.8665e+00,  4.1871e+00, -5.7450e+00,  2.0690e+01,
         -7.2146e+00,  3.8644e-01, -4.0405e+00],
        [-6.1463e+00, -1.4840e-01,  1.0997e+01, -7.5228e+00,  3.7873e+00,
         -1.9492e+00,  1.3359e+00, -2.2054e-01],
        [-3.7406e+00, -6.6409e+00,  5.0722e+00, -6.5484e+00,  2.4172e+01,
         -8.3439e+00,  2.4946e+00, -5.0144e+00],
        [-5.3230e+00, -6.4355e+00,  1.6309e+01, -1.0635e+01,  5.5606e+00,
         -8.0043e-01,  4.4076e+00, -3.0228e+00],
        [-3.0986e+00, -6.6079e+00,  1.3582e+01, -7.5078e+00,  3.6497e+00,
          6.4565e-01,  3.2211e+00, -2.9245e+00],
        [ 1.1374e+01, -1.9582e+00,  3.5408e+00, -2.0947e+00, -2.9970e+00,
         -2.6299e+00, -3.8341e+00, -2.5787e+00],
        [-8.6237e-01, -6.1813e+00,  1.4880e+01, -7.9135e+00,  3.2860e+00,
          1.1165e+00, -5.0532e-01, -3.2199e+00],
        [-1.8112e+00, -6.0815e+00,  1.3272e+01, -8.7682e+00,  2.4203e+00,
          1.5309e-01,  3.7174e+00, -2.6446e+00],
        [-7.2094e+00, -8.0605e+00,  1.7957e+01, -1.2235e+01,  6.1866e+00,
          4.3398e-01,  4.8562e+00, -1.9886e+00],
        [-4.1516e+00, -6.9136e+00,  1.6327e+01, -1.0549e+01,  2.9366e+00,
          3.7406e-01,  5.3245e+00, -2.5674e+00],
        [-3.9378e+00, -7.6156e+00,  1.7949e+01, -1.1044e+01,  3.7547e+00,
          5.3572e-01,  4.6530e+00, -3.3576e+00],
        [-1.9163e+00, -7.8261e-01,  2.1072e+00, -2.7010e+00,  8.2136e+00,
         -3.6074e+00,  1.6602e-01, -1.2390e+00],
        [-1.7888e+00, -3.1760e+00,  8.9412e+00, -4.9513e+00,  2.7789e+00,
         -3.3928e-01,  1.0688e+00, -2.0543e+00],
        [-5.0960e-01, -4.9832e+00,  1.0463e+01, -6.3431e+00,  1.1004e+00,
          2.8211e+00, -1.0143e+00, -1.1379e+00],
        [-1.9075e+00, -6.5843e+00,  1.5087e+01, -8.0767e+00,  2.6774e+00,
          1.4265e+00,  1.5242e+00, -3.0994e+00],
        [-6.4438e-01, -6.4261e+00,  1.1737e+01, -7.1572e+00,  2.6956e+00,
          1.6803e+00,  1.0101e+00, -2.4632e+00],
        [-6.4771e+00, -7.4878e+00,  1.8062e+01, -1.2259e+01,  7.1468e+00,
         -4.1692e-01,  3.7727e+00, -2.4820e+00],
        [-5.5542e+00, -5.3810e+00,  1.4889e+01, -1.0098e+01,  4.6751e+00,
         -7.9067e-01,  4.3260e+00, -1.8987e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 3, 4, 2, 2, 2, 0, 2, 2, 4, 2, 2, 4, 2, 4, 2, 4, 2, 2, 0, 2, 2, 2, 2,
        2, 4, 2, 2, 2, 2, 2, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[ 1.1930e+01, -1.4383e+00,  4.1540e+00, -3.0341e+00, -3.7588e+00,
         -2.7829e+00, -3.4484e+00, -2.6374e+00],
        [-2.0146e+00, -4.4631e+00,  7.2507e+00, -4.8211e+00,  2.2973e+00,
          2.3392e+00,  3.8399e-01, -4.7581e-01],
        [-8.0141e-01, -6.3151e+00,  1.3891e+01, -7.9671e+00,  2.8668e+00,
          1.2782e+00,  6.4583e-01, -3.2269e+00],
        [-1.6455e+00, -5.4767e+00,  1.0966e+01, -6.2008e+00,  2.3427e+00,
          1.1012e+00,  1.5003e+00, -2.0977e+00],
        [-2.0289e+00, -7.4966e+00,  1.6591e+01, -8.9046e+00,  3.2816e+00,
          1.8183e+00,  1.2172e+00, -3.3332e+00],
        [-1.3861e+00, -6.4839e+00,  1.5105e+01, -8.7347e+00,  2.0406e+00,
          1.6285e+00,  1.1438e+00, -2.5512e+00],
        [ 8.1007e+00, -2.1676e+00,  2.9669e+00, -2.3824e+00, -3.1975e+00,
         -1.7852e+00, -7.9287e-01, -1.5714e+00],
        [-5.3130e+00, -4.4265e+00,  1.4661e+01, -1.0184e+01,  6.4812e+00,
         -1.0146e+00,  1.3924e+00, -1.5294e+00],
        [-2.0849e+00, -7.1429e+00,  1.6336e+01, -9.8297e+00,  2.8846e+00,
          2.3579e+00,  3.8687e-01, -1.9802e+00],
        [-4.0284e+00, -6.3631e+00,  1.3102e+01, -8.8973e+00,  2.6595e+00,
          1.5691e-01,  5.9228e+00, -2.0673e+00],
        [-3.9040e+00, -7.1719e+00,  1.6598e+01, -1.0554e+01,  3.8984e+00,
          1.3121e-01,  4.4361e+00, -2.9135e+00],
        [ 3.1150e+00, -4.2982e+00,  5.6654e+00, -4.5834e+00,  1.4388e-02,
          1.2494e+00, -6.9151e-01, -7.3873e-01],
        [ 1.0466e-01, -5.7729e+00,  3.9356e+00, -5.3758e+00,  1.9825e+01,
         -7.0026e+00, -1.1165e-01, -4.4875e+00],
        [ 2.3069e+00, -1.7209e+00,  6.2515e+00, -5.6803e+00,  1.0984e+00,
         -7.2568e-01, -1.2805e+00, -6.9998e-01],
        [ 1.0295e+01, -4.0399e+00,  3.6612e+00, -1.3893e+00, -1.5541e+00,
         -2.2112e+00, -3.0713e+00, -2.8043e+00],
        [-1.8320e+00, -2.7233e+00,  1.0619e+01, -5.1147e+00,  2.1444e+00,
         -3.6548e-02, -7.6331e-01, -1.9380e+00],
        [-1.8012e+00, -5.1964e+00,  1.0384e+01, -6.3946e+00,  3.1533e+00,
          1.5126e+00,  1.9708e-01, -1.6764e+00],
        [-2.4012e+00, -7.1472e+00,  1.6384e+01, -8.6486e+00,  2.6635e+00,
          1.6451e+00,  1.5150e+00, -3.1806e+00],
        [-2.9306e+00, -5.3277e+00,  1.3463e+01, -8.9407e+00,  3.6659e+00,
         -2.3134e-01,  2.8087e+00, -2.5155e+00],
        [-4.9580e+00, -8.2121e+00,  1.8644e+01, -1.1692e+01,  4.5599e+00,
          2.9515e-02,  6.1516e+00, -3.7262e+00],
        [-3.7930e+00, -6.8747e+00,  4.9329e+00, -6.7688e+00,  2.6104e+01,
         -9.0140e+00,  2.2303e+00, -5.1657e+00],
        [-4.1251e+00, -3.2454e+00,  1.0127e+01, -6.8289e+00,  4.1786e+00,
         -1.2089e+00,  2.7357e+00, -1.6454e+00],
        [-2.7122e-01, -1.8620e+00,  8.8492e+00, -4.7530e+00,  7.4414e-01,
          3.3455e-02, -7.8561e-01, -1.5995e+00],
        [-5.2821e+00, -7.3237e+00,  7.1062e+00, -8.0978e+00,  2.6603e+01,
         -9.1366e+00,  3.2009e+00, -5.4220e+00],
        [ 6.4852e+00, -3.5300e+00,  2.7710e+00, -3.1181e+00,  2.3651e+00,
         -2.5354e+00,  5.0128e-02, -2.6562e+00],
        [-4.2727e+00, -6.7464e+00,  1.6908e+01, -1.0567e+01,  3.4176e+00,
          3.6294e-01,  4.2846e+00, -2.7133e+00],
        [-4.7271e+00,  1.7173e+01, -4.3323e+00,  4.1652e+00, -4.6369e+00,
         -5.4170e+00, -7.5150e+00,  5.9382e+00],
        [-5.3000e+00, -7.3552e+00,  1.7168e+01, -1.0989e+01,  4.7253e+00,
         -2.5521e-01,  5.6618e+00, -3.1345e+00],
        [-3.0738e-01, -4.9488e+00,  1.0413e+01, -6.6412e+00,  2.6986e+00,
         -2.8771e-01,  1.8590e+00, -2.5727e+00],
        [ 1.2649e+01, -3.0217e-02,  3.2970e+00, -2.9860e+00, -2.5909e+00,
         -3.6289e+00, -5.4397e+00, -2.5603e+00],
        [-1.3799e+00, -5.9413e+00,  1.3155e+01, -8.0262e+00,  4.2990e+00,
         -1.3837e-01,  1.2834e+00, -3.0774e+00],
        [-4.3921e+00, -5.9769e+00,  1.5371e+01, -9.9562e+00,  3.9946e+00,
         -1.1758e-01,  3.9980e+00, -2.6143e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 4, 2, 0, 2, 2, 2, 2, 2, 4, 2, 2, 4,
        0, 2, 1, 2, 2, 0, 2, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[  8.9529,  -1.1948,   4.4863,  -3.1365,  -3.1064,  -2.0408,  -2.7576,
          -2.1784],
        [  0.1050,  -7.0131,  14.5339,  -8.9641,   2.0609,   1.8062,   0.1510,
          -2.2760],
        [ -1.6235,  -5.1218,  10.7453,  -6.0303,   2.6090,   1.6918,   0.2658,
          -1.8210],
        [  8.9555,  -4.1944,   4.4086,  -3.8597,   0.2230,  -1.2078,  -3.0078,
          -2.3345],
        [ -2.2298,  -6.6361,  12.6667,  -7.6967,   2.1659,   3.4767,   0.2008,
          -1.4277],
        [ -1.2582,  -6.1919,  14.6634,  -8.2938,   1.5882,   1.7593,   1.1595,
          -2.2650],
        [ -4.9082,  -6.4199,  14.9404, -10.2606,   5.5487,  -0.6891,   4.4995,
          -2.3847],
        [ 11.1398,  -4.5345,   5.0559,  -4.0986,  -2.2414,  -0.8777,  -2.9419,
          -2.4316],
        [ -2.1718,  -5.8329,  10.6395,  -6.3472,   2.9218,   1.9539,   1.4634,
          -1.9004],
        [ -1.9104,  -2.9663,   7.1459,  -4.0366,   2.9877,  -0.6299,   1.8366,
          -1.8670],
        [ -6.2305,  -7.2241,  19.1847, -12.4929,   6.3097,   0.1572,   2.6731,
          -2.2043],
        [ -2.4738,  -5.6762,  12.1602,  -8.1663,   0.9046,   0.1160,   5.4471,
          -1.6344],
        [ -0.6707,  -3.5080,   2.9093,  -5.0679,  16.9463,  -6.3264,   0.0516,
          -3.4596],
        [ -4.6287,  -7.5288,  18.1571, -11.6899,   3.8363,   0.2043,   5.5104,
          -3.1127],
        [ -2.1744,  -7.0492,  15.6383,  -8.3490,   3.0393,   1.5796,   1.7213,
          -3.2075],
        [ -3.1929,  -0.3852,   7.2052,  -5.3091,   2.9725,  -1.6402,   1.0287,
          -0.3370],
        [ -2.0996,  -3.4613,   7.2748,  -4.1751,   2.5092,  -0.5795,   3.0562,
          -1.9052],
        [ -1.3953,  -7.9979,  16.7906, -10.2635,   3.3633,   1.8659,   1.0335,
          -2.8234],
        [  1.3868,  -2.1341,   4.3172,  -3.5666,   0.3269,  -1.2893,   2.1434,
          -0.9305],
        [ -4.0512,  -5.1562,   4.6947,  -6.1121,  20.7762,  -7.2568,   2.1158,
          -4.0543],
        [ -1.8425,  -7.0107,  13.1725,  -7.7897,   2.2185,   3.9585,  -0.6045,
          -1.5494],
        [ -3.8665,  -7.6365,  18.0762, -11.3509,   3.4118,   0.7152,   4.3490,
          -2.9844],
        [ -3.6817,  -7.4234,   5.5432,  -7.0754,  21.5030,  -7.1523,   4.0132,
          -4.5077],
        [ -3.9253,  -7.3013,  17.9030, -11.2100,   3.3197,   0.6475,   4.1102,
          -2.9764],
        [ -1.9787,  -6.5664,   5.2059,  -5.9934,  18.9677,  -6.2974,   2.1021,
          -4.4622],
        [ -2.0689,  -2.8975,   3.9386,  -2.5516,   2.3333,  -0.9777,   3.9796,
          -1.2831],
        [ -3.5592,  -6.5833,   5.1961,  -6.6794,  25.0521,  -8.4825,   1.8333,
          -4.8424],
        [  0.2368,  -5.9040,  11.4033,  -6.5978,   1.9890,   2.0963,  -0.7159,
          -2.0587],
        [ -5.8105,  -6.4536,  16.8282, -10.6965,   6.2257,  -0.8887,   4.1339,
          -3.1801],
        [  6.7699,  -3.2309,   2.6378,  -2.3125,  -1.3541,  -0.2192,  -1.5387,
          -1.2860],
        [ -2.6715,  -4.2743,   5.8997,  -3.2492,  -0.1011,  -0.7967,   6.7987,
          -0.9599],
        [ -2.2420,  -5.3431,  14.3634,  -7.6621,   2.8983,   1.2814,  -0.1073,
          -2.5849]], device='cuda:0', grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2,
        4, 6, 4, 2, 2, 0, 2, 2], device='cuda:0')
torch.Size([32])
torch.Size([32, 3, 64, 64])
(32, 3, 64, 64)
tensor([[-1.4498e+00, -7.6454e+00,  1.6823e+01, -1.0158e+01,  2.4741e+00,
          2.3704e+00,  3.4787e-01, -2.2577e+00],
        [-1.7442e+00, -7.4078e+00,  1.6142e+01, -9.9375e+00,  3.1877e+00,
          2.0359e+00,  5.1360e-01, -2.1329e+00],
        [-3.8801e+00, -6.3219e+00,  1.6423e+01, -1.0041e+01,  4.2478e+00,
          1.1416e-01,  2.8132e+00, -2.8712e+00],
        [-5.6538e-01, -7.1385e+00,  1.4312e+01, -9.2726e+00,  2.5319e+00,
          1.7961e+00,  8.7988e-01, -2.2208e+00],
        [-1.7144e+00, -2.7091e+00,  8.0404e+00, -3.8926e+00,  2.5945e+00,
         -4.6740e-01,  1.9906e-01, -1.8331e+00],
        [-3.0723e+00, -6.9668e+00,  1.5897e+01, -9.8623e+00,  3.0396e+00,
          2.4827e-01,  4.6398e+00, -3.1936e+00],
        [-2.2439e+00, -5.7903e+00,  1.2750e+01, -6.8932e+00,  3.4964e+00,
          1.3582e+00,  5.7628e-01, -2.5355e+00],
        [-4.1794e+00, -5.6173e+00,  4.7750e+00, -6.4927e+00,  2.3853e+01,
         -8.3034e+00,  1.9517e+00, -4.5511e+00],
        [-1.2281e+00, -3.9010e+00,  2.3602e+00, -4.1659e+00,  2.0471e+01,
         -7.5353e+00, -7.9258e-01, -3.9317e+00],
        [ 1.4650e+01, -1.8428e+00,  4.3251e+00, -1.4048e+00, -4.4436e+00,
         -3.1937e+00, -6.5148e+00, -3.0881e+00],
        [-4.6359e+00, -6.5626e+00,  1.5375e+01, -1.0342e+01,  3.7911e+00,
         -5.1994e-01,  5.7401e+00, -2.7618e+00],
        [-3.3845e+00, -8.1843e+00,  1.5792e+01, -1.0015e+01,  2.6508e+00,
          2.9600e+00,  2.6557e+00, -1.6822e+00],
        [-5.2911e+00, -7.6844e+00,  1.7936e+01, -1.1492e+01,  5.2153e+00,
         -5.4982e-01,  5.6828e+00, -3.4962e+00],
        [ 4.6732e+00, -1.7011e+00,  1.3406e+00, -5.9872e-01, -1.9831e+00,
          6.7271e-01, -2.9810e+00,  4.3941e-02],
        [-2.9820e+00, -1.5156e+00,  1.0147e+01, -5.5145e+00,  1.9786e+00,
          1.1236e-01, -2.0673e+00,  2.9165e-04],
        [-3.5155e+00, -6.3128e+00,  1.6410e+01, -1.0585e+01,  3.0518e+00,
         -8.6062e-02,  4.3990e+00, -2.8661e+00],
        [ 1.4201e-01, -5.3306e+00,  1.3693e+01, -7.8711e+00,  7.0664e-01,
          1.5017e+00,  1.9230e-01, -2.2643e+00],
        [-4.2364e+00, -8.4788e+00,  1.7717e+01, -1.1446e+01,  4.2561e+00,
          5.5083e-01,  5.2868e+00, -3.4747e+00],
        [-5.4362e+00, -6.8381e+00,  1.6863e+01, -1.1162e+01,  5.6057e+00,
         -7.6305e-01,  5.0322e+00, -3.1583e+00],
        [-2.5288e-01, -4.9235e+00,  1.0738e+01, -6.3758e+00,  1.6545e+00,
          2.4714e+00, -1.7495e+00, -1.2593e+00],
        [-3.7560e+00, -6.9546e+00,  1.7582e+01, -1.1040e+01,  3.6095e+00,
          6.8771e-01,  3.4587e+00, -2.8313e+00],
        [-8.3249e-01, -6.0002e+00,  1.2154e+01, -6.8301e+00,  1.2292e+00,
          2.4435e+00,  5.5034e-01, -2.2488e+00],
        [-2.1598e+00, -3.4441e+00,  5.9148e+00, -3.4324e+00,  2.4056e+00,
         -5.5885e-01,  3.4388e+00, -1.6509e+00],
        [ 1.4688e+00, -5.0785e+00,  1.3032e+01, -7.0582e+00,  3.8506e-01,
          2.1013e+00, -1.7126e+00, -2.7098e+00],
        [ 8.4031e+00, -2.4387e+00,  3.7925e+00, -2.8615e+00, -2.4590e+00,
         -1.5929e+00, -1.6325e+00, -2.0631e+00],
        [ 1.1649e+01, -1.4549e+00,  4.1567e+00, -1.7535e+00, -4.5063e+00,
         -2.3058e+00, -4.5419e+00, -2.4816e+00],
        [-5.7451e+00, -3.9682e+00,  1.3826e+01, -9.1036e+00,  3.3532e+00,
         -4.0334e-01,  3.2390e+00, -1.2693e+00],
        [ 1.0067e+01, -4.9377e+00,  4.7752e+00, -3.5243e+00, -9.6739e-01,
         -1.1355e+00, -2.4396e+00, -2.6232e+00],
        [-1.1735e+00,  1.0224e+01, -4.8995e-01,  2.7235e-01, -2.2866e+00,
         -3.7032e+00, -4.4318e+00,  2.2714e+00],
        [-2.1617e+00, -6.8540e+00,  4.7507e+00, -6.2487e+00,  2.4522e+01,
         -8.2032e+00,  3.9210e-01, -5.1784e+00],
        [-2.0799e+00, -5.6229e+00,  1.1247e+01, -7.3834e+00,  2.7394e+00,
          5.8084e-01,  2.2603e+00, -1.6323e+00],
        [ 6.5338e-01, -5.1105e+00,  1.3518e+01, -7.5520e+00,  3.9718e-01,
          2.1665e+00, -1.3202e+00, -2.4643e+00]], device='cuda:0',
       grad_fn=<AddmmBackward>)
torch.Size([32, 8])
tensor([2, 2, 2, 2, 2, 2, 2, 4, 4, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        0, 0, 2, 0, 1, 4, 2, 2], device='cuda:0')
torch.Size([32])
Traceback (most recent call last):
  File "/home/diego/projects/DA_ML_Capstone/letsplay_classifier/driver.py", line 92, in <module>
    eval_model(model, criterion)
  File "/home/diego/projects/DA_ML_Capstone/letsplay_classifier/driver.py", line 25, in eval_model
    for i, data in enumerate(dataloaders['val']):
  File "/home/diego/anaconda3/envs/cnn-wendy/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 363, in __next__
    data = self._next_data()
  File "/home/diego/anaconda3/envs/cnn-wendy/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 974, in _next_data
    idx, data = self._get_data()
  File "/home/diego/anaconda3/envs/cnn-wendy/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 941, in _get_data
    success, data = self._try_get_data()
  File "/home/diego/anaconda3/envs/cnn-wendy/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 779, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/diego/anaconda3/envs/cnn-wendy/lib/python3.8/multiprocessing/queues.py", line 107, in get
    if not self._poll(timeout):
  File "/home/diego/anaconda3/envs/cnn-wendy/lib/python3.8/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/diego/anaconda3/envs/cnn-wendy/lib/python3.8/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/diego/anaconda3/envs/cnn-wendy/lib/python3.8/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/diego/anaconda3/envs/cnn-wendy/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt

Process finished with exit code 130 (interrupted by signal 2: SIGINT)
