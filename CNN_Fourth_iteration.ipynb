{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in required libraries, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SageMaker Resources\n",
    "\n",
    "The below cell stores the SageMaker session and role (for creating estimators and models), and creates a default S3 bucket. After creating this bucket, locally stored data can be uploaded to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# default S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix='cnn-wendy-data-5'\n",
    "prefix_output='cnn-wendy-model-5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we retrieve the dataset of images and we upload it to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-31 03:14:09--  https://da-youtube-ml.s3.eu-central-1.amazonaws.com/wendy-cnn/frames/wendy_cnn_frames_data_5.zip\n",
      "Resolving da-youtube-ml.s3.eu-central-1.amazonaws.com (da-youtube-ml.s3.eu-central-1.amazonaws.com)... 52.219.74.21\n",
      "Connecting to da-youtube-ml.s3.eu-central-1.amazonaws.com (da-youtube-ml.s3.eu-central-1.amazonaws.com)|52.219.74.21|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1219145869 (1.1G) [application/zip]\n",
      "Saving to: ‘wendy_cnn_frames_data_5.zip’\n",
      "\n",
      "wendy_cnn_frames_da 100%[===================>]   1.13G  72.2MB/s    in 16s     \n",
      "\n",
      "2020-10-31 03:14:25 (73.3 MB/s) - ‘wendy_cnn_frames_data_5.zip’ saved [1219145869/1219145869]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://da-youtube-ml.s3.eu-central-1.amazonaws.com/wendy-cnn/frames/wendy_cnn_frames_data_5.zip\n",
    "!unzip -qq -n wendy_cnn_frames_data_5.zip -d wendy_cnn_frames_data_5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data to cnn-wendy-data-5\n",
      "Data uploaded to s3://sagemaker-eu-central-1-283211002347/cnn-wendy-data-5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# upload to S3. Skip if already uploaded. This can take a while.\n",
    "print('Uploading data to {}'.format(prefix))\n",
    "input_data = sagemaker_session.upload_data(path='wendy_cnn_frames_data_5', bucket=bucket, key_prefix=prefix)\n",
    "print('Data uploaded to {}'.format(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location to input data can be written down here, if known\n",
    "#input_data='s3://sagemaker-eu-central-1-283211002347/cnn-wendy-data-5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After uploading images to S3, we can define and train the estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path for models is s3://sagemaker-eu-central-1-283211002347/cnn-wendy-model-5\n"
     ]
    }
   ],
   "source": [
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix_output)\n",
    "print('Output path for models is {}'.format(output_path))\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='letsplay_classifier',\n",
    "                    role=role,\n",
    "                    framework_version='1.6',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'img-width': 320,\n",
    "                        'img-height': 180,\n",
    "                        'batch-size': 16,\n",
    "                        'layer-cfg': 'B',\n",
    "                        'epochs': 6\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Estimator\n",
    "\n",
    "After instantiating the estimator, we train it with a call to `.fit()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31 03:59:53 Starting - Starting the training job...\n",
      "2020-10-31 03:59:55 Starting - Launching requested ML instances......\n",
      "2020-10-31 04:01:06 Starting - Preparing the instances for training.........\n",
      "2020-10-31 04:02:28 Downloading - Downloading input data.................................\n",
      "2020-10-31 04:08:23 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-10-31 04:08:24,631 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-10-31 04:08:24,655 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-10-31 04:08:30,894 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-10-31 04:08:31,400 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch==1.6.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.6.0)\u001b[0m\n",
      "\u001b[34mCollecting torchdata==0.2.0\n",
      "  Downloading torchdata-0.2.0-py3-none-any.whl (27 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision==0.7.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 1)) (0.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 1)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch==1.6.0->-r requirements.txt (line 2)) (0.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==0.7.0->-r requirements.txt (line 4)) (8.0.1)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: torchdata\u001b[0m\n",
      "\u001b[34mSuccessfully installed torchdata-0.2.0\u001b[0m\n",
      "\u001b[34m2020-10-31 04:08:33,490 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 16,\n",
      "        \"layer-cfg\": \"B\",\n",
      "        \"img-width\": 320,\n",
      "        \"epochs\": 6,\n",
      "        \"img-height\": 180\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-10-31-03-59-53-628\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-283211002347/pytorch-training-2020-10-31-03-59-53-628/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":16,\"epochs\":6,\"img-height\":180,\"img-width\":320,\"layer-cfg\":\"B\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-central-1-283211002347/pytorch-training-2020-10-31-03-59-53-628/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":16,\"epochs\":6,\"img-height\":180,\"img-width\":320,\"layer-cfg\":\"B\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-10-31-03-59-53-628\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-283211002347/pytorch-training-2020-10-31-03-59-53-628/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"16\",\"--epochs\",\"6\",\"--img-height\",\"180\",\"--img-width\",\"320\",\"--layer-cfg\",\"B\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_LAYER-CFG=B\u001b[0m\n",
      "\u001b[34mSM_HP_IMG-WIDTH=320\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=6\u001b[0m\n",
      "\u001b[34mSM_HP_IMG-HEIGHT=180\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --batch-size 16 --epochs 6 --img-height 180 --img-width 320 --layer-cfg B\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mData Dir: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mModel Dir: /opt/ml/model\u001b[0m\n",
      "\u001b[34mEpoch 0/6\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTraining batch 0/2081\u001b[0m\n",
      "\u001b[34m[2020-10-31 04:08:44.536 algo-1:33 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-10-31 04:08:44.536 algo-1:33 INFO hook.py:193] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-10-31 04:08:44.536 algo-1:33 INFO hook.py:238] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-10-31 04:08:44.536 algo-1:33 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-10-31 04:08:44.564 algo-1:33 INFO hook.py:398] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-10-31 04:08:44.565 algo-1:33 INFO hook.py:459] Hook is writing from the hook with pid: 33\n",
      "\u001b[0m\n",
      "\u001b[34mTraining batch 100/2081\u001b[0m\n",
      "\u001b[34mTraining batch 200/2081\u001b[0m\n",
      "\u001b[34mTraining batch 300/2081\u001b[0m\n",
      "\u001b[34mTraining batch 400/2081\u001b[0m\n",
      "\u001b[34mTraining batch 500/2081\u001b[0m\n",
      "\u001b[34mTraining batch 600/2081\u001b[0m\n",
      "\u001b[34mTraining batch 700/2081\u001b[0m\n",
      "\u001b[34mTraining batch 800/2081\u001b[0m\n",
      "\u001b[34mTraining batch 900/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1000/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1100/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1200/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1300/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1400/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1500/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1600/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1700/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1800/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1900/2081\u001b[0m\n",
      "\u001b[34mTraining batch 2000/2081\u001b[0m\n",
      "\u001b[34mValidation batch 0/673\u001b[0m\n",
      "\u001b[34mValidation batch 100/673\u001b[0m\n",
      "\u001b[34mValidation batch 200/673\u001b[0m\n",
      "\u001b[34mValidation batch 300/673\u001b[0m\n",
      "\u001b[34mValidation batch 400/673\u001b[0m\n",
      "\u001b[34mValidation batch 500/673\u001b[0m\n",
      "\u001b[34mValidation batch 600/673\u001b[0m\n",
      "\u001b[34mEpoch 0 result: \u001b[0m\n",
      "\u001b[34mAvg loss (train): 0.0137\u001b[0m\n",
      "\u001b[34mAvg acc (train): 0.9301\u001b[0m\n",
      "\u001b[34mAvg loss (val): 0.0061\u001b[0m\n",
      "\u001b[34mAvg acc (val): 0.9718\u001b[0m\n",
      "\u001b[34m----------\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 1/6\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTraining batch 0/2081\u001b[0m\n",
      "\u001b[34mTraining batch 100/2081\u001b[0m\n",
      "\u001b[34mTraining batch 200/2081\u001b[0m\n",
      "\u001b[34mTraining batch 300/2081\u001b[0m\n",
      "\u001b[34mTraining batch 400/2081\u001b[0m\n",
      "\u001b[34mTraining batch 500/2081\u001b[0m\n",
      "\u001b[34mTraining batch 600/2081\u001b[0m\n",
      "\u001b[34mTraining batch 700/2081\u001b[0m\n",
      "\u001b[34mTraining batch 800/2081\u001b[0m\n",
      "\u001b[34mTraining batch 900/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1000/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1100/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1200/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1300/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1400/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1500/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1600/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1700/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1800/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1900/2081\u001b[0m\n",
      "\u001b[34mTraining batch 2000/2081\u001b[0m\n",
      "\u001b[34mValidation batch 0/673\u001b[0m\n",
      "\u001b[34mValidation batch 100/673\u001b[0m\n",
      "\u001b[34mValidation batch 200/673\u001b[0m\n",
      "\u001b[34mValidation batch 300/673\u001b[0m\n",
      "\u001b[34mValidation batch 400/673\u001b[0m\n",
      "\u001b[34mValidation batch 500/673\u001b[0m\n",
      "\u001b[34mValidation batch 600/673\u001b[0m\n",
      "\u001b[34mEpoch 1 result: \u001b[0m\n",
      "\u001b[34mAvg loss (train): 0.0065\u001b[0m\n",
      "\u001b[34mAvg acc (train): 0.9677\u001b[0m\n",
      "\u001b[34mAvg loss (val): 0.0043\u001b[0m\n",
      "\u001b[34mAvg acc (val): 0.9817\u001b[0m\n",
      "\u001b[34m----------\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 2/6\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTraining batch 0/2081\u001b[0m\n",
      "\u001b[34mTraining batch 100/2081\u001b[0m\n",
      "\u001b[34mTraining batch 200/2081\u001b[0m\n",
      "\u001b[34mTraining batch 300/2081\u001b[0m\n",
      "\u001b[34mTraining batch 400/2081\u001b[0m\n",
      "\u001b[34mTraining batch 500/2081\u001b[0m\n",
      "\u001b[34mTraining batch 600/2081\u001b[0m\n",
      "\u001b[34mTraining batch 700/2081\u001b[0m\n",
      "\u001b[34mTraining batch 800/2081\u001b[0m\n",
      "\u001b[34mTraining batch 900/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1000/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1100/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1200/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1300/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1400/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1500/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1600/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1700/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1800/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1900/2081\u001b[0m\n",
      "\u001b[34mTraining batch 2000/2081\u001b[0m\n",
      "\u001b[34mValidation batch 0/673\u001b[0m\n",
      "\u001b[34mValidation batch 100/673\u001b[0m\n",
      "\u001b[34mValidation batch 200/673\u001b[0m\n",
      "\u001b[34mValidation batch 300/673\u001b[0m\n",
      "\u001b[34mValidation batch 400/673\u001b[0m\n",
      "\u001b[34mValidation batch 500/673\u001b[0m\n",
      "\u001b[34mValidation batch 600/673\u001b[0m\n",
      "\u001b[34mEpoch 2 result: \u001b[0m\n",
      "\u001b[34mAvg loss (train): 0.0051\u001b[0m\n",
      "\u001b[34mAvg acc (train): 0.9758\u001b[0m\n",
      "\u001b[34mAvg loss (val): 0.0032\u001b[0m\n",
      "\u001b[34mAvg acc (val): 0.9865\u001b[0m\n",
      "\u001b[34m----------\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 3/6\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTraining batch 0/2081\u001b[0m\n",
      "\u001b[34mTraining batch 100/2081\u001b[0m\n",
      "\u001b[34mTraining batch 200/2081\u001b[0m\n",
      "\u001b[34mTraining batch 300/2081\u001b[0m\n",
      "\u001b[34mTraining batch 400/2081\u001b[0m\n",
      "\u001b[34mTraining batch 500/2081\u001b[0m\n",
      "\u001b[34mTraining batch 600/2081\u001b[0m\n",
      "\u001b[34mTraining batch 700/2081\u001b[0m\n",
      "\u001b[34mTraining batch 800/2081\u001b[0m\n",
      "\u001b[34mTraining batch 900/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1000/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1100/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1200/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1300/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1400/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1500/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1600/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1700/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1800/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1900/2081\u001b[0m\n",
      "\u001b[34mTraining batch 2000/2081\u001b[0m\n",
      "\u001b[34mValidation batch 0/673\u001b[0m\n",
      "\u001b[34mValidation batch 100/673\u001b[0m\n",
      "\u001b[34mValidation batch 200/673\u001b[0m\n",
      "\u001b[34mValidation batch 300/673\u001b[0m\n",
      "\u001b[34mValidation batch 400/673\u001b[0m\n",
      "\u001b[34mValidation batch 500/673\u001b[0m\n",
      "\u001b[34mValidation batch 600/673\u001b[0m\n",
      "\u001b[34mEpoch 3 result: \u001b[0m\n",
      "\u001b[34mAvg loss (train): 0.0041\u001b[0m\n",
      "\u001b[34mAvg acc (train): 0.9800\u001b[0m\n",
      "\u001b[34mAvg loss (val): 0.0039\u001b[0m\n",
      "\u001b[34mAvg acc (val): 0.9832\u001b[0m\n",
      "\u001b[34m----------\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 4/6\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTraining batch 0/2081\u001b[0m\n",
      "\u001b[34mTraining batch 100/2081\u001b[0m\n",
      "\u001b[34mTraining batch 200/2081\u001b[0m\n",
      "\u001b[34mTraining batch 300/2081\u001b[0m\n",
      "\u001b[34mTraining batch 400/2081\u001b[0m\n",
      "\u001b[34mTraining batch 500/2081\u001b[0m\n",
      "\u001b[34mTraining batch 600/2081\u001b[0m\n",
      "\u001b[34mTraining batch 700/2081\u001b[0m\n",
      "\u001b[34mTraining batch 800/2081\u001b[0m\n",
      "\u001b[34mTraining batch 900/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1000/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1100/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1200/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1300/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1400/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1500/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1600/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1700/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1800/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1900/2081\u001b[0m\n",
      "\u001b[34mTraining batch 2000/2081\u001b[0m\n",
      "\u001b[34mValidation batch 0/673\u001b[0m\n",
      "\u001b[34mValidation batch 100/673\u001b[0m\n",
      "\u001b[34mValidation batch 200/673\u001b[0m\n",
      "\u001b[34mValidation batch 300/673\u001b[0m\n",
      "\u001b[34mValidation batch 400/673\u001b[0m\n",
      "\u001b[34mValidation batch 500/673\u001b[0m\n",
      "\u001b[34mValidation batch 600/673\u001b[0m\n",
      "\u001b[34mEpoch 4 result: \u001b[0m\n",
      "\u001b[34mAvg loss (train): 0.0036\u001b[0m\n",
      "\u001b[34mAvg acc (train): 0.9829\u001b[0m\n",
      "\u001b[34mAvg loss (val): 0.0027\u001b[0m\n",
      "\u001b[34mAvg acc (val): 0.9889\u001b[0m\n",
      "\u001b[34m----------\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 5/6\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTraining batch 0/2081\u001b[0m\n",
      "\u001b[34mTraining batch 100/2081\u001b[0m\n",
      "\u001b[34mTraining batch 200/2081\u001b[0m\n",
      "\u001b[34mTraining batch 300/2081\u001b[0m\n",
      "\u001b[34mTraining batch 400/2081\u001b[0m\n",
      "\u001b[34mTraining batch 500/2081\u001b[0m\n",
      "\u001b[34mTraining batch 600/2081\u001b[0m\n",
      "\u001b[34mTraining batch 700/2081\u001b[0m\n",
      "\u001b[34mTraining batch 800/2081\u001b[0m\n",
      "\u001b[34mTraining batch 900/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1000/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1100/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1200/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1300/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1400/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1500/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1600/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1700/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1800/2081\u001b[0m\n",
      "\u001b[34mTraining batch 1900/2081\u001b[0m\n",
      "\u001b[34mTraining batch 2000/2081\u001b[0m\n",
      "\u001b[34mValidation batch 0/673\u001b[0m\n",
      "\u001b[34mValidation batch 100/673\u001b[0m\n",
      "\u001b[34mValidation batch 200/673\u001b[0m\n",
      "\u001b[34mValidation batch 300/673\u001b[0m\n",
      "\u001b[34mValidation batch 400/673\u001b[0m\n",
      "\u001b[34mValidation batch 500/673\u001b[0m\n",
      "\u001b[34mValidation batch 600/673\u001b[0m\n",
      "\u001b[34mEpoch 5 result: \u001b[0m\n",
      "\u001b[34mAvg loss (train): 0.0030\u001b[0m\n",
      "\u001b[34mAvg acc (train): 0.9851\u001b[0m\n",
      "\u001b[34mAvg loss (val): 0.0030\u001b[0m\n",
      "\u001b[34mAvg acc (val): 0.9869\u001b[0m\n",
      "\u001b[34m----------\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTraining completed in 152m 59s\u001b[0m\n",
      "\u001b[34mBest acc: 0.9889\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34m#015Test batch 0/449#015Test batch 100/449#015Test batch 200/449#015Test batch 300/449#015Test batch 400/449\u001b[0m\n",
      "\u001b[34mEvaluation completed in 1m 54s\u001b[0m\n",
      "\u001b[34mAvg loss (test): 0.0031\u001b[0m\n",
      "\u001b[34mAvg acc (test): 0.9855\u001b[0m\n",
      "\u001b[34m----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1008\n",
      "           1       0.96      0.96      0.96       163\n",
      "           2       0.99      0.99      0.99      4960\n",
      "           3       0.92      0.99      0.95        89\n",
      "           4       0.99      0.97      0.98       951\n",
      "\n",
      "    accuracy                           0.99      7171\n",
      "   macro avg       0.96      0.98      0.97      7171\u001b[0m\n",
      "\u001b[34mweighted avg       0.99      0.99      0.99      7171\n",
      "\u001b[0m\n",
      "\u001b[34m[[ 989    4   10    2    3]\n",
      " [   1  156    1    5    0]\n",
      " [  35    3 4914    0    8]\n",
      " [   0    0    1   88    0]\n",
      " [   2    0   28    1  920]]\u001b[0m\n",
      "\u001b[34m2020-10-31 06:43:39,651 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-10-31 06:43:43 Uploading - Uploading generated training model\n",
      "2020-10-31 06:44:56 Completed - Training job completed\n",
      "Training seconds: 9748\n",
      "Billable seconds: 9748\n",
      "CPU times: user 21.4 s, sys: 774 ms, total: 22.2 s\n",
      "Wall time: 2h 45min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# train the estimator on S3 training data\n",
    "estimator.fit({'train': input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-central-1-283211002347/cnn-wendy-model-5/pytorch-training-2020-10-31-03-59-53-628/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(estimator.model_data)\n",
    "model_data = estimator.model_data\n",
    "#model_data = 's3://sagemaker-eu-central-1-283211002347/cnn-wendy-model-2b/pytorch-training-2020-10-26-00-49-31-414/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-central-1-283211002347/cnn-wendy-model-5/pytorch-training-2020-10-31-03-59-53-628/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(estimator.model_data)\n",
    "model_data = estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a model that can predict the class of an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the trained model\n",
    "\n",
    "We deploy our model to create a predictor. We'll use this to make predictions on our data and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# importing PyTorchModel\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.6',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir='letsplay_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!CPU times: user 38.8 s, sys: 4.6 s, total: 43.4 s\n",
      "Wall time: 10min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# deploy and create a predictor\n",
    "              \n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.p2.xlarge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-inference-2020-10-31-06-46-05-193\n"
     ]
    }
   ],
   "source": [
    "# the endpoint where the predictor is located\n",
    "endpoint_name = predictor.endpoint\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from letsplay_classifier.endpoint import evalaute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 processed up to 2500\n",
      "10000 processed up to 5000\n",
      "15000 processed up to 7500\n",
      "20000 processed up to 10000\n",
      "25000 processed up to 12500\n",
      "30000 processed up to 15000\n",
      "35000 processed up to 17500\n",
      "40000 processed up to 20000\n",
      "45000 processed up to 22500\n",
      "50000 processed up to 25000\n",
      "55000 processed up to 27500\n",
      "60000 processed up to 30000\n",
      "65000 processed up to 32500\n",
      "70000 processed up to 35000\n",
      "75000 processed up to 37500\n",
      "80000 processed up to 40000\n",
      "85000 processed up to 42500\n",
      "90000 processed up to 45000\n",
      "95000 processed up to 47500\n",
      "100000 processed up to 50000\n"
     ]
    }
   ],
   "source": [
    "from letsplay_classifier.endpoint import evaluate\n",
    "\n",
    "y_true,  y_pred = evaluate(predictor, 'wendy_cnn_frames_data_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is deployed, we check how the predictor performs on our full dataset,\n",
    "ensuring that the predictions make sense. We produce a classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#endpoint_name='pytorch-inference-2020-10-26-04-51-38-837'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      7198\n",
      "           1       0.98      0.98      0.98      1163\n",
      "           2       0.99      0.99      0.99     35425\n",
      "           3       0.96      0.99      0.98       634\n",
      "           4       0.98      0.97      0.98      6796\n",
      "\n",
      "    accuracy                           0.99     51216\n",
      "   macro avg       0.98      0.98      0.98     51216\n",
      "weighted avg       0.99      0.99      0.99     51216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7110,    11,    56,     4,    17],\n",
       "       [    2,  1140,     4,    17,     0],\n",
       "       [  167,    11, 35155,     1,    91],\n",
       "       [    0,     3,     2,   628,     1],\n",
       "       [    7,     3,   187,     1,  6598]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘wendy_cnn_frames_E69.zip’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://da-youtube-ml.s3.eu-central-1.amazonaws.com/wendy-cnn/frames/wendy_cnn_frames_E69.zip\n",
    "!unzip -qq -n wendy_cnn_frames_E69.zip -d wendy_cnn_frames_E69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:44-03:10 | Battle : 92% , Other : 7% \n",
      "06:12-06:14 | ????? \n",
      "19:50-21:56 | Battle : 91% , Other : 7% \n",
      "35:42-35:44 | ????? \n",
      "36:50-38:10 | Battle : 90% , Other : 9% \n",
      "41:10-41:42 | Battle : 77% , Other : 12% \n",
      "52:30-52:34 | Other : 85% , Tournament : 15% \n"
     ]
    }
   ],
   "source": [
    "from letsplay_classifier.interval.predict_intervals_endpoint import evaluate\n",
    "evaluate(predictor, 'wendy_cnn_frames_E69/E69', class_names= ['Battle', 'Hideout', 'Other', 'Siege', 'Tournament'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Endpoint\n",
    "\n",
    "Finally, I've added a convenience function to delete prediction endpoints after we're done with them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a predictor endpoint as input\n",
    "# And deletes the endpoint by name\n",
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=endpoint_name)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already deleted: pytorch-inference-2020-10-30-23-46-17-619\n"
     ]
    }
   ],
   "source": [
    "# delete the predictor endpoint \n",
    "delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
